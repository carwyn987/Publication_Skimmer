author,citations,titles,author_ids
CH Papadimitriou,3796.0,"['The complexity of Markov decision processes', 'The complexity of Markov decision processes']",['rXYLXJMAAAAJ']
JN Tsitsiklis,3796.0,"['The complexity of Markov decision processes', 'The complexity of Markov decision processes']",['bWTPrLEAAAAJ']
HR Karimi,314.0,"['Adaptive-critic design for decentralized event-triggered control of constrained nonlinear interconnected systems within an identifier-critic framework', 'Adaptive-critic design for decentralized event-triggered control of constrained nonlinear interconnected systems within an identifier-critic framework']",['YcTS0ZMAAAAJ']
X Zhao,314.0,"['Adaptive-critic design for decentralized event-triggered control of constrained nonlinear interconnected systems within an identifier-critic framework', 'Adaptive-critic design for decentralized event-triggered control of constrained nonlinear interconnected systems within an identifier-critic framework', 'A Data-Based Adaptive Consensus Control Algorithm of Discrete-Time Multi-Agent Systems', 'A Data-Based Adaptive Consensus Control Algorithm of Discrete-Time Multi-Agent Systems']","['uYkpwCAAAAAJ', 'nFG8lEYAAAAJ']"
B Wang,314.0,"['Adaptive-critic design for decentralized event-triggered control of constrained nonlinear interconnected systems within an identifier-critic framework', 'Adaptive-critic design for decentralized event-triggered control of constrained nonlinear interconnected systems within an identifier-critic framework']",['9sau-6oAAAAJ']
R Ngo,314.0,"['The alignment problem from a deep learning perspective', 'The alignment problem from a deep learning perspective']",['7CY93A4AAAAJ']
L Chan,314.0,"['The alignment problem from a deep learning perspective', 'The alignment problem from a deep learning perspective']",['6Id1G8cAAAAJ']
S Mindermann,314.0,"['The alignment problem from a deep learning perspective', 'The alignment problem from a deep learning perspective']",['slBPlrQAAAAJ']
CC Hung,282.0,"['Optimizing agent behavior over long time scales by transporting value', 'Optimizing agent behavior over long time scales by transporting value']",['zl0fMUYAAAAJ']
T Lillicrap,282.0,"['Optimizing agent behavior over long time scales by transporting value', 'Optimizing agent behavior over long time scales by transporting value']",['htPVdRMAAAAJ']
Y Wu,282.0,"['Optimizing agent behavior over long time scales by transporting value', 'Optimizing agent behavior over long time scales by transporting value']",['vYmSd0UAAAAJ']
JR Peters,208.0,"['Machine learning of motor skills for robotics', 'Machine learning of motor skills for robotics']",['-kIVAcAAAAAJ']
N Vlassis,206.0,"['Bayesian reinforcement learning', 'Bayesian reinforcement learning']",['JJWWPjsAAAAJ']
M Ghavamzadeh,206.0,"['Bayesian reinforcement learning', 'Bayesian reinforcement learning']",['Bo-wyrkAAAAJ']
S Mannor,206.0,"['Bayesian reinforcement learning', 'Bayesian reinforcement learning']",['q1HlbIUAAAAJ']
V Narayanan,186.0,"['Event-triggered distributed control of nonlinear interconnected systems using online reinforcement learning with exploration', 'Event-triggered distributed control of nonlinear interconnected systems using online reinforcement learning with exploration']",['rirGB10AAAAJ']
S Jagannathan,186.0,"['Event-triggered distributed control of nonlinear interconnected systems using online reinforcement learning with exploration', 'Event-triggered distributed control of nonlinear interconnected systems using online reinforcement learning with exploration']",['RTewL_wAAAAJ']
L Liu,186.0,"['Fuzzy observer constraint based on adaptive control for uncertain nonlinear MIMO systems with time-varying state constraints', 'Fuzzy observer constraint based on adaptive control for uncertain nonlinear MIMO systems with time-varying state constraints', 'Compressible Non-Newtonian Fluid Based Road Traffic Flow Equation Solved by Physical-Informed Rational Neural Network', 'Compressible Non-Newtonian Fluid Based Road Traffic Flow Equation Solved by Physical-Informed Rational Neural Network']","['7r__F5EAAAAJ', 'UCIsl-sAAAAJ']"
YJ Liu,180.0,"['Fuzzy observer constraint based on adaptive control for uncertain nonlinear MIMO systems with time-varying state constraints', 'Fuzzy observer constraint based on adaptive control for uncertain nonlinear MIMO systems with time-varying state constraints']",['x_Wk1jAAAAAJ']
MA Wiering,176.0,"['Reinforcement learning algorithms for solving classification problems', 'Reinforcement learning algorithms for solving classification problems']",['880vFIgAAAAJ']
H Van Hasselt,176.0,"['Reinforcement learning algorithms for solving classification problems', 'Reinforcement learning algorithms for solving classification problems']",['W80oBMkAAAAJ']
X Huo,157.0,['Adaptive-critic design for decentralized event-triggered control of constrained nonlinear interconnected systems within an identifier-critic framework'],[]
Y Jiang,156.0,"['Data-driven cooperative output regulation of multi-agent systems via robust adaptive dynamic programming', 'Data-driven cooperative output regulation of multi-agent systems via robust adaptive dynamic programming', 'Robust adaptive dynamic programming: An overview of recent results', 'Robust adaptive dynamic programming: An overview of recent results', 'Robust adaptive dynamic programming: recent results and applications', 'Robust adaptive dynamic programming: recent results and applications']",['QYanTRsAAAAJ']
L Lei,150.0,"['Autonomous platoon control with integrated deep reinforcement learning and dynamic programming', 'Autonomous platoon control with integrated deep reinforcement learning and dynamic programming', 'Deep reinforcement learning aided platoon control relying on V2X information', 'Deep reinforcement learning aided platoon control relying on V2X information', 'AVDDPG: Federated reinforcement learning applied to autonomous platoon control', 'AVDDPG: Federated reinforcement learning applied to autonomous platoon control']",['Ut0-14IAAAAJ']
W Gao,146.0,"['Data-driven cooperative output regulation of multi-agent systems via robust adaptive dynamic programming', 'Data-driven cooperative output regulation of multi-agent systems via robust adaptive dynamic programming', 'Data-Driven Adaptive Optimal Tracking and Its Applications to Intelligent Transportation Systems', 'Data-Driven Adaptive Optimal Tracking and Its Applications to Intelligent Transportation Systems']",['XNYwzswAAAAJ']
M Davari,146.0,"['Data-driven cooperative output regulation of multi-agent systems via robust adaptive dynamic programming', 'Data-driven cooperative output regulation of multi-agent systems via robust adaptive dynamic programming']",['fHOM7SEAAAAJ']
K Zheng,144.0,"['Autonomous platoon control with integrated deep reinforcement learning and dynamic programming', 'Autonomous platoon control with integrated deep reinforcement learning and dynamic programming', 'Deep reinforcement learning aided platoon control relying on V2X information', 'Deep reinforcement learning aided platoon control relying on V2X information']",['IX_id5UAAAAJ']
J Abramson,141.0,['Optimizing agent behavior over long time scales by transporting value'],[]
M Ranzato,138.0,"['Advances in Neural Information Processing Systems 34', 'Advances in Neural Information Processing Systems 34']",['NbXF7T8AAAAJ']
Y Dauphin,138.0,"['Advances in Neural Information Processing Systems 34', 'Advances in Neural Information Processing Systems 34']",['XSforroAAAAJ']
PS Liang,138.0,"['Advances in Neural Information Processing Systems 34', 'Advances in Neural Information Processing Systems 34']",['pouyVyUAAAAJ']
K Yu,134.0,"[""A blockchain-based shamir's threshold cryptography scheme for data protection in industrial internet of things settings""]",[]
L Tan,134.0,"[""A blockchain-based shamir's threshold cryptography scheme for data protection in industrial internet of things settings""]",[]
C Yang,134.0,"[""A blockchain-based shamir's threshold cryptography scheme for data protection in industrial internet of things settings""]",[]
KKR Choo,134.0,"[""A blockchain-based shamir's threshold cryptography scheme for data protection in industrial internet of things settings""]",[]
A Zhang,116.0,"['Learning causal state representations of partially observable environments', 'Learning causal state representations of partially observable environments', 'Drone Swarm Robust Cooperative Formation Pursuit through Relative Positioning in a Location Denial Environment.']",['mXtH1UYAAAAJ']
ZC Lipton,116.0,"['Learning causal state representations of partially observable environments', 'Learning causal state representations of partially observable environments']",['MN9Kfg8AAAAJ']
L Pineda,116.0,"['Learning causal state representations of partially observable environments', 'Learning causal state representations of partially observable environments']",['rebEn8oAAAAJ']
M Gong,90.0,['Fuzzy observer constraint based on adaptive control for uncertain nonlinear MIMO systems with time-varying state constraints'],[]
S Tong,90.0,['Fuzzy observer constraint based on adaptive control for uncertain nonlinear MIMO systems with time-varying state constraints'],[]
L Hanzo,86.0,"['Deep reinforcement learning aided platoon control relying on V2X information', 'Deep reinforcement learning aided platoon control relying on V2X information']",['p0jnEW0AAAAJ']
W Tang,76.0,"['Data-driven control: Overview and perspectives', 'Data-driven control: Overview and perspectives']",['K67JZlsAAAAJ']
P Daoutidis,76.0,"['Data-driven control: Overview and perspectives', 'Data-driven control: Overview and perspectives']",['qIm39l8AAAAJ']
T Liu,72.0,"['Autonomous platoon control with integrated deep reinforcement learning and dynamic programming', 'Deep reinforcement learning aided platoon control relying on V2X information']",[]
A Beygelzimer,69.0,['Advances in Neural Information Processing Systems 34'],[]
X Chen,68.0,"['Model-free output consensus control for partially observable heterogeneous multivehicle systems', 'Model-free output consensus control for partially observable heterogeneous multivehicle systems', 'Decentralized stochastic bilevel optimization with improved per-iteration complexity', 'Decentralized stochastic bilevel optimization with improved per-iteration complexity']","['Jcrh5xAAAAAJ', '5l-RAfEAAAAJ']"
D Cappello,64.0,"['Distributed differential games for control of multi-agent systems', 'Distributed differential games for control of multi-agent systems']",['xjmL-7IAAAAJ']
T Mylvaganam,64.0,"['Distributed differential games for control of multi-agent systems', 'Distributed differential games for control of multi-agent systems']",['fIEuk78AAAAJ']
G Jing,62.0,"['Asynchronous distributed reinforcement learning for lqr control via zeroth-order block coordinate descent', 'Asynchronous distributed reinforcement learning for lqr control via zeroth-order block coordinate descent', 'Model-free optimal control of linear multiagent systems via decomposition and hierarchical approximation', 'Model-free optimal control of linear multiagent systems via decomposition and hierarchical approximation']",['Czk87NYAAAAJ']
H Bai,62.0,"['Asynchronous distributed reinforcement learning for lqr control via zeroth-order block coordinate descent', 'Asynchronous distributed reinforcement learning for lqr control via zeroth-order block coordinate descent', 'Model-free optimal control of linear multiagent systems via decomposition and hierarchical approximation', 'Model-free optimal control of linear multiagent systems via decomposition and hierarchical approximation']",['z7N_-U4AAAAJ']
J George,62.0,"['Asynchronous distributed reinforcement learning for lqr control via zeroth-order block coordinate descent', 'Asynchronous distributed reinforcement learning for lqr control via zeroth-order block coordinate descent', 'Model-free optimal control of linear multiagent systems via decomposition and hierarchical approximation', 'Model-free optimal control of linear multiagent systems via decomposition and hierarchical approximation']",['caxjdt4AAAAJ']
M Hutter,59.0,"['Self-predictive universal AI', 'Compress and control', 'Compress and control']",['7hmCntEAAAAJ']
K Zhang,58.0,"['Autonomous platoon control with integrated deep reinforcement learning and dynamic programming', 'Autonomous platoon control with integrated deep reinforcement learning and dynamic programming']",['hLT3_twAAAAJ']
J Veness,56.0,"['Compress and control', 'Compress and control']",['_iYrAxEAAAAJ']
M Bellemare,56.0,"['Compress and control', 'Compress and control']",['uyYPun0AAAAJ']
Y Li,54.0,"['Multiagent reinforcement learning-based cooperative multitype task offloading strategy for internet of vehicles in B5G/6G network', 'Deep reinforcement learning for wireless scheduling in distributed networked control', 'Deep reinforcement learning for wireless scheduling in distributed networked control']",['xLj8A2EAAAAJ']
J Peters,52.0,"['Towards machine learning of motor skills', 'Towards machine learning of motor skills', 'Policy learning for motor skills', 'Policy learning for motor skills']",['-kIVAcAAAAAJ']
S Schaal,52.0,"['Towards machine learning of motor skills', 'Towards machine learning of motor skills', 'Policy learning for motor skills', 'Policy learning for motor skills']",['YGQs1AYAAAAJ']
Z Peng,52.0,"['Data-driven containment control of discrete-time multi-agent systems via value iteration', 'Data-driven containment control of discrete-time multi-agent systems via value iteration']",['9AUL9JEAAAAJ']
J Hu,52.0,"['Data-driven containment control of discrete-time multi-agent systems via value iteration', 'Data-driven containment control of discrete-time multi-agent systems via value iteration']",['KMoR83sAAAAJ']
B Goertzel,52.0,"['The general theory of general intelligence: a pragmatic patternist perspective', 'The general theory of general intelligence: a pragmatic patternist perspective']",['kTfdhRcAAAAJ']
M Huang,46.0,"['Deep Reinforcement Learning-Based DoS Attack and its Countermeasures in Cyber-Physical Systems', 'Decentralized stochastic bilevel optimization with improved per-iteration complexity', 'Decentralized stochastic bilevel optimization with improved per-iteration complexity']",['5j_jAr8AAAAJ']
S Ma,46.0,"['Decentralized stochastic bilevel optimization with improved per-iteration complexity', 'Decentralized stochastic bilevel optimization with improved per-iteration complexity']",['kkzUrUgAAAAJ']
H Li,45.0,"['Multiagent reinforcement learning-based cooperative multitype task offloading strategy for internet of vehicles in B5G/6G network', 'Observer-based consensus control for MASs with prescribed constraints via reinforcement learning algorithm']",[]
KG Vamvoudakis,44.0,"['Online optimal operation of parallel voltage-source inverters using partial information', 'Online optimal operation of parallel voltage-source inverters using partial information']",['4hWyM_gAAAAJ']
JP Hespanha,44.0,"['Online optimal operation of parallel voltage-source inverters using partial information', 'Online optimal operation of parallel voltage-source inverters using partial information']",['AsT__tUAAAAJ']
B Zhao,40.0,"['Event-triggered local control for nonlinear interconnected systems through particle swarm optimization-based adaptive dynamic programming', 'Event-triggered local control for nonlinear interconnected systems through particle swarm optimization-based adaptive dynamic programming']",['977NXzsAAAAJ']
G Pang,36.0,"['Deep reinforcement learning for wireless scheduling in distributed networked control', 'Deep reinforcement learning for wireless scheduling in distributed networked control']",['v1X_GU4AAAAJ']
DE Quevedo,36.0,"['Deep reinforcement learning for wireless scheduling in distributed networked control', 'Deep reinforcement learning for wireless scheduling in distributed networked control']",['s0MIz4sAAAAJ']
B Vucetic,36.0,"['Deep reinforcement learning for wireless scheduling in distributed networked control', 'Deep reinforcement learning for wireless scheduling in distributed networked control']",['uS5QyboAAAAJ']
X Zhang,36.0,"['Gaussian Distribution.', 'Gaussian Distribution.']",['jrkrn3sAAAAJ']
K Young,34.0,"['The benefits of model-based generalization in reinforcement learning', 'The benefits of model-based generalization in reinforcement learning']",['zI2uHi8AAAAJ']
A Ramesh,34.0,"['The benefits of model-based generalization in reinforcement learning', 'The benefits of model-based generalization in reinforcement learning']",['60K82BkAAAAJ']
L Kirsch,34.0,"['The benefits of model-based generalization in reinforcement learning', 'The benefits of model-based generalization in reinforcement learning']",['w8AkOEAAAAAJ']
E Uchibe,32.0,"['Cooperative behavior acquisition by learning and evolution in a multi-agent environment for mobile robots', 'Cooperative behavior acquisition by learning and evolution in a multi-agent environment for mobile robots']",['nXqBRo8AAAAJ']
W Zhao,30.0,"['Robust optimal formation control of heterogeneous multi-agent system via reinforcement learning', 'Robust optimal formation control of heterogeneous multi-agent system via reinforcement learning']",['tzJ9BsoAAAAJ']
R Song,30.0,"['Containment control of heterogeneous systems with active leaders of bounded unknown control using reinforcement learning', 'Containment control of heterogeneous systems with active leaders of bounded unknown control using reinforcement learning', 'Output resilient containment control of heterogeneous systems with active leaders using reinforcement learning under attack inputs', 'Output resilient containment control of heterogeneous systems with active leaders using reinforcement learning under attack inputs']",['wGWQpLIAAAAJ']
Y Yang,28.0,"['Containment control of heterogeneous systems with non-autonomous leaders: A distributed optimal model reference approach', 'Containment control of heterogeneous systems with non-autonomous leaders: A distributed optimal model reference approach', 'Containment control of heterogeneous systems with active leaders of bounded unknown control using reinforcement learning', 'Containment control of heterogeneous systems with active leaders of bounded unknown control using reinforcement learning', 'Data-Driven Solutions to Mixed Control: A Hamilton-Inequality-Driven Reinforcement Learning Approach', 'Data-Driven Solutions to Mixed Control: A Hamilton-Inequality-Driven Reinforcement Learning Approach']",['smwQtUwAAAAJ']
DC Wunsch,28.0,"['Containment control of heterogeneous systems with non-autonomous leaders: A distributed optimal model reference approach', 'Containment control of heterogeneous systems with non-autonomous leaders: A distributed optimal model reference approach', 'Containment control of heterogeneous systems with active leaders of bounded unknown control using reinforcement learning', 'Containment control of heterogeneous systems with active leaders of bounded unknown control using reinforcement learning']",['fQC7bIoAAAAJ']
A Chua,28.0,['Compress and control'],[]
A Luo,27.0,['Observer-based consensus control for MASs with prescribed constraints via reinforcement learning algorithm'],[]
Q Zhou,27.0,['Observer-based consensus control for MASs with prescribed constraints via reinforcement learning algorithm'],[]
H Ma,27.0,['Observer-based consensus control for MASs with prescribed constraints via reinforcement learning algorithm'],[]
X Dong,27.0,"['Data-Driven Distributed Current Sharing Consensus Optimal Control of DC Microgrids via Reinforcement Learning', 'Fully data-driven robust output formation tracking control for heterogeneous multiagent system with multiple leaders and actuator faults', 'Fully data-driven robust output formation tracking control for heterogeneous multiagent system with multiple leaders and actuator faults', 'Resilient Output Formation-Containment Tracking of Heterogeneous Multi-Agent Systems: A Learning-Based Framework using Dynamic Data', 'Cooperative Fault-Tolerant Formation Tracking Control for Heterogeneous Air-Ground Systems Using a Learning-Based Method']",['4GeHHnUAAAAJ']
F Tatari,26.0,"['Distributed optimal synchronization control of linear networked systems under unknown dynamics', 'Distributed optimal synchronization control of linear networked systems under unknown dynamics']",['kocqXnAAAAAJ']
BK Ghosh,26.0,['Data-driven containment control of discrete-time multi-agent systems via value iteration'],[]
NK Dhar,24.0,"['An online event-triggered near-optimal controller for Nash solution in interconnected system', 'An online event-triggered near-optimal controller for Nash solution in interconnected system']",['xH9YlKQAAAAJ']
NK Verma,24.0,"['An online event-triggered near-optimal controller for Nash solution in interconnected system', 'An online event-triggered near-optimal controller for Nash solution in interconnected system']",['Iir1EBsAAAAJ']
L Behera,24.0,"['An online event-triggered near-optimal controller for Nash solution in interconnected system', 'An online event-triggered near-optimal controller for Nash solution in interconnected system']",['QWTcyP8AAAAJ']
LA Cox Jr,24.0,"['Information structures for causally explainable decisions', 'Information structures for causally explainable decisions', 'Causally explainable decision recommendations using causal artificial intelligence', 'Causally explainable decision recommendations using causal artificial intelligence']",['i0PiR8UAAAAJ']
Y Shi,24.0,"['Fully data-driven robust output formation tracking control for heterogeneous multiagent system with multiple leaders and actuator faults', 'Fully data-driven robust output formation tracking control for heterogeneous multiagent system with multiple leaders and actuator faults', 'Resilient Output Formation-Containment Tracking of Heterogeneous Multi-Agent Systems: A Learning-Based Framework using Dynamic Data', 'Resilient Output Formation-Containment Tracking of Heterogeneous Multi-Agent Systems: A Learning-Based Framework using Dynamic Data', 'Cooperative Fault-Tolerant Formation Tracking Control for Heterogeneous Air-Ground Systems Using a Learning-Based Method', 'Cooperative Fault-Tolerant Formation Tracking Control for Heterogeneous Air-Ground Systems Using a Learning-Based Method']",['DBqSTJ0AAAAJ']
J Yu,24.0,"['Fully data-driven robust output formation tracking control for heterogeneous multiagent system with multiple leaders and actuator faults', 'Fully data-driven robust output formation tracking control for heterogeneous multiagent system with multiple leaders and actuator faults', 'Resilient Output Formation-Containment Tracking of Heterogeneous Multi-Agent Systems: A Learning-Based Framework using Dynamic Data', 'Resilient Output Formation-Containment Tracking of Heterogeneous Multi-Agent Systems: A Learning-Based Framework using Dynamic Data', 'Cooperative Fault-Tolerant Formation Tracking Control for Heterogeneous Air-Ground Systems Using a Learning-Based Method', 'Cooperative Fault-Tolerant Formation Tracking Control for Heterogeneous Air-Ground Systems Using a Learning-Based Method']",['XaGaDnYAAAAJ']
Y Sun,22.0,"['Model-free output consensus control for partially observable heterogeneous multivehicle systems', 'Model-free output consensus control for partially observable heterogeneous multivehicle systems']",['jhV1sqwAAAAJ']
W Wang,22.0,"['Model-free output consensus control for partially observable heterogeneous multivehicle systems', 'Model-free output consensus control for partially observable heterogeneous multivehicle systems']",['UedS9LQAAAAJ']
H Cai,22.0,"['Drone Swarm Robust Cooperative Formation Pursuit through Relative Positioning in a Location Denial Environment.', 'Drone Swarm Robust Cooperative Formation Pursuit through Relative Positioning in a Location Denial Environment.', ""Distributed tracking of leader-follower multiagent systems subject to disturbed leader's information"", ""Distributed tracking of leader-follower multiagent systems subject to disturbed leader's information""]",['g3ugXlkAAAAJ']
G Shi,20.0,['Event-triggered local control for nonlinear interconnected systems through particle swarm optimization-based adaptive dynamic programming'],[]
D Liu,20.0,['Event-triggered local control for nonlinear interconnected systems through particle swarm optimization-based adaptive dynamic programming'],[]
Y Cui,18.0,['Multiagent reinforcement learning-based cooperative multitype task offloading strategy for internet of vehicles in B5G/6G network'],[]
D Zhang,18.0,['Multiagent reinforcement learning-based cooperative multitype task offloading strategy for internet of vehicles in B5G/6G network'],[]
A Zhu,18.0,['Multiagent reinforcement learning-based cooperative multitype task offloading strategy for internet of vehicles in B5G/6G network'],[]
K Huang,18.0,['Deep reinforcement learning for wireless scheduling in distributed networked control'],[]
L Xia,16.0,"['Output resilient containment control of heterogeneous systems with active leaders using reinforcement learning under attack inputs', 'Output resilient containment control of heterogeneous systems with active leaders using reinforcement learning under attack inputs']",['Euxh1SoAAAAJ']
H Liu,15.0,"['Distributed Vibration Control of Large Flexible Satellite Solar Panel Via Reinforcement Learning', 'Robust optimal formation control of heterogeneous multi-agent system via reinforcement learning', 'Robust optimal control law learning for heterogeneous rotorcraft formation involving unknown parameters']",[]
W Lin,15.0,['Robust optimal formation control of heterogeneous multi-agent system via reinforcement learning'],[]
Y Yin,15.0,"['Containment control of heterogeneous systems with non-autonomous leaders: A distributed optimal model reference approach', 'Containment control of heterogeneous systems with active leaders of bounded unknown control using reinforcement learning', 'Model-Free Containment Control of Fully Heterogeneous Linear Multiagent Systems']",[]
L Yang,15.0,"['Learning optimal stochastic sensor scheduling for remote estimation with channel capacity constraint', 'Learning optimal stochastic sensor scheduling for remote estimation with channel capacity constraint', 'Robust optimal control law learning for heterogeneous rotorcraft formation involving unknown parameters', 'Distributed Containment Control Strategy for the Dynamic Stabilization of Integrated Energy System With Multiple Virtual Leaders']",['G-u29p4AAAAJ']
H Zhang,14.0,"['Data-Driven Distributed Current Sharing Consensus Optimal Control of DC Microgrids via Reinforcement Learning', 'Data-Driven Distributed Current Sharing Consensus Optimal Control of DC Microgrids via Reinforcement Learning', 'Distributed Containment Control Strategy for the Dynamic Stabilization of Integrated Energy System With Multiple Virtual Leaders', 'Distributed Containment Control Strategy for the Dynamic Stabilization of Integrated Energy System With Multiple Virtual Leaders']",['nbQu9moAAAAJ']
A Chakrabortty,14.0,"['Asynchronous distributed reinforcement learning for lqr control via zeroth-order block coordinate descent', 'Asynchronous distributed reinforcement learning for lqr control via zeroth-order block coordinate descent']",['cyRBMkkAAAAJ']
GP Liu,14.0,"['A leader-follower formation strategy for networked multi-agent systems based on the PI predictive control method', 'A leader-follower formation strategy for networked multi-agent systems based on the PI predictive control method']",['jWmF7IQAAAAJ']
DW Zhang,14.0,"['A leader-follower formation strategy for networked multi-agent systems based on the PI predictive control method', 'A leader-follower formation strategy for networked multi-agent systems based on the PI predictive control method']",['94h31jkAAAAJ']
MB Naghibi-Sistani,13.0,['Distributed optimal synchronization control of linear networked systems under unknown dynamics'],['3OiE5loAAAAJ']
MB Naghibi,13.0,['Distributed optimal synchronization control of linear networked systems under unknown dynamics'],[]
Y Grinberg,12.0,"['Goal-directed online learning of predictive models', 'Goal-directed online learning of predictive models']",['z-sG3n4AAAAJ']
J Pineau,12.0,"['Goal-directed online learning of predictive models', 'Goal-directed online learning of predictive models']",['CEt6_mMAAAAJ']
Y Hua,12.0,"['Fully data-driven robust output formation tracking control for heterogeneous multiagent system with multiple leaders and actuator faults', 'Resilient Output Formation-Containment Tracking of Heterogeneous Multi-Agent Systems: A Learning-Based Framework using Dynamic Data', 'Cooperative Fault-Tolerant Formation Tracking Control for Heterogeneous Air-Ground Systems Using a Learning-Based Method']",[]
H Fu,11.0,['Model-free output consensus control for partially observable heterogeneous multivehicle systems'],[]
J Grand-Clément,11.0,['Reducing blackwell and average optimality to discounted mdps via the blackwell discount factor'],['K_ZLzdoAAAAJ']
M Petrik,11.0,['Reducing blackwell and average optimality to discounted mdps via the blackwell discount factor'],['yT-xSLoAAAAJ']
J Grand,11.0,['Reducing blackwell and average optimality to discounted mdps via the blackwell discount factor'],[]
H Gao,11.0,"['Drone Swarm Robust Cooperative Formation Pursuit through Relative Positioning in a Location Denial Environment.', ""Distributed tracking of leader-follower multiagent systems subject to disturbed leader's information""]",[]
X Li,11.0,"[""Distributed tracking of leader-follower multiagent systems subject to disturbed leader's information""]",[]
S Xu,11.0,"[""Distributed tracking of leader-follower multiagent systems subject to disturbed leader's information""]",[]
ZP Jiang,10.0,"['Robust adaptive dynamic programming: An overview of recent results', 'Robust adaptive dynamic programming: An overview of recent results', 'Robust adaptive dynamic programming: recent results and applications', 'Robust adaptive dynamic programming: recent results and applications']",['COrhJXcAAAAJ']
B Schölkopf,8.0,"['Towards machine learning of motor skills', 'Towards machine learning of motor skills']",['DZ-fHPgAAAAJ']
SK Paul,8.0,"['Solving partially observable environments with universal search using dataflow graph-based programming model', 'Solving partially observable environments with universal search using dataflow graph-based programming model']",['YHRO7eoAAAAJ']
P Bhaumik,8.0,"['Solving partially observable environments with universal search using dataflow graph-based programming model', 'Solving partially observable environments with universal search using dataflow graph-based programming model']",['dzrHTMcAAAAJ']
DM Bossens,8.0,"['Lifetime policy reuse and the importance of task capacity', 'Lifetime policy reuse and the importance of task capacity']",['w2feGIoAAAAJ']
AJ Sobey,8.0,"['Lifetime policy reuse and the importance of task capacity', 'Lifetime policy reuse and the importance of task capacity']",['inoZq8AAAAAJ']
L Chen,8.0,"['Adaptive event-triggered transmission scheduling in rate-limited multiloop remote control', 'Adaptive event-triggered transmission scheduling in rate-limited multiloop remote control']",['-0n0cu8AAAAJ']
Q Li,8.0,['Output resilient containment control of heterogeneous systems with active leaders using reinforcement learning under attack inputs'],[]
S Cheng,7.0,['Containment control of heterogeneous systems with non-autonomous leaders: A distributed optimal model reference approach'],[]
Y Xu,7.0,"['Learning optimal stochastic sensor scheduling for remote estimation with channel capacity constraint', 'Adaptive dynamic programming approach for Stackelberg game-based fault-tolerant control']",[]
L Cao,7.0,['A leader-follower formation strategy for networked multi-agent systems based on the PI predictive control method'],[]
E Catt,6.0,"['Self-predictive universal AI', 'Self-predictive universal AI']",['d1JYeMIAAAAJ']
SX Yang,6.0,"['AVDDPG: Federated reinforcement learning applied to autonomous platoon control', 'AVDDPG: Federated reinforcement learning applied to autonomous platoon control']",['cyRDiPMAAAAJ']
SCW Ong,6.0,['Goal-directed online learning of predictive models'],[]
Z Huang,6.0,['Learning optimal stochastic sensor scheduling for remote estimation with channel capacity constraint'],[]
H Rao,6.0,['Learning optimal stochastic sensor scheduling for remote estimation with channel capacity constraint'],[]
JVDF Neto,6.0,"['HDP algorithms for trajectory tracking and formation control of multi-agent systems', 'HDP algorithms for trajectory tracking and formation control of multi-agent systems']",['gkCdm_8AAAAJ']
RR Selmic,6.0,"['HDP algorithms for trajectory tracking and formation control of multi-agent systems', 'HDP algorithms for trajectory tracking and formation control of multi-agent systems']",['PxMC2pcAAAAJ']
X Xie,4.0,['Data-Driven Distributed Current Sharing Consensus Optimal Control of DC Microgrids via Reinforcement Learning'],[]
Z Ming,4.0,['Data-Driven Distributed Current Sharing Consensus Optimal Control of DC Microgrids via Reinforcement Learning'],[]
B Hu,4.0,['Adaptive event-triggered transmission scheduling in rate-limited multiloop remote control'],[]
ZH Guan,4.0,['Adaptive event-triggered transmission scheduling in rate-limited multiloop remote control'],[]
J Grau-Moya,3.0,['Self-predictive universal AI'],['u8ccN8sAAAAJ']
J Grau,3.0,['Self-predictive universal AI'],[]
C Boin,3.0,"['AVDDPG: Federated reinforcement learning applied to autonomous platoon control', 'A Federated Reinforcement Learning Approach for Autonomous Vehicle Platooning']",[]
EFM Ferreira,3.0,['HDP algorithms for trajectory tracking and formation control of multi-agent systems'],[]
H Han,3.0,['Distributed Containment Control Strategy for the Dynamic Stabilization of Integrated Energy System With Multiple Virtual Leaders'],[]
J Yang,3.0,['Distributed Containment Control Strategy for the Dynamic Stabilization of Integrated Energy System With Multiple Virtual Leaders'],[]
Z Yang,3.0,['Compressible Non-Newtonian Fluid Based Road Traffic Flow Equation Solved by Physical-Informed Rational Neural Network'],[]
D Li,3.0,['Compressible Non-Newtonian Fluid Based Road Traffic Flow Equation Solved by Physical-Informed Rational Neural Network'],[]
W Nai,3.0,['Compressible Non-Newtonian Fluid Based Road Traffic Flow Equation Solved by Physical-Informed Rational Neural Network'],[]
J Sun,3.0,['Compressible Non-Newtonian Fluid Based Road Traffic Flow Equation Solved by Physical-Informed Rational Neural Network'],[]
X Lv,3.0,['Compressible Non-Newtonian Fluid Based Road Traffic Flow Equation Solved by Physical-Informed Rational Neural Network'],[]
W He,3.0,['Distributed cooperative formation control for multi-agent systems based on robust adaptive strategy'],[]
B Yan,3.0,['Distributed cooperative formation control for multi-agent systems based on robust adaptive strategy'],[]
C Wu,3.0,['Distributed cooperative formation control for multi-agent systems based on robust adaptive strategy'],[]
SW Lin,2.0,"['Distributed Actor-Critic Approach for Frequency Synchronization of Isolated AC Microgrids', 'Distributed Actor-Critic Approach for Frequency Synchronization of Isolated AC Microgrids']",['qwFjTH0AAAAJ']
CC Chu,2.0,"['Distributed Actor-Critic Approach for Frequency Synchronization of Isolated AC Microgrids', 'Distributed Actor-Critic Approach for Frequency Synchronization of Isolated AC Microgrids']",['RHOx02cAAAAJ']
J Li,2.0,"['Reinforcement Learning for Synchronization of Heterogeneous Multiagent Systems by Improved -Functions', 'Balancing Fairness and Efficiency in Energy Resource Allocations', 'Balancing Fairness and Efficiency in Energy Resource Allocations', 'To What Extent do Open-loop and Feedback Nash Equilibria Diverge in General-Sum Linear Quadratic Dynamic Games?', 'To What Extent do Open-loop and Feedback Nash Equilibria Diverge in General-Sum Linear Quadratic Dynamic Games?']","['jHwxA4oAAAAJ', 'V_M8l4IAAAAJ']"
H Shafieirad,2.0,"['On Meeting a Maximum Delay Constraint Using Reinforcement Learning in Wireless Networks', 'On Meeting a Maximum Delay Constraint Using Reinforcement Learning in Wireless Networks']",['8Q85_zQAAAAJ']
D Abel,2.0,"['Three Dogmas of Reinforcement Learning', 'Three Dogmas of Reinforcement Learning']",['lvBJlmwAAAAJ']
MK Ho,2.0,"['Three Dogmas of Reinforcement Learning', 'Three Dogmas of Reinforcement Learning']",['yK7yTiwAAAAJ']
A Harutyunyan,2.0,"['Three Dogmas of Reinforcement Learning', 'Three Dogmas of Reinforcement Learning']",['Pon8OksAAAAJ']
KY Yan,2.0,['AGI via Combining Logic with Deep Learning'],[]
B Jiang,2.0,"['Adaptive dynamic programming approach for Stackelberg game-based fault-tolerant control', 'Adaptive dynamic programming approach for Stackelberg game-based fault-tolerant control']",['FRXg54EAAAAJ']
H Kazemi,2.0,"['Intelligent Transportation Systems, Hybrid Electric Vehicles, Powertrain Control, Cooperative Adaptive Cruise Control, Model Predictive Control', 'Intelligent Transportation Systems, Hybrid Electric Vehicles, Powertrain Control, Cooperative Adaptive Cruise Control, Model Predictive Control']",['O2-z9TYAAAAJ']
P Poupart,2.0,"['Faster Policy Adaptation in Environments with Exogeneity: A State Augmentation Approach.', 'Faster Policy Adaptation in Environments with Exogeneity: A State Augmentation Approach.']",['KhAJWroAAAAJ']
S Das,2.0,"['Faster Policy Adaptation in Environments with Exogeneity: A State Augmentation Approach.', 'Faster Policy Adaptation in Environments with Exogeneity: A State Augmentation Approach.']",['HRSDO6IAAAAJ']
Y Geng,2.0,"['Faster Policy Adaptation in Environments with Exogeneity: A State Augmentation Approach.', 'Faster Policy Adaptation in Environments with Exogeneity: A State Augmentation Approach.']",['SbA3q80AAAAJ']
C Chi,2.0,"['Theory Embedded Learning', 'Theory Embedded Learning', 'Theory Embedded Learning A Universal Framework for Combining Theory With Learning']",['-BZtJogAAAAJ']
J Lü,2.0,"['Resilient Output Formation-Containment Tracking of Heterogeneous Multi-Agent Systems: A Learning-Based Framework using Dynamic Data', 'Resilient Output Formation-Containment Tracking of Heterogeneous Multi-Agent Systems: A Learning-Based Framework using Dynamic Data', 'Cooperative Fault-Tolerant Formation Tracking Control for Heterogeneous Air-Ground Systems Using a Learning-Based Method', 'Cooperative Fault-Tolerant Formation Tracking Control for Heterogeneous Air-Ground Systems Using a Learning-Based Method']",['mCjNN7kAAAAJ']
ME Duntz,2.0,['Counter autonomy defense for aerial autonomous systems'],[]
SE Alam,2.0,"['Communication-efficient allocation of multiple indivisible resources in a federated multi-agent system', 'Communication-efficient allocation of multiple indivisible resources in a federated multi-agent system']",['8PZoDZkAAAAJ']
D Shukla,2.0,"['Communication-efficient allocation of multiple indivisible resources in a federated multi-agent system', 'Communication-efficient allocation of multiple indivisible resources in a federated multi-agent system']",['KXHNQNwAAAAJ']
M Motoki,2.0,"['Balancing Fairness and Efficiency in Energy Resource Allocations', 'Balancing Fairness and Efficiency in Energy Resource Allocations']",['fOWhQ3AAAAAJ']
B Zhang,2.0,"['Balancing Fairness and Efficiency in Energy Resource Allocations', 'Balancing Fairness and Efficiency in Energy Resource Allocations']",['3svZOGAAAAAJ']
CF Tung,1.0,['Distributed Actor-Critic Approach for Frequency Synchronization of Isolated AC Microgrids'],[]
Y Guo,1.0,['Differential graphical game‐based multi‐agent tracking control using integral reinforcement learning'],[]
Q Sun,1.0,['Differential graphical game‐based multi‐agent tracking control using integral reinforcement learning'],[]
Y Wang,1.0,"['Differential graphical game‐based multi‐agent tracking control using integral reinforcement learning', 'Secure Control for Markov Jump Cyber–Physical Systems Subject to Malicious Attacks: A Resilient Hybrid Learning Scheme']",[]
Q Pan,1.0,['Differential graphical game‐based multi‐agent tracking control using integral reinforcement learning'],[]
P Zeman,1.0,['Assessing Policy Optimization agents using Algorithmic IQ test'],[]
Y Meng,1.0,['Adaptive dynamic programming approach for Stackelberg game-based fault-tolerant control'],[]
M Shein,1.0,['A spiking neural network of state transition probabilities in model-based reinforcement learning'],[]
Z Li,1.0,['Faster Policy Adaptation in Environments with Exogeneity: A State Augmentation Approach.'],[]
Z Chen,1.0,['Faster Policy Adaptation in Environments with Exogeneity: A State Augmentation Approach.'],[]
F Wang,1.0,['Model-Free Containment Control of Fully Heterogeneous Linear Multiagent Systems'],[]
A Cao,1.0,['Model-Free Containment Control of Fully Heterogeneous Linear Multiagent Systems'],[]
Z Liu,1.0,['Model-Free Containment Control of Fully Heterogeneous Linear Multiagent Systems'],[]
B Shi,1.0,['Jamming the Relay-Assisted Multi-User Wireless Communication System: A Zero-Sum Game Approach'],[]
H Shao,1.0,['Jamming the Relay-Assisted Multi-User Wireless Communication System: A Zero-Sum Game Approach'],[]
J Lin,1.0,['Jamming the Relay-Assisted Multi-User Wireless Communication System: A Zero-Sum Game Approach'],[]
S Zhao,1.0,['Jamming the Relay-Assisted Multi-User Wireless Communication System: A Zero-Sum Game Approach'],[]
X Jia,0,['Optimal Consensus Control for Continuous-time Multi-agent Systems via Actor-Critic Neural Networks'],[]
K Wolter,0,['Optimal Consensus Control for Continuous-time Multi-agent Systems via Actor-Critic Neural Networks'],[]
K Jiang,0,"['Safe Reinforcement Learning for Connected and Automated Vehicle Platooning', 'Safe Reinforcement Learning for Connected and Automated Vehicle Platooning']",['tCHMPX0AAAAJ']
Y Lu,0,"['Safe Reinforcement Learning for Connected and Automated Vehicle Platooning', 'Safe Reinforcement Learning for Connected and Automated Vehicle Platooning']",['_uFez_0AAAAJ']
R Su,0,['Safe Reinforcement Learning for Connected and Automated Vehicle Platooning'],[]
J Huang,0,"['Distributed Vibration Control of Large Flexible Satellite Solar Panel Via Reinforcement Learning', 'Joint routing and computation offloading based deep reinforcement learning for Flying Ad hoc Networks']",[]
X Liu,0,['Distributed Vibration Control of Large Flexible Satellite Solar Panel Via Reinforcement Learning'],[]
SHQ Li,0,"['General sum stochastic games with networked information flows', 'General sum stochastic games with networked information flows']",['yZhro2IAAAAJ']
LJ Ratliff,0,"['General sum stochastic games with networked information flows', 'General sum stochastic games with networked information flows']",['LVPkbeYAAAAJ']
P Kumar,0,"['General sum stochastic games with networked information flows', 'General sum stochastic games with networked information flows']",['mh6kznYAAAAJ']
D Yu,0,"['Integral-Reinforcement-Learning-Based Hierarchical Optimal Evolutionary Strategy for Continuous Action Social Dilemma Games', 'Integral-Reinforcement-Learning-Based Hierarchical Optimal Evolutionary Strategy for Continuous Action Social Dilemma Games']",['sxN3HdcAAAAJ']
L Fan,0,['Integral-Reinforcement-Learning-Based Hierarchical Optimal Evolutionary Strategy for Continuous Action Social Dilemma Games'],[]
Z Wang,0,['Integral-Reinforcement-Learning-Based Hierarchical Optimal Evolutionary Strategy for Continuous Action Social Dilemma Games'],[]
L Yuan,0,['Reinforcement Learning for Synchronization of Heterogeneous Multiagent Systems by Improved -Functions'],[]
W Cheng,0,['Reinforcement Learning for Synchronization of Heterogeneous Multiagent Systems by Improved -Functions'],[]
T Chai,0,['Reinforcement Learning for Synchronization of Heterogeneous Multiagent Systems by Improved -Functions'],[]
J Yan,0,"['Digital Twin-Driven Formation Control of ROVs: An Integral Reinforcement Learning-Based Solution', 'Digital Twin-Driven Formation Control of ROVs: An Integral Reinforcement Learning-Based Solution']",['HtjDQ1AAAAAJ']
X Yang,0,"['Digital Twin-Driven Formation Control of ROVs: An Integral Reinforcement Learning-Based Solution', 'Digital Twin-Driven Formation Control of ROVs: An Integral Reinforcement Learning-Based Solution']",['ISADH70AAAAJ']
C Chen,0,"['Digital Twin-Driven Formation Control of ROVs: An Integral Reinforcement Learning-Based Solution', 'Digital Twin-Driven Formation Control of ROVs: An Integral Reinforcement Learning-Based Solution']",['NGQrfUwAAAAJ']
T Zhang,0,['Digital Twin-Driven Formation Control of ROVs: An Integral Reinforcement Learning-Based Solution'],[]
C DONALD,0,"['Containment Control of Heterogeneous Systems with Non-Autonomous Leaders: A Distributed Optimal Model Reference Approach', 'Containment Control of Heterogeneous Systems with Non-Autonomous Leaders: A Distributed Optimal Model Reference Approach']",['fQC7bIoAAAAJ']
Y YONGLIANG,0,['Containment Control of Heterogeneous Systems with Non-Autonomous Leaders: A Distributed Optimal Model Reference Approach'],[]
S CHENG,0,['Containment Control of Heterogeneous Systems with Non-Autonomous Leaders: A Distributed Optimal Model Reference Approach'],[]
Y YIN,0,['Containment Control of Heterogeneous Systems with Non-Autonomous Leaders: A Distributed Optimal Model Reference Approach'],[]
P Olhager,0,['Robust Reinforcement Learning Control of a Furuta Pendulum'],[]
P Michailidis,0,"['Review and Evaluation of Multi-Agent Control Applications for Energy Management in Buildings.', 'Review and Evaluation of Multi-Agent Control Applications for Energy Management in Buildings.']",['E5RFom0AAAAJ']
I Michailidis,0,"['Review and Evaluation of Multi-Agent Control Applications for Energy Management in Buildings.', 'Review and Evaluation of Multi-Agent Control Applications for Energy Management in Buildings.']",['hUC2CC8AAAAJ']
D Bossens,0,"['Reinforcement learning with limited prior knowledge in long-term environments', 'Reinforcement learning with limited prior knowledge in long-term environments']",['w2feGIoAAAAJ']
V Sadhu,0,"['Real-Time Autonomic Decision Making Under Uncertain Environments for UAV-Based Search-And-Rescue Missions', 'Real-Time Autonomic Decision Making Under Uncertain Environments for UAV-Based Search-And-Rescue Missions']",['K5GcTPYAAAAJ']
D CIRINO,0,['State entropy maximization in POMDPs'],[]
A Hawbani,0,"['Joint routing and computation offloading based deep reinforcement learning for Flying Ad hoc Networks', 'Joint routing and computation offloading based deep reinforcement learning for Flying Ad hoc Networks']",['HZRx6AkAAAAJ']
L Zhao,0,"['Joint routing and computation offloading based deep reinforcement learning for Flying Ad hoc Networks', 'Joint routing and computation offloading based deep reinforcement learning for Flying Ad hoc Networks']",['7KlP2dIAAAAJ']
N Lin,0,['Joint routing and computation offloading based deep reinforcement learning for Flying Ad hoc Networks'],[]
H Tang,0,['Joint routing and computation offloading based deep reinforcement learning for Flying Ad hoc Networks'],[]
Y Guan,0,['Joint routing and computation offloading based deep reinforcement learning for Flying Ad hoc Networks'],[]
N Bougie,0,"['Efficient Reinforcement Learning through Improved Cognitive Capabilities.', 'Efficient Reinforcement Learning through Improved Cognitive Capabilities.']",['j_Kf-msAAAAJ']
손동원,0,['Multi-Contact Simulator and Reinforcement Learning for Screw Tightening Tasks'],[]
H Drias,0,"['Leveraging Transfer Learning with Federated DRL for Autonomous Vehicles Platooning', 'Leveraging Transfer Learning with Federated DRL for Autonomous Vehicles Platooning']",['KN10OEIAAAAJ']
B Brik,0,"['Leveraging Transfer Learning with Federated DRL for Autonomous Vehicles Platooning', 'Leveraging Transfer Learning with Federated DRL for Autonomous Vehicles Platooning']",['c3EPy9sAAAAJ']
MEA Ameur,0,['Leveraging Transfer Learning with Federated DRL for Autonomous Vehicles Platooning'],[]
R Wang,0,"['End-to-end network slicing design policy in 5G networks', 'End-to-end network slicing design policy in 5G networks']",['4FAm6I4AAAAJ']
W Yu,0,"['Adaptive Optimal Bipartite Consensus Control for Heterogeneous Multi-Agent Systems', 'Adaptive Optimal Bipartite Consensus Control for Heterogeneous Multi-Agent Systems']",['I7XxngUAAAAJ']
B Liang,0,['Adaptive Optimal Bipartite Consensus Control for Heterogeneous Multi-Agent Systems'],[]
Y Wei,0,['Adaptive Optimal Bipartite Consensus Control for Heterogeneous Multi-Agent Systems'],[]
K Suri,0,['Effects of Conservatism on Offline Learning'],[]
F Shkurti,0,['Effects of Conservatism on Offline Learning'],[]
Q Meng,0,['Robust optimal control law learning for heterogeneous rotorcraft formation involving unknown parameters'],[]
H Tian,0,['Robust optimal control law learning for heterogeneous rotorcraft formation involving unknown parameters'],[]
T Logemann,0,"['Explainability of power grid attack strategies learned by Deep Reinforcement Learning Agents', 'Explainability of power grid attack strategies learned by Deep Reinforcement Learning Agents']",['9TgFlZ0AAAAJ']
TD Kulkarni,0,"['Learning structured representations for perception and control', 'Learning structured representations for perception and control']",['rrPyvsgAAAAJ']
M Mazouchi,0,"['Data-Driven Solutions to Mixed Control: A Hamilton-Inequality-Driven Reinforcement Learning Approach', 'Data-Driven Solutions to Mixed Control: A Hamilton-Inequality-Driven Reinforcement Learning Approach']",['vpqGNf8AAAAJ']
H Modares,0,"['Data-Driven Solutions to Mixed Control: A Hamilton-Inequality-Driven Reinforcement Learning Approach', 'Data-Driven Solutions to Mixed Control: A Hamilton-Inequality-Driven Reinforcement Learning Approach']",['xhucCdUAAAAJ']
G Dubosarskii,0,"['Vehicle Networks: Statistical and Game Theoretic Approaches to Their Evaluation and Design', 'Vehicle Networks: Statistical and Game Theoretic Approaches to Their Evaluation and Design']",['7kRxVoIAAAAJ']
JH Park,0,"['Secure Control for Markov Jump Cyber–Physical Systems Subject to Malicious Attacks: A Resilient Hybrid Learning Scheme', 'Secure Control for Markov Jump Cyber–Physical Systems Subject to Malicious Attacks: A Resilient Hybrid Learning Scheme']",['t-3_zUQAAAAJ']
H Shen,0,['Secure Control for Markov Jump Cyber–Physical Systems Subject to Malicious Attacks: A Resilient Hybrid Learning Scheme'],[]
J Wu,0,['Secure Control for Markov Jump Cyber–Physical Systems Subject to Malicious Attacks: A Resilient Hybrid Learning Scheme'],[]
A Sundstrom,0,"['Securing Industrial Production from Sophisticated Cyberattacks.', 'Securing Industrial Production from Sophisticated Cyberattacks.']",['w7zKpOsAAAAJ']
DW Limoge,0,"['Securing Industrial Production from Sophisticated Cyberattacks.', 'Securing Industrial Production from Sophisticated Cyberattacks.']",['4Slqw1kAAAAJ']
V Pinskiy,0,['Securing Industrial Production from Sophisticated Cyberattacks.'],[]
M Putman,0,['Securing Industrial Production from Sophisticated Cyberattacks.'],[]
A Xiang,0,"['A Data-Based Adaptive Consensus Control Algorithm of Discrete-Time Multi-Agent Systems', 'A Data-Based Adaptive Consensus Control Algorithm of Discrete-Time Multi-Agent Systems']",['WSHo9YgAAAAJ']
T Khan Mohd,0,"['Multimodal Data Fusion Using Voice and Electromyography Data for Robotic Control', 'Multimodal Data Fusion Using Voice and Electromyography Data for Robotic Control']",['nh1Jx2kAAAAJ']
D Baumann,0,"['Fast and Resource-Efficient Control of Wireless Cyber-Physical Systems', 'Fast and Resource-Efficient Control of Wireless Cyber-Physical Systems']",['bJX8-CEAAAAJ']
Z Xu,0,"['Bioinspired Intelligent Control of Autonomous Robots with State Estimation', 'Bioinspired Intelligent Control of Autonomous Robots with State Estimation']",['hS8epm8AAAAJ']
M Finzi,0,"['Understanding and Incorporating Mathematical Inductive Biases in Neural Networks', 'Understanding and Incorporating Mathematical Inductive Biases in Neural Networks']",['ysMAhlwAAAAJ']
CY Chiu,0,"['To What Extent do Open-loop and Feedback Nash Equilibria Diverge in General-Sum Linear Quadratic Dynamic Games?', 'To What Extent do Open-loop and Feedback Nash Equilibria Diverge in General-Sum Linear Quadratic Dynamic Games?']",['cl9ModoAAAAJ']
M Bhatt,0,"['To What Extent do Open-loop and Feedback Nash Equilibria Diverge in General-Sum Linear Quadratic Dynamic Games?', 'To What Extent do Open-loop and Feedback Nash Equilibria Diverge in General-Sum Linear Quadratic Dynamic Games?']",['O9WQVAEAAAAJ']
N Mehr,0,"['To What Extent do Open-loop and Feedback Nash Equilibria Diverge in General-Sum Linear Quadratic Dynamic Games?', 'To What Extent do Open-loop and Feedback Nash Equilibria Diverge in General-Sum Linear Quadratic Dynamic Games?']",['oAlCitYAAAAJ']
W Li,0,"['Drone Swarm Robust Cooperative Formation Pursuit through Relative Positioning in a Location Denial Environment.', 'Drone Swarm Robust Cooperative Formation Pursuit through Relative Positioning in a Location Denial Environment.']",['BZhoy6AAAAAJ']
W Ma,0,['VARIABLE COUPLING CONTAINMENT CONTROL IN HETEROGENEOUS MULTI-AGENT SWITCHING TOPOLOGY BASED ON EVENT-TRIGGERED'],[]
O Francuski,0,['UČENJE USLOVLJAVANJEM UZ POŠTOVANJE SIGURNOSNIH MEHANIZAMA–STUDIJA SLUČAJA RADA UZ SAMO-MODIFIKACIJU'],[]
M Pavlić,0,['UČENJE USLOVLJAVANJEM UZ POŠTOVANJE SIGURNOSNIH MEHANIZAMA–STUDIJA SLUČAJA RADA UZ SIGURNOSNI PREKID'],[]
RNDM Malý,0,['Reinforcement Learning with Abstraction'],[]
ニコラスブーギー,0,['Efficient Reinforcement Learning through Improved Cognitive Capabilities (認知能力の改善による効率的な強化学習)'],[]
張邵瑀,0,['基於深度學習及遷移式學習之機器人操作平板電腦虛擬鍵盤的視覺與動作協調系統'],[]
温广辉， 杨涛， 周佳玲， 付俊杰， 徐磊,0,['强化学习与自适应动态规划: 从基础理论到多智能体系统中的应用进展综述'],[]
A García Belmonte,0,"[""Metode d'explicabilitat per Aprenentatge Per Reforç Multiagent en presència de comunicació""]",[]
A Teymur,0,['Řízení robotů pomocí stukturovaného hlubokého učení'],[]
