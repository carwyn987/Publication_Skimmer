position,title,result_id,link,snippet,publication_info_summary,publication_info_authors_0_name,publication_info_authors_0_link,publication_info_authors_0_serpapi_scholar_link,publication_info_authors_0_author_id,publication_info_authors_1_name,publication_info_authors_1_link,publication_info_authors_1_serpapi_scholar_link,publication_info_authors_1_author_id,publication_info_authors_2_name,publication_info_authors_2_link,publication_info_authors_2_serpapi_scholar_link,publication_info_authors_2_author_id,resources_0_title,resources_0_file_format,resources_0_link,inline_links_serpapi_cite_link,inline_links_cited_by_total,inline_links_cited_by_link,inline_links_cited_by_cites_id,inline_links_cited_by_serpapi_scholar_link,inline_links_related_pages_link,inline_links_serpapi_related_pages_link,inline_links_versions_total,inline_links_versions_link,inline_links_versions_cluster_id,inline_links_versions_serpapi_scholar_link,inline_links_cached_page_link,publication_info_authors_3_name,publication_info_authors_3_link,publication_info_authors_3_serpapi_scholar_link,publication_info_authors_3_author_id,type,publication_info_authors_4_name,publication_info_authors_4_link,publication_info_authors_4_serpapi_scholar_link,publication_info_authors_4_author_id,inline_links_html_version,resources_1_title,resources_1_link,publication_info_authors_5_name,publication_info_authors_5_link,publication_info_authors_5_serpapi_scholar_link,publication_info_authors_5_author_id,publication_info_authors_6_name,publication_info_authors_6_link,publication_info_authors_6_serpapi_scholar_link,publication_info_authors_6_author_id
0,Timetraveler: Reinforcement learning for temporal knowledge graph forecasting,lK34YvgFpH0J,https://arxiv.org/abs/2109.04101,"… Temporal knowledge graph (TKG) reasoning is a crucial task that has gained … reinforcement learning method for forecasting. Specifically, the agent travels on historical knowledge graph …","H Sun, J Zhong, Y Ma, Z Han, K He - arXiv preprint arXiv:2109.04101, 2021 - arxiv.org",Y Ma,https://scholar.google.com/citations?user=fj5DzgcAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=fj5DzgcAAAAJ&engine=google_scholar_author&hl=en,fj5DzgcAAAAJ,Z Han,https://scholar.google.com/citations?user=HMdgrwoAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=HMdgrwoAAAAJ&engine=google_scholar_author&hl=en,HMdgrwoAAAAJ,K He,https://scholar.google.com/citations?user=YTQnGJsAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=YTQnGJsAAAAJ&engine=google_scholar_author&hl=en,YTQnGJsAAAAJ,arxiv.org,PDF,https://arxiv.org/pdf/2109.04101,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=lK34YvgFpH0J,103.0,"https://scholar.google.com/scholar?cites=9053367715292032404&as_sdt=5,47&sciodt=0,47&hl=en&num=20",9053367715292032404,https://serpapi.com/search.json?as_sdt=5%2C47&cites=9053367715292032404&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:lK34YvgFpH0J:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,47",https://serpapi.com/search.json?as_sdt=0%2C47&engine=google_scholar&hl=en&num=20&q=related%3AlK34YvgFpH0J%3Ascholar.google.com%2F&start=0,5.0,"https://scholar.google.com/scholar?cluster=9053367715292032404&hl=en&num=20&as_sdt=0,47",9053367715292032404,https://serpapi.com/search.json?as_sdt=0%2C47&cluster=9053367715292032404&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:lK34YvgFpH0J:scholar.google.com/+%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,47",,,,,,,,,,,,,,,,,,,,
1,Safe reinforcement learning via curriculum induction,tfH9mMRQM3UJ,https://proceedings.neurips.cc/paper/2020/hash/8df6a65941e4c9da40a4fb899de65c55-Abstract.html,"… Safety is a major concern that prevents application of reinforcement learning (RL) [45] to many practical problems [16]. Among the RL safety notions studied in the literature [23], …","M Turchetta, A Kolobov, S Shah… - Advances in Neural …, 2020 - proceedings.neurips.cc",M Turchetta,https://scholar.google.com/citations?user=Em6KUq8AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=Em6KUq8AAAAJ&engine=google_scholar_author&hl=en,Em6KUq8AAAAJ,A Kolobov,https://scholar.google.com/citations?user=xEWgxBsAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=xEWgxBsAAAAJ&engine=google_scholar_author&hl=en,xEWgxBsAAAAJ,S Shah,https://scholar.google.com/citations?user=1PEHzesAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=1PEHzesAAAAJ&engine=google_scholar_author&hl=en,1PEHzesAAAAJ,neurips.cc,PDF,https://proceedings.neurips.cc/paper/2020/file/8df6a65941e4c9da40a4fb899de65c55-Paper.pdf,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=tfH9mMRQM3UJ,90.0,"https://scholar.google.com/scholar?cites=8445182531560403381&as_sdt=5,47&sciodt=0,47&hl=en&num=20",8445182531560403381,https://serpapi.com/search.json?as_sdt=5%2C47&cites=8445182531560403381&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:tfH9mMRQM3UJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,47",https://serpapi.com/search.json?as_sdt=0%2C47&engine=google_scholar&hl=en&num=20&q=related%3AtfH9mMRQM3UJ%3Ascholar.google.com%2F&start=0,9.0,"https://scholar.google.com/scholar?cluster=8445182531560403381&hl=en&num=20&as_sdt=0,47",8445182531560403381,https://serpapi.com/search.json?as_sdt=0%2C47&cluster=8445182531560403381&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:tfH9mMRQM3UJ:scholar.google.com/+%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,47",,,,,,,,,,,,,,,,,,,,
2,Interactive recommender system via knowledge graph-enhanced reinforcement learning,aVQ7jm2mwjgJ,https://dl.acm.org/doi/abs/10.1145/3397271.3401174,"… Knowledge Graph enhanced Q-learning framework for interactive Recommendation), a novel architecture that extends DQN… to-end deep reinforcement learning based framework KGQR …","S Zhou, X Dai, H Chen, W Zhang, K Ren… - Proceedings of the 43rd …, 2020 - dl.acm.org",X Dai,https://scholar.google.com/citations?user=X20p7l4AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=X20p7l4AAAAJ&engine=google_scholar_author&hl=en,X20p7l4AAAAJ,H Chen,https://scholar.google.com/citations?user=J_GWOJAAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=J_GWOJAAAAAJ&engine=google_scholar_author&hl=en,J_GWOJAAAAAJ,W Zhang,https://scholar.google.com/citations?user=Qzss0GEAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=Qzss0GEAAAAJ&engine=google_scholar_author&hl=en,Qzss0GEAAAAJ,arxiv.org,PDF,https://arxiv.org/pdf/2006.10389,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=aVQ7jm2mwjgJ,156.0,"https://scholar.google.com/scholar?cites=4090014401073730665&as_sdt=5,47&sciodt=0,47&hl=en&num=20",4090014401073730665,https://serpapi.com/search.json?as_sdt=5%2C47&cites=4090014401073730665&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:aVQ7jm2mwjgJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,47",https://serpapi.com/search.json?as_sdt=0%2C47&engine=google_scholar&hl=en&num=20&q=related%3AaVQ7jm2mwjgJ%3Ascholar.google.com%2F&start=0,4.0,"https://scholar.google.com/scholar?cluster=4090014401073730665&hl=en&num=20&as_sdt=0,47",4090014401073730665,https://serpapi.com/search.json?as_sdt=0%2C47&cluster=4090014401073730665&engine=google_scholar&hl=en&num=20,,K Ren,https://scholar.google.com/citations?user=USnQVWgAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=USnQVWgAAAAJ&engine=google_scholar_author&hl=en,USnQVWgAAAAJ,,,,,,,,,,,,,,,,
3,Deeppath: A reinforcement learning method for knowledge graph reasoning,ljqVj9Pm070J,https://arxiv.org/abs/1707.06690,"… 2016) is a more recent work on KG reasoning, which also applies reinforcement learning … our RL model tries to add new facts to knowledge graph (KG) by reasoning on existing KG …","W Xiong, T Hoang, WY Wang - arXiv preprint arXiv:1707.06690, 2017 - arxiv.org",W Xiong,https://scholar.google.com/citations?user=J9_LwQUAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=J9_LwQUAAAAJ&engine=google_scholar_author&hl=en,J9_LwQUAAAAJ,WY Wang,https://scholar.google.com/citations?user=gf8Ms_8AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=gf8Ms_8AAAAJ&engine=google_scholar_author&hl=en,gf8Ms_8AAAAJ,,,,,arxiv.org,PDF,https://arxiv.org/pdf/1707.06690,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=ljqVj9Pm070J,783.0,"https://scholar.google.com/scholar?cites=13678530289575738006&as_sdt=5,47&sciodt=0,47&hl=en&num=20",13678530289575738006,https://serpapi.com/search.json?as_sdt=5%2C47&cites=13678530289575738006&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:ljqVj9Pm070J:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,47",https://serpapi.com/search.json?as_sdt=0%2C47&engine=google_scholar&hl=en&num=20&q=related%3AljqVj9Pm070J%3Ascholar.google.com%2F&start=0,8.0,"https://scholar.google.com/scholar?cluster=13678530289575738006&hl=en&num=20&as_sdt=0,47",13678530289575738006,https://serpapi.com/search.json?as_sdt=0%2C47&cluster=13678530289575738006&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:ljqVj9Pm070J:scholar.google.com/+%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,47",,,,,,,,,,,,,,,,,,,,
4,Vulnerability of deep reinforcement learning to policy induction attacks,EGjzcPkrX40J,https://link.springer.com/chapter/10.1007/978-3-319-62416-7_19,"… establish that reinforcement learning techniques … DQN models. Furthermore, we present a novel class of attacks based on this vulnerability that enable policy manipulation and induction …","V Behzadan, A Munir - Machine Learning and Data Mining in Pattern …, 2017 - Springer",V Behzadan,https://scholar.google.com/citations?user=MYMANOYAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=MYMANOYAAAAJ&engine=google_scholar_author&hl=en,MYMANOYAAAAJ,A Munir,https://scholar.google.com/citations?user=-P9waaQAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=-P9waaQAAAAJ&engine=google_scholar_author&hl=en,-P9waaQAAAAJ,,,,,arxiv.org,PDF,https://arxiv.org/pdf/1701.04143,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=EGjzcPkrX40J,319.0,"https://scholar.google.com/scholar?cites=10186909232477202448&as_sdt=5,47&sciodt=0,47&hl=en&num=20",10186909232477202448,https://serpapi.com/search.json?as_sdt=5%2C47&cites=10186909232477202448&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:EGjzcPkrX40J:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,47",https://serpapi.com/search.json?as_sdt=0%2C47&engine=google_scholar&hl=en&num=20&q=related%3AEGjzcPkrX40J%3Ascholar.google.com%2F&start=0,6.0,"https://scholar.google.com/scholar?cluster=10186909232477202448&hl=en&num=20&as_sdt=0,47",10186909232477202448,https://serpapi.com/search.json?as_sdt=0%2C47&cluster=10186909232477202448&engine=google_scholar&hl=en&num=20,,,,,,,,,,,,,,,,,,,,,
5,Reasoning like human: Hierarchical reinforcement learning for knowledge graph reasoning,-1CnwyW_JpQJ,https://opus.lib.uts.edu.au/handle/10453/157768,… Reinforcement Learning framework to learn chains of reasoning from a Knowledge Graph … a hierarchy of two-level Reinforcement Learning policies for encoding historical information …,"G Wan, S Pan, C Gong, C Zhou… - … Joint Conference on …, 2021 - opus.lib.uts.edu.au",G Wan,https://scholar.google.com/citations?user=R-Wy9ksAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=R-Wy9ksAAAAJ&engine=google_scholar_author&hl=en,R-Wy9ksAAAAJ,S Pan,https://scholar.google.com/citations?user=frWRJN4AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=frWRJN4AAAAJ&engine=google_scholar_author&hl=en,frWRJN4AAAAJ,C Gong,https://scholar.google.com/citations?user=guttoBwAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=guttoBwAAAAJ&engine=google_scholar_author&hl=en,guttoBwAAAAJ,uts.edu.au,PDF,https://opus.lib.uts.edu.au/bitstream/10453/157768/2/0267.pdf,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=-1CnwyW_JpQJ,87.0,"https://scholar.google.com/scholar?cites=10675430135645556987&as_sdt=5,47&sciodt=0,47&hl=en&num=20",10675430135645556987,https://serpapi.com/search.json?as_sdt=5%2C47&cites=10675430135645556987&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:-1CnwyW_JpQJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,47",https://serpapi.com/search.json?as_sdt=0%2C47&engine=google_scholar&hl=en&num=20&q=related%3A-1CnwyW_JpQJ%3Ascholar.google.com%2F&start=0,8.0,"https://scholar.google.com/scholar?cluster=10675430135645556987&hl=en&num=20&as_sdt=0,47",10675430135645556987,https://serpapi.com/search.json?as_sdt=0%2C47&cluster=10675430135645556987&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:-1CnwyW_JpQJ:scholar.google.com/+%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,47",C Zhou,https://scholar.google.com/citations?user=4oBUWVEAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=4oBUWVEAAAAJ&engine=google_scholar_author&hl=en,4oBUWVEAAAAJ,,,,,,,,,,,,,,,,
6,KERL: A knowledge-guided reinforcement learning model for sequential recommendation,oF5KuB-PnlYJ,https://dl.acm.org/doi/abs/10.1145/3397271.3401134,"… To improve the predictive capacity, we adopt reinforcement learning (RL) for developing … of knowledge graph (KG), we propose a novel Knowledge-guidEd Reinforcement Learning …","P Wang, Y Fan, L Xia, WX Zhao, SZ Niu… - Proceedings of the 43rd …, 2020 - dl.acm.org",P Wang,https://scholar.google.com/citations?user=BEDKYxUAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=BEDKYxUAAAAJ&engine=google_scholar_author&hl=en,BEDKYxUAAAAJ,Y Fan,https://scholar.google.com/citations?user=IZ2kY8gAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=IZ2kY8gAAAAJ&engine=google_scholar_author&hl=en,IZ2kY8gAAAAJ,L Xia,https://scholar.google.com/citations?user=NRwerBAAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=NRwerBAAAAAJ&engine=google_scholar_author&hl=en,NRwerBAAAAAJ,google.com,PDF,https://drive.google.com/file/d/1An5YXDvQ1K0A1AwpJG-I4gTbIQ26gUDS/view,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=oF5KuB-PnlYJ,121.0,"https://scholar.google.com/scholar?cites=6241583499980725920&as_sdt=5,47&sciodt=0,47&hl=en&num=20",6241583499980725920,https://serpapi.com/search.json?as_sdt=5%2C47&cites=6241583499980725920&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:oF5KuB-PnlYJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,47",https://serpapi.com/search.json?as_sdt=0%2C47&engine=google_scholar&hl=en&num=20&q=related%3AoF5KuB-PnlYJ%3Ascholar.google.com%2F&start=0,3.0,"https://scholar.google.com/scholar?cluster=6241583499980725920&hl=en&num=20&as_sdt=0,47",6241583499980725920,https://serpapi.com/search.json?as_sdt=0%2C47&cluster=6241583499980725920&engine=google_scholar&hl=en&num=20,,WX Zhao,https://scholar.google.com/citations?user=JNhNacoAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=JNhNacoAAAAJ&engine=google_scholar_author&hl=en,JNhNacoAAAAJ,,,,,,,,,,,,,,,,
7,Hierarchical reinforcement learning for pedagogical policy induction,RSEzog4cASMJ,https://link.springer.com/chapter/10.1007/978-3-030-23204-7_45,"… , off-policy Gaussian Processes based Hierarchical Reinforcement Learning (HRL) framework to … a Deep Q-Network (DQN) induced policy and a random yet reasonable baseline policy. …","G Zhou, H Azizsoltani, MS Ausin, T Barnes… - … IL, USA, June 25-29, 2019 …, 2019 - Springer",H Azizsoltani,https://scholar.google.com/citations?user=njjeOtkAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=njjeOtkAAAAJ&engine=google_scholar_author&hl=en,njjeOtkAAAAJ,MS Ausin,https://scholar.google.com/citations?user=n7j70gsAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=n7j70gsAAAAJ&engine=google_scholar_author&hl=en,n7j70gsAAAAJ,T Barnes,https://scholar.google.com/citations?user=7rSs25YAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=7rSs25YAAAAJ&engine=google_scholar_author&hl=en,7rSs25YAAAAJ,nsf.gov,PDF,https://par.nsf.gov/servlets/purl/10136493,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=RSEzog4cASMJ,42.0,"https://scholar.google.com/scholar?cites=2522328115480568133&as_sdt=5,47&sciodt=0,47&hl=en&num=20",2522328115480568133,https://serpapi.com/search.json?as_sdt=5%2C47&cites=2522328115480568133&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:RSEzog4cASMJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,47",https://serpapi.com/search.json?as_sdt=0%2C47&engine=google_scholar&hl=en&num=20&q=related%3ARSEzog4cASMJ%3Ascholar.google.com%2F&start=0,6.0,"https://scholar.google.com/scholar?cluster=2522328115480568133&hl=en&num=20&as_sdt=0,47",2522328115480568133,https://serpapi.com/search.json?as_sdt=0%2C47&cluster=2522328115480568133&engine=google_scholar&hl=en&num=20,,,,,,,,,,,,,,,,,,,,,
8,Rule-aware reinforcement learning for knowledge graph reasoning,sdAnSBNZPUQJ,https://aclanthology.org/2021.findings-acl.412.pdf,Multi-hop reasoning is an effective and explainable approach to predicting missing facts in Knowledge Graphs (KGs). It usually adopts the Reinforcement Learning (RL) framework and …,"Z Hou, X Jin, Z Li, L Bai - Findings of the Association for …, 2021 - aclanthology.org",X Jin,https://scholar.google.com/citations?user=5TRLpyIAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=5TRLpyIAAAAJ&engine=google_scholar_author&hl=en,5TRLpyIAAAAJ,Z Li,https://scholar.google.com/citations?user=fibOdOkAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=fibOdOkAAAAJ&engine=google_scholar_author&hl=en,fibOdOkAAAAJ,L Bai,https://scholar.google.com/citations?user=Zrd9pCMAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=Zrd9pCMAAAAJ&engine=google_scholar_author&hl=en,Zrd9pCMAAAAJ,aclanthology.org,PDF,https://aclanthology.org/2021.findings-acl.412.pdf,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=sdAnSBNZPUQJ,21.0,"https://scholar.google.com/scholar?cites=4917184307508269233&as_sdt=5,47&sciodt=0,47&hl=en&num=20",4917184307508269233,https://serpapi.com/search.json?as_sdt=5%2C47&cites=4917184307508269233&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:sdAnSBNZPUQJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,47",https://serpapi.com/search.json?as_sdt=0%2C47&engine=google_scholar&hl=en&num=20&q=related%3AsdAnSBNZPUQJ%3Ascholar.google.com%2F&start=0,2.0,"https://scholar.google.com/scholar?cluster=4917184307508269233&hl=en&num=20&as_sdt=0,47",4917184307508269233,https://serpapi.com/search.json?as_sdt=0%2C47&cluster=4917184307508269233&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:sdAnSBNZPUQJ:scholar.google.com/+%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,47",,,,,Pdf,,,,,,,,,,,,,,,
9,GRL: Knowledge graph completion with GAN-based reinforcement learning,4mJwBc2tywMJ,https://www.sciencedirect.com/science/article/pii/S0950705120305505,"… knowledge graph are important factors for knowledge graph … based on GAN and reinforcement learning. We use WGAN to … NAS) to knowledge graph reasoning, and combine GAN and …","Q Wang, Y Ji, Y Hao, J Cao - Knowledge-Based Systems, 2020 - Elsevier",Y Ji,https://scholar.google.com/citations?user=1-GjVYgAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=1-GjVYgAAAAJ&engine=google_scholar_author&hl=en,1-GjVYgAAAAJ,Y Hao,https://scholar.google.com/citations?user=26lghIsAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=26lghIsAAAAJ&engine=google_scholar_author&hl=en,26lghIsAAAAJ,,,,,,,,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=4mJwBc2tywMJ,47.0,"https://scholar.google.com/scholar?cites=273503298457199330&as_sdt=5,47&sciodt=0,47&hl=en&num=20",273503298457199330,https://serpapi.com/search.json?as_sdt=5%2C47&cites=273503298457199330&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:4mJwBc2tywMJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,47",https://serpapi.com/search.json?as_sdt=0%2C47&engine=google_scholar&hl=en&num=20&q=related%3A4mJwBc2tywMJ%3Ascholar.google.com%2F&start=0,2.0,"https://scholar.google.com/scholar?cluster=273503298457199330&hl=en&num=20&as_sdt=0,47",273503298457199330,https://serpapi.com/search.json?as_sdt=0%2C47&cluster=273503298457199330&engine=google_scholar&hl=en&num=20,,,,,,,,,,,,,,,,,,,,,
10,Empirically evaluating the application of reinforcement learning to the induction of effective and adaptive pedagogical strategies,j2SW9XUOIVcJ,https://link.springer.com/article/10.1007/s11257-010-9093-1,… In this project we present a Reinforcement Learning (RL) approach for inducing effective pedagogical strategies and empirical evaluations of the induced strategies. This paper …,"M Chi, K VanLehn, D Litman, P Jordan - User Modeling and User-Adapted …, 2011 - Springer",M Chi,https://scholar.google.com/citations?user=gJmbChYAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=gJmbChYAAAAJ&engine=google_scholar_author&hl=en,gJmbChYAAAAJ,K VanLehn,https://scholar.google.com/citations?user=hjYT3JYAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=hjYT3JYAAAAJ&engine=google_scholar_author&hl=en,hjYT3JYAAAAJ,D Litman,https://scholar.google.com/citations?user=8MFFVgEAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=8MFFVgEAAAAJ&engine=google_scholar_author&hl=en,8MFFVgEAAAAJ,psu.edu,PDF,https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=e7a12907a5502ab31132adb41b73a5220cb26161,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=j2SW9XUOIVcJ,177.0,"https://scholar.google.com/scholar?cites=6278315255325418639&as_sdt=5,47&sciodt=0,47&hl=en&num=20",6278315255325418639,https://serpapi.com/search.json?as_sdt=5%2C47&cites=6278315255325418639&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:j2SW9XUOIVcJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,47",https://serpapi.com/search.json?as_sdt=0%2C47&engine=google_scholar&hl=en&num=20&q=related%3Aj2SW9XUOIVcJ%3Ascholar.google.com%2F&start=0,17.0,"https://scholar.google.com/scholar?cluster=6278315255325418639&hl=en&num=20&as_sdt=0,47",6278315255325418639,https://serpapi.com/search.json?as_sdt=0%2C47&cluster=6278315255325418639&engine=google_scholar&hl=en&num=20,,P Jordan,https://scholar.google.com/citations?user=TjVAlm4AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=TjVAlm4AAAAJ&engine=google_scholar_author&hl=en,TjVAlm4AAAAJ,,,,,,,,,,,,,,,,
11,Towards Self-X cognitive manufacturing network: An industrial knowledge graph-based multi-agent reinforcement learning approach,N60CGTD-jesJ,https://www.sciencedirect.com/science/article/pii/S0278612521001643,"… To pave its way, this work proposes an industrial knowledge graph (IKG)-based multi-agent reinforcement learning (MARL) approach to realizing the so-called Self-X cognitive …","P Zheng, L Xia, C Li, X Li, B Liu - Journal of Manufacturing Systems, 2021 - Elsevier",P Zheng,https://scholar.google.com/citations?user=gS7pL68AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=gS7pL68AAAAJ&engine=google_scholar_author&hl=en,gS7pL68AAAAJ,L Xia,https://scholar.google.com/citations?user=2v6JQ4cAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=2v6JQ4cAAAAJ&engine=google_scholar_author&hl=en,2v6JQ4cAAAAJ,C Li,https://scholar.google.com/citations?user=ePCpKKsAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=ePCpKKsAAAAJ&engine=google_scholar_author&hl=en,ePCpKKsAAAAJ,polyu.edu.hk,PDF,https://ira.lib.polyu.edu.hk/bitstream/10397/91590/1/Zheng_Towards_Self-X_Cognitive.pdf,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=N60CGTD-jesJ,121.0,"https://scholar.google.com/scholar?cites=16973502053160758583&as_sdt=5,47&sciodt=0,47&hl=en&num=20",16973502053160758583,https://serpapi.com/search.json?as_sdt=5%2C47&cites=16973502053160758583&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:N60CGTD-jesJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,47",https://serpapi.com/search.json?as_sdt=0%2C47&engine=google_scholar&hl=en&num=20&q=related%3AN60CGTD-jesJ%3Ascholar.google.com%2F&start=0,4.0,"https://scholar.google.com/scholar?cluster=16973502053160758583&hl=en&num=20&as_sdt=0,47",16973502053160758583,https://serpapi.com/search.json?as_sdt=0%2C47&cluster=16973502053160758583&engine=google_scholar&hl=en&num=20,,X Li,https://scholar.google.com/citations?user=01gHJ2YAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=01gHJ2YAAAAJ&engine=google_scholar_author&hl=en,01gHJ2YAAAAJ,,B Liu,https://scholar.google.com/citations?user=qBaUFbQAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=qBaUFbQAAAAJ&engine=google_scholar_author&hl=en,qBaUFbQAAAAJ,,,,,,,,,,,
12,ADRL: An attention-based deep reinforcement learning framework for knowledge graph reasoning,-akCk-MTXNIJ,https://www.sciencedirect.com/science/article/pii/S0950705120302525,"… We propose a new network architecture based on deep reinforcement learning for knowledge graph reasoning, which can improve the efficiency and interpretability of traditional …","Q Wang, Y Hao, J Cao - Knowledge-Based Systems, 2020 - Elsevier",Y Hao,https://scholar.google.com/citations?user=26lghIsAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=26lghIsAAAAJ&engine=google_scholar_author&hl=en,26lghIsAAAAJ,,,,,,,,,,,,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=-akCk-MTXNIJ,54.0,"https://scholar.google.com/scholar?cites=15158012313967176185&as_sdt=5,47&sciodt=0,47&hl=en&num=20",15158012313967176185,https://serpapi.com/search.json?as_sdt=5%2C47&cites=15158012313967176185&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:-akCk-MTXNIJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,47",https://serpapi.com/search.json?as_sdt=0%2C47&engine=google_scholar&hl=en&num=20&q=related%3A-akCk-MTXNIJ%3Ascholar.google.com%2F&start=0,,,,,,,,,,,,,,,,,,,,,,,,,
13,Causal Reinforcement Learning for Knowledge Graph Reasoning,fiZbLaFiAusJ,https://www.mdpi.com/2076-3417/14/6/2498,"… We introduce a new method combining causal inference and reinforcement learning that applies to knowledge graph reasoning. Specifically, the prior knowledge is integrated into the …","D Li, Y Lu, J Wu, W Zhou, G Zeng - Applied Sciences, 2024 - mdpi.com",,,,,,,,,,,,,mdpi.com,PDF,https://www.mdpi.com/2076-3417/14/6/2498/pdf,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=fiZbLaFiAusJ,1.0,"https://scholar.google.com/scholar?cites=16934205993256691326&as_sdt=5,47&sciodt=0,47&hl=en&num=20",16934205993256691326,https://serpapi.com/search.json?as_sdt=5%2C47&cites=16934205993256691326&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:fiZbLaFiAusJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,47",https://serpapi.com/search.json?as_sdt=0%2C47&engine=google_scholar&hl=en&num=20&q=related%3AfiZbLaFiAusJ%3Ascholar.google.com%2F&start=0,2.0,"https://scholar.google.com/scholar?cluster=16934205993256691326&hl=en&num=20&as_sdt=0,47",16934205993256691326,https://serpapi.com/search.json?as_sdt=0%2C47&cluster=16934205993256691326&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:fiZbLaFiAusJ:scholar.google.com/+%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,47",,,,,,,,,,,,,,,,,,,,
14,End-to-end reinforcement learning for automatic taxonomy induction,wUk2gqOq_m4J,https://arxiv.org/abs/1805.04044,… 3 Reinforcement Learning for End-to-End Taxonomy Induction We present the reinforcement learning (RL) approach to taxonomy induction in this section. The RL agent employs the …,"Y Mao, X Ren, J Shen, X Gu, J Han - arXiv preprint arXiv:1805.04044, 2018 - arxiv.org",Y Mao,https://scholar.google.com/citations?user=steJe6IAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=steJe6IAAAAJ&engine=google_scholar_author&hl=en,steJe6IAAAAJ,X Ren,https://scholar.google.com/citations?user=_moJlrIAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=_moJlrIAAAAJ&engine=google_scholar_author&hl=en,_moJlrIAAAAJ,J Shen,https://scholar.google.com/citations?user=-ZJ0sCoAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=-ZJ0sCoAAAAJ&engine=google_scholar_author&hl=en,-ZJ0sCoAAAAJ,arxiv.org,PDF,https://arxiv.org/pdf/1805.04044,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=wUk2gqOq_m4J,56.0,"https://scholar.google.com/scholar?cites=7998017607497566657&as_sdt=5,47&sciodt=0,47&hl=en&num=20",7998017607497566657,https://serpapi.com/search.json?as_sdt=5%2C47&cites=7998017607497566657&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:wUk2gqOq_m4J:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,47",https://serpapi.com/search.json?as_sdt=0%2C47&engine=google_scholar&hl=en&num=20&q=related%3AwUk2gqOq_m4J%3Ascholar.google.com%2F&start=0,5.0,"https://scholar.google.com/scholar?cluster=7998017607497566657&hl=en&num=20&as_sdt=0,47",7998017607497566657,https://serpapi.com/search.json?as_sdt=0%2C47&cluster=7998017607497566657&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:wUk2gqOq_m4J:scholar.google.com/+%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,47",X Gu,https://scholar.google.com/citations?user=YR4Lp0QAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=YR4Lp0QAAAAJ&engine=google_scholar_author&hl=en,YR4Lp0QAAAAJ,,J Han,https://scholar.google.com/citations?user=Kv9AbjMAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=Kv9AbjMAAAAJ&engine=google_scholar_author&hl=en,Kv9AbjMAAAAJ,,,,,,,,,,,
15,Path reasoning over knowledge graph: A multi-agent and reinforcement learning based method,7oLoHDlFE24J,https://ieeexplore.ieee.org/abstract/document/8637433/,"… (eg, knowledge graph completion and question answering). Recently, reinforcement learning has … To solve this problem, we propose a Multi-Agent and Reinforcement Learning based …","Z Li, X Jin, S Guan, Y Wang… - 2018 IEEE International …, 2018 - ieeexplore.ieee.org",Z Li,https://scholar.google.com/citations?user=fibOdOkAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=fibOdOkAAAAJ&engine=google_scholar_author&hl=en,fibOdOkAAAAJ,X Jin,https://scholar.google.com/citations?user=5TRLpyIAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=5TRLpyIAAAAJ&engine=google_scholar_author&hl=en,5TRLpyIAAAAJ,S Guan,https://scholar.google.com/citations?user=mS2QCewAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=mS2QCewAAAAJ&engine=google_scholar_author&hl=en,mS2QCewAAAAJ,researchgate.net,PDF,https://www.researchgate.net/profile/Saiping-Guan/publication/331042991_Path_Reasoning_over_Knowledge_Graph_A_Multi-agent_and_Reinforcement_Learning_Based_Method/links/5e674b2fa6fdcc37dd15e64c/Path-Reasoning-over-Knowledge-Graph-A-Multi-agent-and-Reinforcement-Learning-Based-Method.pdf,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=7oLoHDlFE24J,30.0,"https://scholar.google.com/scholar?cites=7931759480330027758&as_sdt=5,47&sciodt=0,47&hl=en&num=20",7931759480330027758,https://serpapi.com/search.json?as_sdt=5%2C47&cites=7931759480330027758&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:7oLoHDlFE24J:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,47",https://serpapi.com/search.json?as_sdt=0%2C47&engine=google_scholar&hl=en&num=20&q=related%3A7oLoHDlFE24J%3Ascholar.google.com%2F&start=0,3.0,"https://scholar.google.com/scholar?cluster=7931759480330027758&hl=en&num=20&as_sdt=0,47",7931759480330027758,https://serpapi.com/search.json?as_sdt=0%2C47&cluster=7931759480330027758&engine=google_scholar&hl=en&num=20,,Y Wang,https://scholar.google.com/citations?user=v1KzwYEAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=v1KzwYEAAAAJ&engine=google_scholar_author&hl=en,v1KzwYEAAAAJ,,,,,,,,,,,,,,,,
16,A Systematic Literature Review of reinforcement learning-based knowledge graph research,1vK96zW9c9IJ,https://www.sciencedirect.com/science/article/pii/S0957417423023825,… (“knowledge graph” … “knowledge graph completion”). There are many keywords that can represent RL methods. Our query strings about RL are defined as KEY2 (“reinforcement learning…,"Z Tang, T Li, D Wu, J Liu, Z Yang - Expert Systems with Applications, 2023 - Elsevier",Z Tang,https://scholar.google.com/citations?user=-n08_1YAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=-n08_1YAAAAJ&engine=google_scholar_author&hl=en,-n08_1YAAAAJ,D Wu,https://scholar.google.com/citations?user=iO7cEB0AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=iO7cEB0AAAAJ&engine=google_scholar_author&hl=en,iO7cEB0AAAAJ,,,,,sciencedirect.com,HTML,https://www.sciencedirect.com/science/article/pii/S0957417423023825,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=1vK96zW9c9IJ,3.0,"https://scholar.google.com/scholar?cites=15164672409572602582&as_sdt=5,47&sciodt=0,47&hl=en&num=20",15164672409572602582,https://serpapi.com/search.json?as_sdt=5%2C47&cites=15164672409572602582&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:1vK96zW9c9IJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,47",https://serpapi.com/search.json?as_sdt=0%2C47&engine=google_scholar&hl=en&num=20&q=related%3A1vK96zW9c9IJ%3Ascholar.google.com%2F&start=0,2.0,"https://scholar.google.com/scholar?cluster=15164672409572602582&hl=en&num=20&as_sdt=0,47",15164672409572602582,https://serpapi.com/search.json?as_sdt=0%2C47&cluster=15164672409572602582&engine=google_scholar&hl=en&num=20,,,,,,Html,,,,,https://www.sciencedirect.com/science/article/pii/S0957417423023825,,,,,,,,,,
17,Deep reinforcement learning with double q-learning,Fn1meBxKdgMJ,https://ojs.aaai.org/index.php/AAAI/article/view/10295,"… In this section, we analyze the overestimations of DQN and show that Double DQN improves over DQN both in terms of value accuracy and in terms of policy quality. To further test the …","H Van Hasselt, A Guez, D Silver - … of the AAAI conference on artificial …, 2016 - ojs.aaai.org",H Van Hasselt,https://scholar.google.com/citations?user=W80oBMkAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=W80oBMkAAAAJ&engine=google_scholar_author&hl=en,W80oBMkAAAAJ,A Guez,https://scholar.google.com/citations?user=iyD9aw8AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=iyD9aw8AAAAJ&engine=google_scholar_author&hl=en,iyD9aw8AAAAJ,D Silver,https://scholar.google.com/citations?user=-8DNE4UAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=-8DNE4UAAAAJ&engine=google_scholar_author&hl=en,-8DNE4UAAAAJ,aaai.org,PDF,https://ojs.aaai.org/index.php/AAAI/article/download/10295/10154,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=Fn1meBxKdgMJ,8926.0,"https://scholar.google.com/scholar?cites=249468315505163542&as_sdt=5,47&sciodt=0,47&hl=en&num=20",249468315505163542,https://serpapi.com/search.json?as_sdt=5%2C47&cites=249468315505163542&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:Fn1meBxKdgMJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,47",https://serpapi.com/search.json?as_sdt=0%2C47&engine=google_scholar&hl=en&num=20&q=related%3AFn1meBxKdgMJ%3Ascholar.google.com%2F&start=0,19.0,"https://scholar.google.com/scholar?cluster=249468315505163542&hl=en&num=20&as_sdt=0,47",249468315505163542,https://serpapi.com/search.json?as_sdt=0%2C47&cluster=249468315505163542&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:Fn1meBxKdgMJ:scholar.google.com/+%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,47",,,,,,,,,,,,,,,,,,,,
18,Explainable knowledge graph-based recommendation via deep reinforcement learning,X4LV0WKpdOUJ,https://www.researchgate.net/profile/Jian-Tang-46/publication/333993762_Explainable_Knowledge_Graph-based_Recommendation_via_Deep_Reinforcement_Learning/links/60728969a6fdcc5f779843f5/Explainable-Knowledge-Graph-based-Recommendation-via-Deep-Reinforcement-Learning.pdf,… entities’ embeddings from the knowledge graph are used to … Reinforcement Learning. Our work is also related to recent work on knowledge graph reasoning with reinforcement learning …,"W Song, Z Duan, Z Yang, H Zhu… - arXiv preprint arXiv …, 2019 - researchgate.net",W Song,https://scholar.google.com/citations?user=pppQSXgAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=pppQSXgAAAAJ&engine=google_scholar_author&hl=en,pppQSXgAAAAJ,Z Duan,https://scholar.google.com/citations?user=7pZHSbkAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=7pZHSbkAAAAJ&engine=google_scholar_author&hl=en,7pZHSbkAAAAJ,Z Yang,https://scholar.google.com/citations?user=AvfM2hsAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=AvfM2hsAAAAJ&engine=google_scholar_author&hl=en,AvfM2hsAAAAJ,researchgate.net,PDF,https://www.researchgate.net/profile/Jian-Tang-46/publication/333993762_Explainable_Knowledge_Graph-based_Recommendation_via_Deep_Reinforcement_Learning/links/60728969a6fdcc5f779843f5/Explainable-Knowledge-Graph-based-Recommendation-via-Deep-Reinforcement-Learning.pdf,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=X4LV0WKpdOUJ,49.0,"https://scholar.google.com/scholar?cites=16534026373876253279&as_sdt=5,47&sciodt=0,47&hl=en&num=20",16534026373876253279,https://serpapi.com/search.json?as_sdt=5%2C47&cites=16534026373876253279&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:X4LV0WKpdOUJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,47",https://serpapi.com/search.json?as_sdt=0%2C47&engine=google_scholar&hl=en&num=20&q=related%3AX4LV0WKpdOUJ%3Ascholar.google.com%2F&start=0,,,,,"https://scholar.googleusercontent.com/scholar?q=cache:X4LV0WKpdOUJ:scholar.google.com/+%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,47",,,,,Pdf,,,,,,,,,,,,,,,
19,DAPath: Distance-aware knowledge graph reasoning based on deep reinforcement learning,I7N6V5Ad-vkJ,https://www.sciencedirect.com/science/article/pii/S089360802030410X,… Knowledge graph reasoning aims to find reasoning paths for relations over incomplete … We propose the distance-aware reward in the reinforcement learning framework to assign …,"P Tiwari, H Zhu, HM Pandey - Neural Networks, 2021 - Elsevier",P Tiwari,https://scholar.google.com/citations?user=sDnmJ_YAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=sDnmJ_YAAAAJ&engine=google_scholar_author&hl=en,sDnmJ_YAAAAJ,H Zhu,https://scholar.google.com/citations?user=LXXoB3QAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=LXXoB3QAAAAJ&engine=google_scholar_author&hl=en,LXXoB3QAAAAJ,HM Pandey,https://scholar.google.com/citations?user=3iuT3pcAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=3iuT3pcAAAAJ&engine=google_scholar_author&hl=en,3iuT3pcAAAAJ,edgehill.ac.uk,PDF,https://research.edgehill.ac.uk/files/36603455/DAPath_Distance_Aware_Knowledge_Graph_Reasoning_Based_on_Deep_Reinforcement_Learning_1_.pdf,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=I7N6V5Ad-vkJ,53.0,"https://scholar.google.com/scholar?cites=18012742165401875235&as_sdt=5,47&sciodt=0,47&hl=en&num=20",18012742165401875235,https://serpapi.com/search.json?as_sdt=5%2C47&cites=18012742165401875235&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:I7N6V5Ad-vkJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,47",https://serpapi.com/search.json?as_sdt=0%2C47&engine=google_scholar&hl=en&num=20&q=related%3AI7N6V5Ad-vkJ%3Ascholar.google.com%2F&start=0,5.0,"https://scholar.google.com/scholar?cluster=18012742165401875235&hl=en&num=20&as_sdt=0,47",18012742165401875235,https://serpapi.com/search.json?as_sdt=0%2C47&cluster=18012742165401875235&engine=google_scholar&hl=en&num=20,,,,,,,,,,,,,,,,,,,,,
0,Rainbow: Combining improvements in deep reinforcement learning,xT2HM3SpPT8J,https://ojs.aaai.org/index.php/AAAI/article/view/11796,… reinforcement learning community has made several independent improvements to the DQN … This paper examines six extensions to the DQN algorithm and empirically studies their …,"M Hessel, J Modayil, H Van Hasselt, T Schaul… - Proceedings of the …, 2018 - ojs.aaai.org",M Hessel,https://scholar.google.com/citations?user=odVYodIAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=odVYodIAAAAJ&engine=google_scholar_author&hl=en,odVYodIAAAAJ,J Modayil,https://scholar.google.com/citations?user=G3pvUNEAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=G3pvUNEAAAAJ&engine=google_scholar_author&hl=en,G3pvUNEAAAAJ,H Van Hasselt,https://scholar.google.com/citations?user=W80oBMkAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=W80oBMkAAAAJ&engine=google_scholar_author&hl=en,W80oBMkAAAAJ,aaai.org,PDF,https://ojs.aaai.org/index.php/AAAI/article/download/11796/11655,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=xT2HM3SpPT8J,2545.0,"https://scholar.google.com/scholar?cites=4556984714514611653&as_sdt=5,34&sciodt=0,34&hl=en&num=20",4556984714514611653,https://serpapi.com/search.json?as_sdt=5%2C34&cites=4556984714514611653&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:xT2HM3SpPT8J:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,34",https://serpapi.com/search.json?as_sdt=0%2C34&engine=google_scholar&hl=en&num=20&q=related%3AxT2HM3SpPT8J%3Ascholar.google.com%2F&start=20,14.0,"https://scholar.google.com/scholar?cluster=4556984714514611653&hl=en&num=20&as_sdt=0,34",4556984714514611653,https://serpapi.com/search.json?as_sdt=0%2C34&cluster=4556984714514611653&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:xT2HM3SpPT8J:scholar.google.com/+%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,34",T Schaul,https://scholar.google.com/citations?user=vDimc-4AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=vDimc-4AAAAJ&engine=google_scholar_author&hl=en,vDimc-4AAAAJ,,,,,,,,,,,,,,,,
1,Reinforcement learning on graphs: A survey,iHxzfmdY_mYJ,https://ieeexplore.ieee.org/abstract/document/10121200/,"… work employing the research-rich Reinforcement Learning (RL) techniques to address graph … framework for multi-hop knowledge graph reasoning with reinforcement learning,” Knowl. …","M Nie, D Chen, D Wang - IEEE Transactions on Emerging …, 2023 - ieeexplore.ieee.org",M Nie,https://scholar.google.com/citations?user=LVij9VAAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=LVij9VAAAAAJ&engine=google_scholar_author&hl=en,LVij9VAAAAAJ,,,,,,,,,arxiv.org,PDF,https://arxiv.org/pdf/2204.06127.pdf?trk=public_post_comment-text,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=iHxzfmdY_mYJ,17.0,"https://scholar.google.com/scholar?cites=7421466437479529608&as_sdt=5,34&sciodt=0,34&hl=en&num=20",7421466437479529608,https://serpapi.com/search.json?as_sdt=5%2C34&cites=7421466437479529608&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:iHxzfmdY_mYJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,34",https://serpapi.com/search.json?as_sdt=0%2C34&engine=google_scholar&hl=en&num=20&q=related%3AiHxzfmdY_mYJ%3Ascholar.google.com%2F&start=20,3.0,"https://scholar.google.com/scholar?cluster=7421466437479529608&hl=en&num=20&as_sdt=0,34",7421466437479529608,https://serpapi.com/search.json?as_sdt=0%2C34&cluster=7421466437479529608&engine=google_scholar&hl=en&num=20,,,,,,,,,,,,,,,,,,,,,
2,Incremental mobile user profiling: Reinforcement learning with spatial knowledge graph for modeling event streams,tUmuJ4gBvkgJ,https://dl.acm.org/doi/abs/10.1145/3394486.3403128,"… of reinforcement learning and spatial knowledge graph for … the problem into a reinforcement learning task, where an … , thus, introduce a spatial Knowledge Graph (KG) to characterize the …","P Wang, K Liu, L Jiang, X Li, Y Fu - Proceedings of the 26th ACM …, 2020 - dl.acm.org",P Wang,https://scholar.google.com/citations?user=o26vQZwAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=o26vQZwAAAAJ&engine=google_scholar_author&hl=en,o26vQZwAAAAJ,K Liu,https://scholar.google.com/citations?user=wfF30KMAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=wfF30KMAAAAJ&engine=google_scholar_author&hl=en,wfF30KMAAAAJ,L Jiang,https://scholar.google.com/citations?user=vdV64dMAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=vdV64dMAAAAJ&engine=google_scholar_author&hl=en,vdV64dMAAAAJ,researchgate.net,PDF,https://www.researchgate.net/profile/Kunpeng-Liu-2/publication/343783148_Incremental_Mobile_User_Profiling_Reinforcement_Learning_with_Spatial_Knowledge_Graph_for_Modeling_Event_Streams/links/60c772194585157774d8c95e/Incremental-Mobile-User-Profiling-Reinforcement-Learning-with-Spatial-Knowledge-Graph-for-Modeling-Event-Streams.pdf,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=tUmuJ4gBvkgJ,72.0,"https://scholar.google.com/scholar?cites=5241628700598749621&as_sdt=5,34&sciodt=0,34&hl=en&num=20",5241628700598749621,https://serpapi.com/search.json?as_sdt=5%2C34&cites=5241628700598749621&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:tUmuJ4gBvkgJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,34",https://serpapi.com/search.json?as_sdt=0%2C34&engine=google_scholar&hl=en&num=20&q=related%3AtUmuJ4gBvkgJ%3Ascholar.google.com%2F&start=20,2.0,"https://scholar.google.com/scholar?cluster=5241628700598749621&hl=en&num=20&as_sdt=0,34",5241628700598749621,https://serpapi.com/search.json?as_sdt=0%2C34&cluster=5241628700598749621&engine=google_scholar&hl=en&num=20,,Y Fu,https://scholar.google.com/citations?user=OSArex4AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=OSArex4AAAAJ&engine=google_scholar_author&hl=en,OSArex4AAAAJ,,,,,,,,,,,,,,,,
3,Incorporating anticipation embedding into reinforcement learning framework for multi-hop knowledge graph question answering,a22K97sMGnwJ,https://www.sciencedirect.com/science/article/pii/S0020025522013317,"… a reinforcement learning method to handle knowledge graph … the unstructured text and knowledge graph to figure out open… , and leverages reinforcement learning to perform effective …","H Cui, T Peng, F Xiao, J Han, R Han, L Liu - Information Sciences, 2023 - Elsevier",J Han,https://scholar.google.com/citations?user=oJPqrtYAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=oJPqrtYAAAAJ&engine=google_scholar_author&hl=en,oJPqrtYAAAAJ,,,,,,,,,,,,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=a22K97sMGnwJ,23.0,"https://scholar.google.com/scholar?cites=8942474011549003115&as_sdt=5,34&sciodt=0,34&hl=en&num=20",8942474011549003115,https://serpapi.com/search.json?as_sdt=5%2C34&cites=8942474011549003115&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:a22K97sMGnwJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,34",https://serpapi.com/search.json?as_sdt=0%2C34&engine=google_scholar&hl=en&num=20&q=related%3Aa22K97sMGnwJ%3Ascholar.google.com%2F&start=20,2.0,"https://scholar.google.com/scholar?cluster=8942474011549003115&hl=en&num=20&as_sdt=0,34",8942474011549003115,https://serpapi.com/search.json?as_sdt=0%2C34&cluster=8942474011549003115&engine=google_scholar&hl=en&num=20,,,,,,,,,,,,,,,,,,,,,
4,Averaged-dqn: Variance reduction and stabilization for deep reinforcement learning,zRMzidpfnSYJ,http://proceedings.mlr.press/v70/anschel17a.html,"… Instability and variability of Deep Reinforcement Learning (DRL) algorithms tend to adversely affect their performance. Averaged-DQN is a simple extension to the DQN algorithm, …","O Anschel, N Baram, N Shimkin - … conference on machine …, 2017 - proceedings.mlr.press",O Anschel,https://scholar.google.com/citations?user=1ed1sPkAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=1ed1sPkAAAAJ&engine=google_scholar_author&hl=en,1ed1sPkAAAAJ,N Baram,https://scholar.google.com/citations?user=feU9M4QAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=feU9M4QAAAAJ&engine=google_scholar_author&hl=en,feU9M4QAAAAJ,N Shimkin,https://scholar.google.com/citations?user=YPptH48AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=YPptH48AAAAJ&engine=google_scholar_author&hl=en,YPptH48AAAAJ,mlr.press,PDF,http://proceedings.mlr.press/v70/anschel17a/anschel17a.pdf,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=zRMzidpfnSYJ,360.0,"https://scholar.google.com/scholar?cites=2782485536994169805&as_sdt=5,34&sciodt=0,34&hl=en&num=20",2782485536994169805,https://serpapi.com/search.json?as_sdt=5%2C34&cites=2782485536994169805&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:zRMzidpfnSYJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,34",https://serpapi.com/search.json?as_sdt=0%2C34&engine=google_scholar&hl=en&num=20&q=related%3AzRMzidpfnSYJ%3Ascholar.google.com%2F&start=20,8.0,"https://scholar.google.com/scholar?cluster=2782485536994169805&hl=en&num=20&as_sdt=0,34",2782485536994169805,https://serpapi.com/search.json?as_sdt=0%2C34&cluster=2782485536994169805&engine=google_scholar&hl=en&num=20,"http://scholar.googleusercontent.com/scholar?q=cache:zRMzidpfnSYJ:scholar.google.com/+%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,34",,,,,,,,,,,,,,,,,,,,
5,Deep reinforcement learning for dynamic multichannel access in wireless networks,ge1z3XZEMewJ,https://ieeexplore.ieee.org/abstract/document/8303773/,… apply the concept of reinforcement learning and implement a deep Q-network (DQN). We first … system dynamics and show through simulations that DQN can achieve the same optimal …,"S Wang, H Liu, PH Gomes… - IEEE Transactions on …, 2018 - ieeexplore.ieee.org",S Wang,https://scholar.google.com/citations?user=Bnv_t0sAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=Bnv_t0sAAAAJ&engine=google_scholar_author&hl=en,Bnv_t0sAAAAJ,H Liu,https://scholar.google.com/citations?user=9xkIAQcAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=9xkIAQcAAAAJ&engine=google_scholar_author&hl=en,9xkIAQcAAAAJ,PH Gomes,https://scholar.google.com/citations?user=SqtVOKUAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=SqtVOKUAAAAJ&engine=google_scholar_author&hl=en,SqtVOKUAAAAJ,ieee.org,PDF,https://ieeexplore.ieee.org/ielaam/6687307/8388569/8303773-aam.pdf,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=ge1z3XZEMewJ,460.0,"https://scholar.google.com/scholar?cites=17019459744122006913&as_sdt=5,34&sciodt=0,34&hl=en&num=20",17019459744122006913,https://serpapi.com/search.json?as_sdt=5%2C34&cites=17019459744122006913&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:ge1z3XZEMewJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,34",https://serpapi.com/search.json?as_sdt=0%2C34&engine=google_scholar&hl=en&num=20&q=related%3Age1z3XZEMewJ%3Ascholar.google.com%2F&start=20,7.0,"https://scholar.google.com/scholar?cluster=17019459744122006913&hl=en&num=20&as_sdt=0,34",17019459744122006913,https://serpapi.com/search.json?as_sdt=0%2C34&cluster=17019459744122006913&engine=google_scholar&hl=en&num=20,,,,,,,,,,,,,,,,,,,,,
6,Incorporating graph attention mechanism into knowledge graph reasoning based on deep reinforcement learning,PUoIaVyvxOkJ,https://aclanthology.org/D19-1264/,"… Knowledge Graph (KG) reasoning aims at finding reasoning paths for relations, in order to … In this paper, we present a deep reinforcement learning based model named by AttnPath, …","H Wang, S Li, R Pan, M Mao - … of the 2019 conference on empirical …, 2019 - aclanthology.org",H Wang,https://scholar.google.com/citations?user=N2sQnbMAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=N2sQnbMAAAAJ&engine=google_scholar_author&hl=en,N2sQnbMAAAAJ,S Li,https://scholar.google.com/citations?user=LQITVaEAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=LQITVaEAAAAJ&engine=google_scholar_author&hl=en,LQITVaEAAAAJ,R Pan,https://scholar.google.com/citations?user=OIJ8_gIAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=OIJ8_gIAAAAJ&engine=google_scholar_author&hl=en,OIJ8_gIAAAAJ,aclanthology.org,PDF,https://aclanthology.org/D19-1264.pdf,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=PUoIaVyvxOkJ,57.0,"https://scholar.google.com/scholar?cites=16844781317706500669&as_sdt=5,34&sciodt=0,34&hl=en&num=20",16844781317706500669,https://serpapi.com/search.json?as_sdt=5%2C34&cites=16844781317706500669&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:PUoIaVyvxOkJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,34",https://serpapi.com/search.json?as_sdt=0%2C34&engine=google_scholar&hl=en&num=20&q=related%3APUoIaVyvxOkJ%3Ascholar.google.com%2F&start=20,2.0,"https://scholar.google.com/scholar?cluster=16844781317706500669&hl=en&num=20&as_sdt=0,34",16844781317706500669,https://serpapi.com/search.json?as_sdt=0%2C34&cluster=16844781317706500669&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:PUoIaVyvxOkJ:scholar.google.com/+%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,34",,,,,,,,,,,,,,,,,,,,
7,Reinforcement Learning Approach for Integrating Compressed Contexts into Knowledge Graphs,CulTgEqsLGMJ,https://arxiv.org/abs/2404.12587,… Leveraging reinforcement learning through the application of DQN marks a progression … The continuous evolution of reinforcement learning strategies for knowledge graph integration …,"N Quach, Q Wang, Z Gao, Q Sun, B Guan… - arXiv preprint arXiv …, 2024 - arxiv.org",,,,,,,,,,,,,arxiv.org,PDF,https://arxiv.org/pdf/2404.12587,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=CulTgEqsLGMJ,1.0,"https://scholar.google.com/scholar?cites=7146276144710674698&as_sdt=5,34&sciodt=0,34&hl=en&num=20",7146276144710674698,https://serpapi.com/search.json?as_sdt=5%2C34&cites=7146276144710674698&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:CulTgEqsLGMJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,34",https://serpapi.com/search.json?as_sdt=0%2C34&engine=google_scholar&hl=en&num=20&q=related%3ACulTgEqsLGMJ%3Ascholar.google.com%2F&start=20,2.0,"https://scholar.google.com/scholar?cluster=7146276144710674698&hl=en&num=20&as_sdt=0,34",7146276144710674698,https://serpapi.com/search.json?as_sdt=0%2C34&cluster=7146276144710674698&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:CulTgEqsLGMJ:scholar.google.com/+%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,34",,,,,,,,,,,,,,,,,,,,
8,Multi‐robot path planning based on a deep reinforcement learning DQN algorithm,6x_TgXJ81i4J,https://ietresearch.onlinelibrary.wiley.com/doi/abs/10.1049/trit.2020.0024,"… (DQN) algorithm in a deep reinforcement learning algorithm, … -learning algorithm in deep reinforcement learning is to address … DQN algorithm. Simulation results show that the improved …","Y Yang, L Juntao, P Lingling - CAAI Transactions on …, 2020 - Wiley Online Library",,,,,,,,,,,,,wiley.com,PDF,https://ietresearch.onlinelibrary.wiley.com/doi/pdfdirect/10.1049/trit.2020.0024?crawler=true&mimetype=application,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=6x_TgXJ81i4J,155.0,"https://scholar.google.com/scholar?cites=3375021802006978539&as_sdt=5,34&sciodt=0,34&hl=en&num=20",3375021802006978539,https://serpapi.com/search.json?as_sdt=5%2C34&cites=3375021802006978539&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:6x_TgXJ81i4J:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,34",https://serpapi.com/search.json?as_sdt=0%2C34&engine=google_scholar&hl=en&num=20&q=related%3A6x_TgXJ81i4J%3Ascholar.google.com%2F&start=20,6.0,"https://scholar.google.com/scholar?cluster=3375021802006978539&hl=en&num=20&as_sdt=0,34",3375021802006978539,https://serpapi.com/search.json?as_sdt=0%2C34&cluster=3375021802006978539&engine=google_scholar&hl=en&num=20,,,,,,,,,,,,Full View,"https://scholar.google.com/scholar?output=instlink&q=info:6x_TgXJ81i4J:scholar.google.com/&hl=en&num=20&as_sdt=0,34&scillfp=9335667215114289064&oi=lle",,,,,,,,
9,Reinforcement learning-based knowledge graph reasoning for aluminum alloy applications,YxGjFWJFPuwJ,https://www.sciencedirect.com/science/article/pii/S0927025623000691,"… we propose a knowledge graph reasoning algorithm based on reinforcement learning using … of sparse reward in the traditional reinforcement learning-based reasoning algorithm, in …","J Liu, Q Qian - Computational Materials Science, 2023 - Elsevier",Q Qian,https://scholar.google.com/citations?user=U3FJ0TQAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=U3FJ0TQAAAAJ&engine=google_scholar_author&hl=en,U3FJ0TQAAAAJ,,,,,,,,,,,,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=YxGjFWJFPuwJ,3.0,"https://scholar.google.com/scholar?cites=17023119929079173475&as_sdt=5,34&sciodt=0,34&hl=en&num=20",17023119929079173475,https://serpapi.com/search.json?as_sdt=5%2C34&cites=17023119929079173475&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:YxGjFWJFPuwJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,34",https://serpapi.com/search.json?as_sdt=0%2C34&engine=google_scholar&hl=en&num=20&q=related%3AYxGjFWJFPuwJ%3Ascholar.google.com%2F&start=20,,,,,,,,,,,,,,,,,,,,,,,,,
10,Leveraging deep reinforcement learning for pedagogical policy induction in an intelligent tutoring system,JnZMmGVzliEJ,https://par.nsf.gov/biblio/10136494,"… the DQN and Double-DQN … DQN policy, although better than Double-DQN, was no better than a random policy. However, when combining DQN with the inferred rewards, our best DQN …","MS Ausin - In: Proceedings of the 12th International Conference on …, 2019 - par.nsf.gov",MS Ausin,https://scholar.google.com/citations?user=n7j70gsAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=n7j70gsAAAAJ&engine=google_scholar_author&hl=en,n7j70gsAAAAJ,,,,,,,,,nsf.gov,PDF,https://par.nsf.gov/servlets/purl/10136494,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=JnZMmGVzliEJ,33.0,"https://scholar.google.com/scholar?cites=2420248729942259238&as_sdt=5,34&sciodt=0,34&hl=en&num=20",2420248729942259238,https://serpapi.com/search.json?as_sdt=5%2C34&cites=2420248729942259238&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:JnZMmGVzliEJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,34",https://serpapi.com/search.json?as_sdt=0%2C34&engine=google_scholar&hl=en&num=20&q=related%3AJnZMmGVzliEJ%3Ascholar.google.com%2F&start=20,2.0,"https://scholar.google.com/scholar?cluster=2420248729942259238&hl=en&num=20&as_sdt=0,34",2420248729942259238,https://serpapi.com/search.json?as_sdt=0%2C34&cluster=2420248729942259238&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:JnZMmGVzliEJ:scholar.google.com/+%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,34",,,,,,,,,,,,,,,,,,,,
11,Induction and exploitation of subgoal automata for reinforcement learning,nYcQax7reXUJ,http://www.jair.org/index.php/jair/article/view/12372,"… reinforcement learning and automaton learning. Firstly, we explain two reinforcement learning … Secondly, we explain how reinforcement learning and automaton learning are interleaved …","D Furelos-Blanco, M Law, A Jonsson, K Broda… - Journal of Artificial …, 2021 - jair.org",D Furelos-Blanco,https://scholar.google.com/citations?user=IfMKjBgAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=IfMKjBgAAAAJ&engine=google_scholar_author&hl=en,IfMKjBgAAAAJ,M Law,https://scholar.google.com/citations?user=A5JWIs0AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=A5JWIs0AAAAJ&engine=google_scholar_author&hl=en,A5JWIs0AAAAJ,A Jonsson,https://scholar.google.com/citations?user=SI_uHCIAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=SI_uHCIAAAAJ&engine=google_scholar_author&hl=en,SI_uHCIAAAAJ,jair.org,PDF,https://www.jair.org/index.php/jair/article/download/12372/26668,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=nYcQax7reXUJ,35.0,"https://scholar.google.com/scholar?cites=8465055490497349533&as_sdt=5,34&sciodt=0,34&hl=en&num=20",8465055490497349533,https://serpapi.com/search.json?as_sdt=5%2C34&cites=8465055490497349533&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:nYcQax7reXUJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,34",https://serpapi.com/search.json?as_sdt=0%2C34&engine=google_scholar&hl=en&num=20&q=related%3AnYcQax7reXUJ%3Ascholar.google.com%2F&start=20,12.0,"https://scholar.google.com/scholar?cluster=8465055490497349533&hl=en&num=20&as_sdt=0,34",8465055490497349533,https://serpapi.com/search.json?as_sdt=0%2C34&cluster=8465055490497349533&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:nYcQax7reXUJ:scholar.google.com/+%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,34",,,,,,,,,,,Full View,"https://scholar.google.com/scholar?output=instlink&q=info:nYcQax7reXUJ:scholar.google.com/&hl=en&num=20&as_sdt=0,34&scillfp=9872157263205223974&oi=lle",,,,,,,,
12,A spatially explicit reinforcement learning model for geographic knowledge graph summarization,jEfjWngGlbsJ,https://onlinelibrary.wiley.com/doi/abs/10.1111/tgis.12547,"… The reward function plays an important role in guiding the agent to summarize the geographic knowledge graph, as the goal of our reinforcement learning model is to find an optimal …","B Yan, K Janowicz, G Mai, R Zhu - Transactions in GIS, 2019 - Wiley Online Library",B Yan,https://scholar.google.com/citations?user=lL_-M7IAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=lL_-M7IAAAAJ&engine=google_scholar_author&hl=en,lL_-M7IAAAAJ,K Janowicz,https://scholar.google.com/citations?user=6B2Z9vAAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=6B2Z9vAAAAAJ&engine=google_scholar_author&hl=en,6B2Z9vAAAAAJ,G Mai,https://scholar.google.com/citations?user=X2Wfl1UAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=X2Wfl1UAAAAJ&engine=google_scholar_author&hl=en,X2Wfl1UAAAAJ,semanticscholar.org,PDF,https://pdfs.semanticscholar.org/e2ff/9c72d55c4fef8ca3cc6b84a6f5f1c22be485.pdf,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=jEfjWngGlbsJ,44.0,"https://scholar.google.com/scholar?cites=13516716970613098380&as_sdt=5,34&sciodt=0,34&hl=en&num=20",13516716970613098380,https://serpapi.com/search.json?as_sdt=5%2C34&cites=13516716970613098380&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:jEfjWngGlbsJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,34",https://serpapi.com/search.json?as_sdt=0%2C34&engine=google_scholar&hl=en&num=20&q=related%3AjEfjWngGlbsJ%3Ascholar.google.com%2F&start=20,6.0,"https://scholar.google.com/scholar?cluster=13516716970613098380&hl=en&num=20&as_sdt=0,34",13516716970613098380,https://serpapi.com/search.json?as_sdt=0%2C34&cluster=13516716970613098380&engine=google_scholar&hl=en&num=20,,R Zhu,https://scholar.google.com/citations?user=7ZN8prIAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=7ZN8prIAAAAJ&engine=google_scholar_author&hl=en,7ZN8prIAAAAJ,,,,,,,,,,,,,,,,
13,An optimistic perspective on offline reinforcement learning,b5u6U1HTwwIJ,https://proceedings.mlr.press/v119/agarwal20c,… Off-policy reinforcement learning (RL) using a fixed offline dataset of logged interactions is … using the DQN Replay Dataset comprising the entire replay experience of a DQN agent on 60 …,"R Agarwal, D Schuurmans… - … Conference on Machine …, 2020 - proceedings.mlr.press",R Agarwal,https://scholar.google.com/citations?user=aH8AJu4AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=aH8AJu4AAAAJ&engine=google_scholar_author&hl=en,aH8AJu4AAAAJ,D Schuurmans,https://scholar.google.com/citations?user=xaQuPloAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=xaQuPloAAAAJ&engine=google_scholar_author&hl=en,xaQuPloAAAAJ,,,,,mlr.press,PDF,http://proceedings.mlr.press/v119/agarwal20c/agarwal20c.pdf,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=b5u6U1HTwwIJ,535.0,"https://scholar.google.com/scholar?cites=199235154784983919&as_sdt=5,34&sciodt=0,34&hl=en&num=20",199235154784983919,https://serpapi.com/search.json?as_sdt=5%2C34&cites=199235154784983919&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:b5u6U1HTwwIJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,34",https://serpapi.com/search.json?as_sdt=0%2C34&engine=google_scholar&hl=en&num=20&q=related%3Ab5u6U1HTwwIJ%3Ascholar.google.com%2F&start=20,7.0,"https://scholar.google.com/scholar?cluster=199235154784983919&hl=en&num=20&as_sdt=0,34",199235154784983919,https://serpapi.com/search.json?as_sdt=0%2C34&cluster=199235154784983919&engine=google_scholar&hl=en&num=20,"http://scholar.googleusercontent.com/scholar?q=cache:b5u6U1HTwwIJ:scholar.google.com/+%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,34",,,,,,,,,,,,,,,,,,,,
14,Deep reinforcement learning: An overview,1pKivau298wJ,https://arxiv.org/abs/1701.07274,"… and reinforcement learning. Next we discuss core RL elements, including value function, in particular, Deep Q-Network (DQN… This is the first overview about deep reinforcement learning …","Y Li - arXiv preprint arXiv:1701.07274, 2017 - arxiv.org",,,,,,,,,,,,,arxiv.org,PDF,https://arxiv.org/pdf/1701.07274.pdf?source=post_page---------------------------,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=1pKivau298wJ,1738.0,"https://scholar.google.com/scholar?cites=14769474351722042070&as_sdt=5,34&sciodt=0,34&hl=en&num=20",14769474351722042070,https://serpapi.com/search.json?as_sdt=5%2C34&cites=14769474351722042070&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:1pKivau298wJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,34",https://serpapi.com/search.json?as_sdt=0%2C34&engine=google_scholar&hl=en&num=20&q=related%3A1pKivau298wJ%3Ascholar.google.com%2F&start=20,5.0,"https://scholar.google.com/scholar?cluster=14769474351722042070&hl=en&num=20&as_sdt=0,34",14769474351722042070,https://serpapi.com/search.json?as_sdt=0%2C34&cluster=14769474351722042070&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:1pKivau298wJ:scholar.google.com/+%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,34",,,,,,,,,,,,,,,,,,,,
15,Dream: Adaptive reinforcement learning based on attention mechanism for temporal knowledge graph reasoning,IAEKVRiqqJ0J,https://dl.acm.org/doi/abs/10.1145/3539618.3591671,"… As reinforcement learning (RL) for multi-hop reasoning on traditional knowledge graphs … To overcome these challenges, we propose an adaptive reinforcement learning model based …","S Zheng, H Yin, T Chen, QVH Nguyen… - Proceedings of the 46th …, 2023 - dl.acm.org",H Yin,https://scholar.google.com/citations?user=JJsBmhYAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=JJsBmhYAAAAJ&engine=google_scholar_author&hl=en,JJsBmhYAAAAJ,T Chen,https://scholar.google.com/citations?user=07cqSMsAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=07cqSMsAAAAJ&engine=google_scholar_author&hl=en,07cqSMsAAAAJ,QVH Nguyen,https://scholar.google.com/citations?user=ntkO_bEAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=ntkO_bEAAAAJ&engine=google_scholar_author&hl=en,ntkO_bEAAAAJ,arxiv.org,PDF,https://arxiv.org/pdf/2304.03984,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=IAEKVRiqqJ0J,9.0,"https://scholar.google.com/scholar?cites=11360517081524732192&as_sdt=5,34&sciodt=0,34&hl=en&num=20",11360517081524732192,https://serpapi.com/search.json?as_sdt=5%2C34&cites=11360517081524732192&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:IAEKVRiqqJ0J:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,34",https://serpapi.com/search.json?as_sdt=0%2C34&engine=google_scholar&hl=en&num=20&q=related%3AIAEKVRiqqJ0J%3Ascholar.google.com%2F&start=20,4.0,"https://scholar.google.com/scholar?cluster=11360517081524732192&hl=en&num=20&as_sdt=0,34",11360517081524732192,https://serpapi.com/search.json?as_sdt=0%2C34&cluster=11360517081524732192&engine=google_scholar&hl=en&num=20,,,,,,,,,,,,,,,,,,,,,
16,Transfer in deep reinforcement learning using knowledge graphs,g9cBas602LYJ,https://arxiv.org/abs/1908.06556,… In this section we consider the problem of transferring a knowledge graph from a static text resource to a DQN—which we refer to as seeding. KG-DQN uses a knowledge graph as a …,"P Ammanabrolu, MO Riedl - arXiv preprint arXiv:1908.06556, 2019 - arxiv.org",P Ammanabrolu,https://scholar.google.com/citations?user=2yaiWZ8AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=2yaiWZ8AAAAJ&engine=google_scholar_author&hl=en,2yaiWZ8AAAAJ,MO Riedl,https://scholar.google.com/citations?user=Yg_QjxcAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=Yg_QjxcAAAAJ&engine=google_scholar_author&hl=en,Yg_QjxcAAAAJ,,,,,arxiv.org,PDF,https://arxiv.org/pdf/1908.06556,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=g9cBas602LYJ,37.0,"https://scholar.google.com/scholar?cites=13175479508507154307&as_sdt=5,34&sciodt=0,34&hl=en&num=20",13175479508507154307,https://serpapi.com/search.json?as_sdt=5%2C34&cites=13175479508507154307&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:g9cBas602LYJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,34",https://serpapi.com/search.json?as_sdt=0%2C34&engine=google_scholar&hl=en&num=20&q=related%3Ag9cBas602LYJ%3Ascholar.google.com%2F&start=20,4.0,"https://scholar.google.com/scholar?cluster=13175479508507154307&hl=en&num=20&as_sdt=0,34",13175479508507154307,https://serpapi.com/search.json?as_sdt=0%2C34&cluster=13175479508507154307&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:g9cBas602LYJ:scholar.google.com/+%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,34",,,,,,,,,,,,,,,,,,,,
17,Path-based multi-hop reasoning over knowledge graph for answering questions via adversarial reinforcement learning,lMcpoV1FVgkJ,https://www.sciencedirect.com/science/article/pii/S0950705123005105,"… Multi-hop knowledge graph question answering targets at … Specifically, with the advances of deep reinforcement learning … method based on adversarial reinforcement learning for multi-…","H Cui, T Peng, R Han, J Han, L Liu - Knowledge-Based Systems, 2023 - Elsevier",J Han,https://scholar.google.com/citations?user=oJPqrtYAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=oJPqrtYAAAAJ&engine=google_scholar_author&hl=en,oJPqrtYAAAAJ,,,,,,,,,,,,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=lMcpoV1FVgkJ,4.0,"https://scholar.google.com/scholar?cites=672801462776612756&as_sdt=5,34&sciodt=0,34&hl=en&num=20",672801462776612756,https://serpapi.com/search.json?as_sdt=5%2C34&cites=672801462776612756&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:lMcpoV1FVgkJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,34",https://serpapi.com/search.json?as_sdt=0%2C34&engine=google_scholar&hl=en&num=20&q=related%3AlMcpoV1FVgkJ%3Ascholar.google.com%2F&start=20,2.0,"https://scholar.google.com/scholar?cluster=672801462776612756&hl=en&num=20&as_sdt=0,34",672801462776612756,https://serpapi.com/search.json?as_sdt=0%2C34&cluster=672801462776612756&engine=google_scholar&hl=en&num=20,,,,,,,,,,,,,,,,,,,,,
18,Dqn-tamer: Human-in-the-loop reinforcement learning with intractable feedback,3FD85zP7ltkJ,https://arxiv.org/abs/1810.11748,"… We also propose an RL method called DQN-TAMER, which efficiently uses both human feedback and distant rewards. We find that DQN-TAMER agents outperform their baselines in …","R Arakawa, S Kobayashi, Y Unno, Y Tsuboi… - arXiv preprint arXiv …, 2018 - arxiv.org",R Arakawa,https://scholar.google.com/citations?user=_6NCBtYAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=_6NCBtYAAAAJ&engine=google_scholar_author&hl=en,_6NCBtYAAAAJ,S Kobayashi,https://scholar.google.com/citations?user=VY6PqvsAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=VY6PqvsAAAAJ&engine=google_scholar_author&hl=en,VY6PqvsAAAAJ,Y Unno,https://scholar.google.com/citations?user=z7XW-goAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=z7XW-goAAAAJ&engine=google_scholar_author&hl=en,z7XW-goAAAAJ,arxiv.org,PDF,https://arxiv.org/pdf/1810.11748,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=3FD85zP7ltkJ,79.0,"https://scholar.google.com/scholar?cites=15678995353090937052&as_sdt=5,34&sciodt=0,34&hl=en&num=20",15678995353090937052,https://serpapi.com/search.json?as_sdt=5%2C34&cites=15678995353090937052&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:3FD85zP7ltkJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,34",https://serpapi.com/search.json?as_sdt=0%2C34&engine=google_scholar&hl=en&num=20&q=related%3A3FD85zP7ltkJ%3Ascholar.google.com%2F&start=20,6.0,"https://scholar.google.com/scholar?cluster=15678995353090937052&hl=en&num=20&as_sdt=0,34",15678995353090937052,https://serpapi.com/search.json?as_sdt=0%2C34&cluster=15678995353090937052&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:3FD85zP7ltkJ:scholar.google.com/+%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,34",,,,,,,,,,,,,,,,,,,,
19,Playing text-adventure games with graph-based deep reinforcement learning,NGeHW6zNftwJ,https://arxiv.org/abs/1812.01628,"… We present a deep reinforcement learning architecture that represents the game state as a … is a deep reinforcement learning architecture, Knowledge Graph DQN (KG-DQN), that …","P Ammanabrolu, MO Riedl - arXiv preprint arXiv:1812.01628, 2018 - arxiv.org",P Ammanabrolu,https://scholar.google.com/citations?user=2yaiWZ8AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=2yaiWZ8AAAAJ&engine=google_scholar_author&hl=en,2yaiWZ8AAAAJ,MO Riedl,https://scholar.google.com/citations?user=Yg_QjxcAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=Yg_QjxcAAAAJ&engine=google_scholar_author&hl=en,Yg_QjxcAAAAJ,,,,,arxiv.org,PDF,https://arxiv.org/pdf/1812.01628,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=NGeHW6zNftwJ,139.0,"https://scholar.google.com/scholar?cites=15888362675563358004&as_sdt=5,34&sciodt=0,34&hl=en&num=20",15888362675563358004,https://serpapi.com/search.json?as_sdt=5%2C34&cites=15888362675563358004&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:NGeHW6zNftwJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,34",https://serpapi.com/search.json?as_sdt=0%2C34&engine=google_scholar&hl=en&num=20&q=related%3ANGeHW6zNftwJ%3Ascholar.google.com%2F&start=20,6.0,"https://scholar.google.com/scholar?cluster=15888362675563358004&hl=en&num=20&as_sdt=0,34",15888362675563358004,https://serpapi.com/search.json?as_sdt=0%2C34&cluster=15888362675563358004&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:NGeHW6zNftwJ:scholar.google.com/+%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,34",,,,,,,,,,,,,,,,,,,,
0,Playing text-adventure games with graph-based deep reinforcement learning,NGeHW6zNftwJ,https://arxiv.org/abs/1812.01628,"… We present a deep reinforcement learning architecture that represents the game state as a … is a deep reinforcement learning architecture, Knowledge Graph DQN (KG-DQN), that …","P Ammanabrolu, MO Riedl - arXiv preprint arXiv:1812.01628, 2018 - arxiv.org",P Ammanabrolu,https://scholar.google.com/citations?user=2yaiWZ8AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=2yaiWZ8AAAAJ&engine=google_scholar_author&hl=en,2yaiWZ8AAAAJ,MO Riedl,https://scholar.google.com/citations?user=Yg_QjxcAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=Yg_QjxcAAAAJ&engine=google_scholar_author&hl=en,Yg_QjxcAAAAJ,,,,,arxiv.org,PDF,https://arxiv.org/pdf/1812.01628,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=NGeHW6zNftwJ,139.0,"https://scholar.google.com/scholar?cites=15888362675563358004&as_sdt=2005&sciodt=0,5&hl=en&num=20",15888362675563358004,https://serpapi.com/search.json?as_sdt=2005&cites=15888362675563358004&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:NGeHW6zNftwJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,5",https://serpapi.com/search.json?as_sdt=0%2C5&engine=google_scholar&hl=en&num=20&q=related%3ANGeHW6zNftwJ%3Ascholar.google.com%2F&start=40,6.0,"https://scholar.google.com/scholar?cluster=15888362675563358004&hl=en&num=20&as_sdt=0,5",15888362675563358004,https://serpapi.com/search.json?as_sdt=0%2C5&cluster=15888362675563358004&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:NGeHW6zNftwJ:scholar.google.com/+%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,5",,,,,,,,,,,,,,,,,,,,
1,Iterative rule-guided reasoning over sparse knowledge graphs with deep reinforcement learning,MA8N-Z8c4XgJ,https://www.sciencedirect.com/science/article/pii/S0306457322001492,"… To the best of our knowledge, our proposed SparKGR constitutes the first iterative inference framework for sparse knowledge graph reasoning with reinforcement learning. …","Y Xia, M Lan, J Luo, X Chen, G Zhou - Information Processing & …, 2022 - Elsevier",,,,,,,,,,,,,,,,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=MA8N-Z8c4XgJ,18.0,"https://scholar.google.com/scholar?cites=8710274627715010352&as_sdt=2005&sciodt=0,5&hl=en&num=20",8710274627715010352,https://serpapi.com/search.json?as_sdt=2005&cites=8710274627715010352&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:MA8N-Z8c4XgJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,5",https://serpapi.com/search.json?as_sdt=0%2C5&engine=google_scholar&hl=en&num=20&q=related%3AMA8N-Z8c4XgJ%3Ascholar.google.com%2F&start=40,2.0,"https://scholar.google.com/scholar?cluster=8710274627715010352&hl=en&num=20&as_sdt=0,5",8710274627715010352,https://serpapi.com/search.json?as_sdt=0%2C5&cluster=8710274627715010352&engine=google_scholar&hl=en&num=20,,,,,,,,,,,,,,,,,,,,,
2,Avoiding jammers: A reinforcement learning approach,IWPIaA-m4qYJ,https://ieeexplore.ieee.org/abstract/document/9114797/,"… Considering two frequency hopping strategies developed in the framework of reinforcement learning (RL), this performance metric is analyzed with deep Q-network (DQN) and long …","S Ak, S Brüggenwirth - 2020 IEEE international radar …, 2020 - ieeexplore.ieee.org",S Brüggenwirth,https://scholar.google.com/citations?user=3efNGegAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=3efNGegAAAAJ&engine=google_scholar_author&hl=en,3efNGegAAAAJ,,,,,,,,,arxiv.org,PDF,https://arxiv.org/pdf/1911.08874,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=IWPIaA-m4qYJ,34.0,"https://scholar.google.com/scholar?cites=12025356540145328929&as_sdt=2005&sciodt=0,5&hl=en&num=20",12025356540145328929,https://serpapi.com/search.json?as_sdt=2005&cites=12025356540145328929&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:IWPIaA-m4qYJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,5",https://serpapi.com/search.json?as_sdt=0%2C5&engine=google_scholar&hl=en&num=20&q=related%3AIWPIaA-m4qYJ%3Ascholar.google.com%2F&start=40,5.0,"https://scholar.google.com/scholar?cluster=12025356540145328929&hl=en&num=20&as_sdt=0,5",12025356540145328929,https://serpapi.com/search.json?as_sdt=0%2C5&cluster=12025356540145328929&engine=google_scholar&hl=en&num=20,,,,,,,,,,,,,,,,,,,,,
3,Understanding multi-step deep reinforcement learning: A systematic study of the DQN target,TaDTBr2F_rEJ,https://arxiv.org/abs/1901.07510,… reinforcement learning literature. The main reason significance has taken such a secondary role in deep reinforcement learning … tested in the deep reinforcement learning setting: Sarsa …,"JF Hernandez-Garcia, RS Sutton - arXiv preprint arXiv:1901.07510, 2019 - arxiv.org",JF Hernandez-Garcia,https://scholar.google.com/citations?user=vD3XXGwAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=vD3XXGwAAAAJ&engine=google_scholar_author&hl=en,vD3XXGwAAAAJ,RS Sutton,https://scholar.google.com/citations?user=6m4wv6gAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=6m4wv6gAAAAJ&engine=google_scholar_author&hl=en,6m4wv6gAAAAJ,,,,,arxiv.org,PDF,https://arxiv.org/pdf/1901.07510,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=TaDTBr2F_rEJ,67.0,"https://scholar.google.com/scholar?cites=12825835835707596877&as_sdt=2005&sciodt=0,5&hl=en&num=20",12825835835707596877,https://serpapi.com/search.json?as_sdt=2005&cites=12825835835707596877&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:TaDTBr2F_rEJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,5",https://serpapi.com/search.json?as_sdt=0%2C5&engine=google_scholar&hl=en&num=20&q=related%3ATaDTBr2F_rEJ%3Ascholar.google.com%2F&start=40,4.0,"https://scholar.google.com/scholar?cluster=12825835835707596877&hl=en&num=20&as_sdt=0,5",12825835835707596877,https://serpapi.com/search.json?as_sdt=0%2C5&cluster=12825835835707596877&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:TaDTBr2F_rEJ:scholar.google.com/+%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,5",,,,,,,,,,,,,,,,,,,,
4,RLAT: Multi-hop temporal knowledge graph reasoning based on Reinforcement Learning and Attention Mechanism,hqBqH5hkqPIJ,https://www.sciencedirect.com/science/article/pii/S0950705123002642,"… First, we present reinforcement learning. The agent can choose the most explanatory reasoning path through continuous interaction with the environment. Second, we explain the …","L Bai, D Chai, L Zhu - Knowledge-Based Systems, 2023 - Elsevier",,,,,,,,,,,,,,,,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=hqBqH5hkqPIJ,9.0,"https://scholar.google.com/scholar?cites=17485336157790838918&as_sdt=2005&sciodt=0,5&hl=en&num=20",17485336157790838918,https://serpapi.com/search.json?as_sdt=2005&cites=17485336157790838918&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:hqBqH5hkqPIJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,5",https://serpapi.com/search.json?as_sdt=0%2C5&engine=google_scholar&hl=en&num=20&q=related%3AhqBqH5hkqPIJ%3Ascholar.google.com%2F&start=40,2.0,"https://scholar.google.com/scholar?cluster=17485336157790838918&hl=en&num=20&as_sdt=0,5",17485336157790838918,https://serpapi.com/search.json?as_sdt=0%2C5&cluster=17485336157790838918&engine=google_scholar&hl=en&num=20,,,,,,,,,,,,,,,,,,,,,
5,Exploratory combinatorial optimization with reinforcement learning,6bvm9-bRYbYJ,https://aaai.org/ojs/index.php/AAAI/article/view/5723,"… Approaches following S2V-DQN’s framework incrementally … present ECO-DQN (Exploratory Combinatorial Optimization DQN), … By comparing ECO-DQN to S2V-DQN as a baseline, we …","T Barrett, W Clements, J Foerster, A Lvovsky - Proceedings of the AAAI …, 2020 - aaai.org",T Barrett,https://scholar.google.com/citations?user=nJa1KGIAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=nJa1KGIAAAAJ&engine=google_scholar_author&hl=en,nJa1KGIAAAAJ,W Clements,https://scholar.google.com/citations?user=sAHpnaoAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=sAHpnaoAAAAJ&engine=google_scholar_author&hl=en,sAHpnaoAAAAJ,J Foerster,https://scholar.google.com/citations?user=6z4lQzMAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=6z4lQzMAAAAJ&engine=google_scholar_author&hl=en,6z4lQzMAAAAJ,aaai.org,PDF,https://aaai.org/ojs/index.php/AAAI/article/view/5723/5579,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=6bvm9-bRYbYJ,196.0,"https://scholar.google.com/scholar?cites=13142015977575594985&as_sdt=2005&sciodt=0,5&hl=en&num=20",13142015977575594985,https://serpapi.com/search.json?as_sdt=2005&cites=13142015977575594985&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:6bvm9-bRYbYJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,5",https://serpapi.com/search.json?as_sdt=0%2C5&engine=google_scholar&hl=en&num=20&q=related%3A6bvm9-bRYbYJ%3Ascholar.google.com%2F&start=40,11.0,"https://scholar.google.com/scholar?cluster=13142015977575594985&hl=en&num=20&as_sdt=0,5",13142015977575594985,https://serpapi.com/search.json?as_sdt=0%2C5&cluster=13142015977575594985&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:6bvm9-bRYbYJ:scholar.google.com/+%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,5",A Lvovsky,https://scholar.google.com/citations?user=vhkS2c4AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=vhkS2c4AAAAJ&engine=google_scholar_author&hl=en,vhkS2c4AAAAJ,,,,,,,,,,,,,,,,
6,Reinforcement learning with dynamic completion for answering multi-hop questions over incomplete knowledge graph,UW7mThVhNV8J,https://www.sciencedirect.com/science/article/pii/S0306457323000201,"… knowledge graph (KG), whereas prior studies either rely on external resources or lack necessary interpretability. This article desires to extend the line of reinforcement learning (RL) …","H Cui, T Peng, R Han, B Zhu, H Bi, L Liu - Information Processing & …, 2023 - Elsevier",,,,,,,,,,,,,,,,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=UW7mThVhNV8J,8.0,"https://scholar.google.com/scholar?cites=6860496351514750545&as_sdt=2005&sciodt=0,5&hl=en&num=20",6860496351514750545,https://serpapi.com/search.json?as_sdt=2005&cites=6860496351514750545&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:UW7mThVhNV8J:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,5",https://serpapi.com/search.json?as_sdt=0%2C5&engine=google_scholar&hl=en&num=20&q=related%3AUW7mThVhNV8J%3Ascholar.google.com%2F&start=40,2.0,"https://scholar.google.com/scholar?cluster=6860496351514750545&hl=en&num=20&as_sdt=0,5",6860496351514750545,https://serpapi.com/search.json?as_sdt=0%2C5&cluster=6860496351514750545&engine=google_scholar&hl=en&num=20,,,,,,,,,,,,,,,,,,,,,
7,Induction of subgoal automata for reinforcement learning,tD8KBXFa32QJ,https://ojs.aaai.org/index.php/AAAI/article/view/5802,… approach for learning and exploiting subgoals in reinforcement learning (RL). Our method relies … The reinforcement learning and automaton learning processes are interleaved: a new re…,"D Furelos-Blanco, M Law, A Russo, K Broda… - Proceedings of the …, 2020 - ojs.aaai.org",D Furelos-Blanco,https://scholar.google.com/citations?user=IfMKjBgAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=IfMKjBgAAAAJ&engine=google_scholar_author&hl=en,IfMKjBgAAAAJ,M Law,https://scholar.google.com/citations?user=A5JWIs0AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=A5JWIs0AAAAJ&engine=google_scholar_author&hl=en,A5JWIs0AAAAJ,A Russo,https://scholar.google.com/citations?user=_6zceo4AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=_6zceo4AAAAJ&engine=google_scholar_author&hl=en,_6zceo4AAAAJ,aaai.org,PDF,https://ojs.aaai.org/index.php/AAAI/article/view/5802/5658,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=tD8KBXFa32QJ,34.0,"https://scholar.google.com/scholar?cites=7268627765061631924&as_sdt=2005&sciodt=0,5&hl=en&num=20",7268627765061631924,https://serpapi.com/search.json?as_sdt=2005&cites=7268627765061631924&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:tD8KBXFa32QJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,5",https://serpapi.com/search.json?as_sdt=0%2C5&engine=google_scholar&hl=en&num=20&q=related%3AtD8KBXFa32QJ%3Ascholar.google.com%2F&start=40,8.0,"https://scholar.google.com/scholar?cluster=7268627765061631924&hl=en&num=20&as_sdt=0,5",7268627765061631924,https://serpapi.com/search.json?as_sdt=0%2C5&cluster=7268627765061631924&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:tD8KBXFa32QJ:scholar.google.com/+%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,5",,,,,,,,,,,,,,,,,,,,
8,A novel deep reinforcement learning based stock direction prediction using knowledge graph and community aware sentiments,Znhz5Ww2kzAJ,https://arxiv.org/abs/2107.00931,"… a novel deep reinforcement learning method to predict the direction of stock prices using knowledge graph and community aware sentiments. With the usage of knowledge graph, …","AB Altuner, ZH Kilimci - arXiv preprint arXiv:2107.00931, 2021 - arxiv.org",ZH Kilimci,https://scholar.google.com/citations?user=isGlUbMAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=isGlUbMAAAAJ&engine=google_scholar_author&hl=en,isGlUbMAAAAJ,,,,,,,,,arxiv.org,PDF,https://arxiv.org/pdf/2107.00931,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=Znhz5Ww2kzAJ,7.0,"https://scholar.google.com/scholar?cites=3500201176730925158&as_sdt=2005&sciodt=0,5&hl=en&num=20",3500201176730925158,https://serpapi.com/search.json?as_sdt=2005&cites=3500201176730925158&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:Znhz5Ww2kzAJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,5",https://serpapi.com/search.json?as_sdt=0%2C5&engine=google_scholar&hl=en&num=20&q=related%3AZnhz5Ww2kzAJ%3Ascholar.google.com%2F&start=40,4.0,"https://scholar.google.com/scholar?cluster=3500201176730925158&hl=en&num=20&as_sdt=0,5",3500201176730925158,https://serpapi.com/search.json?as_sdt=0%2C5&cluster=3500201176730925158&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:Znhz5Ww2kzAJ:scholar.google.com/+%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,5",,,,,,,,,,,,,,,,,,,,
9,Reinforcement learning-based knowledge graph reasoning for explainable fact-checking,TkerOohQvbUJ,https://dl.acm.org/doi/abs/10.1145/3625007.3627593,… This work proposes a combination of reinforcement learning and KG to provide explainable … the paths produced by a graph hopping reinforcement learning agent to vote on the veracity …,"G Nikopensius, M Mayank, OC Phukan… - Proceedings of the …, 2023 - dl.acm.org",OC Phukan,https://scholar.google.com/citations?user=EV6cXVIAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=EV6cXVIAAAAJ&engine=google_scholar_author&hl=en,EV6cXVIAAAAJ,,,,,,,,,arxiv.org,PDF,https://arxiv.org/pdf/2310.07613,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=TkerOohQvbUJ,2.0,"https://scholar.google.com/scholar?cites=13095711837493348174&as_sdt=2005&sciodt=0,5&hl=en&num=20",13095711837493348174,https://serpapi.com/search.json?as_sdt=2005&cites=13095711837493348174&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:TkerOohQvbUJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,5",https://serpapi.com/search.json?as_sdt=0%2C5&engine=google_scholar&hl=en&num=20&q=related%3ATkerOohQvbUJ%3Ascholar.google.com%2F&start=40,2.0,"https://scholar.google.com/scholar?cluster=13095711837493348174&hl=en&num=20&as_sdt=0,5",13095711837493348174,https://serpapi.com/search.json?as_sdt=0%2C5&cluster=13095711837493348174&engine=google_scholar&hl=en&num=20,,,,,,,,,,,,,,,,,,,,,
10,Generating text with deep reinforcement learning,amlvqQkw4DoJ,https://arxiv.org/abs/1510.09202,"… The newly modified output sequence is subsequently used as the input to the DQN for the next decoding iteration. In each iteration, we also bias the reinforcement learning’s attention to …","H Guo - arXiv preprint arXiv:1510.09202, 2015 - arxiv.org",H Guo,https://scholar.google.com/citations?user=bZUqlakAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=bZUqlakAAAAJ&engine=google_scholar_author&hl=en,bZUqlakAAAAJ,,,,,,,,,arxiv.org,PDF,https://arxiv.org/pdf/1510.09202,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=amlvqQkw4DoJ,59.0,"https://scholar.google.com/scholar?cites=4242443667038497130&as_sdt=2005&sciodt=0,5&hl=en&num=20",4242443667038497130,https://serpapi.com/search.json?as_sdt=2005&cites=4242443667038497130&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:amlvqQkw4DoJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,5",https://serpapi.com/search.json?as_sdt=0%2C5&engine=google_scholar&hl=en&num=20&q=related%3AamlvqQkw4DoJ%3Ascholar.google.com%2F&start=40,3.0,"https://scholar.google.com/scholar?cluster=4242443667038497130&hl=en&num=20&as_sdt=0,5",4242443667038497130,https://serpapi.com/search.json?as_sdt=0%2C5&cluster=4242443667038497130&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:amlvqQkw4DoJ:scholar.google.com/+%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,5",,,,,,,,,,,,,,,,,,,,
11,Stabilizing reinforcement learning in dynamic environment with application to online recommendation,5MfyKycEe6cJ,https://dl.acm.org/doi/abs/10.1145/3219819.3220122,… We apply Robust DQN in the tip recommendation system in Taobao online retail trading platform. We firstly disclose the highly dynamic property of the recommendation application. We …,"SY Chen, Y Yu, Q Da, J Tan, HK Huang… - Proceedings of the 24th …, 2018 - dl.acm.org",SY Chen,https://scholar.google.com/citations?user=BIFXUFYAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=BIFXUFYAAAAJ&engine=google_scholar_author&hl=en,BIFXUFYAAAAJ,Y Yu,https://scholar.google.com/citations?user=PG2lDSwAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=PG2lDSwAAAAJ&engine=google_scholar_author&hl=en,PG2lDSwAAAAJ,Q Da,https://scholar.google.com/citations?user=sRKGtmgAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=sRKGtmgAAAAJ&engine=google_scholar_author&hl=en,sRKGtmgAAAAJ,researchgate.net,PDF,https://www.researchgate.net/profile/Qing-Da/publication/324988927_Stablizing_Reinforcement_Learning_in_Dynamic_Environment_with_Application_to_Online_Recommendation/links/5b2b4321aca27209f3797d65/Stablizing-Reinforcement-Learning-in-Dynamic-Environment-with-Application-to-Online-Recommendation.pdf?ref=https://githubhelp.com,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=5MfyKycEe6cJ,158.0,"https://scholar.google.com/scholar?cites=12068244192756942820&as_sdt=2005&sciodt=0,5&hl=en&num=20",12068244192756942820,https://serpapi.com/search.json?as_sdt=2005&cites=12068244192756942820&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:5MfyKycEe6cJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,5",https://serpapi.com/search.json?as_sdt=0%2C5&engine=google_scholar&hl=en&num=20&q=related%3A5MfyKycEe6cJ%3Ascholar.google.com%2F&start=40,3.0,"https://scholar.google.com/scholar?cluster=12068244192756942820&hl=en&num=20&as_sdt=0,5",12068244192756942820,https://serpapi.com/search.json?as_sdt=0%2C5&cluster=12068244192756942820&engine=google_scholar&hl=en&num=20,,HK Huang,https://scholar.google.com/citations?user=5t3avfkAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=5t3avfkAAAAJ&engine=google_scholar_author&hl=en,5t3avfkAAAAJ,,,,,,,,,,,,,,,,
12,Mobile robot navigation based on deep reinforcement learning,5InVsle5iocJ,https://ieeexplore.ieee.org/abstract/document/8832393/,… in this paper using deep reinforcement learning for the navigation of mobile … reinforcement learning (Dueling DQN) and deep reinforcement learning with double q learning (Double DQN…,"X Ruan, D Ren, X Zhu, J Huang - 2019 Chinese control and …, 2019 - ieeexplore.ieee.org",X Zhu,https://scholar.google.com/citations?user=DfXFgksAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=DfXFgksAAAAJ&engine=google_scholar_author&hl=en,DfXFgksAAAAJ,J Huang,https://scholar.google.com/citations?user=UIrnSXMAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=UIrnSXMAAAAJ&engine=google_scholar_author&hl=en,UIrnSXMAAAAJ,,,,,,,,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=5InVsle5iocJ,108.0,"https://scholar.google.com/scholar?cites=9766822528219974116&as_sdt=2005&sciodt=0,5&hl=en&num=20",9766822528219974116,https://serpapi.com/search.json?as_sdt=2005&cites=9766822528219974116&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:5InVsle5iocJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,5",https://serpapi.com/search.json?as_sdt=0%2C5&engine=google_scholar&hl=en&num=20&q=related%3A5InVsle5iocJ%3Ascholar.google.com%2F&start=40,,,,,,,,,,,,,,,,,,,,,,,,,
13,Go for a walk and arrive at the answer: Reasoning over paths in knowledge bases using reinforcement learning,x2Fw3QHn5kIJ,https://arxiv.org/abs/1711.05851,"… Given a massive knowledge graph, we learn a policy, which, … -answering task as a reinforcement learning (RL) problem … the knowledge graph from scratch with reinforcement …","R Das, S Dhuliawala, M Zaheer, L Vilnis… - arXiv preprint arXiv …, 2017 - arxiv.org",R Das,https://scholar.google.com/citations?user=FKoKAwIAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=FKoKAwIAAAAJ&engine=google_scholar_author&hl=en,FKoKAwIAAAAJ,S Dhuliawala,https://scholar.google.com/citations?user=7O33ij4AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=7O33ij4AAAAJ&engine=google_scholar_author&hl=en,7O33ij4AAAAJ,M Zaheer,https://scholar.google.com/citations?user=A33FhJMAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=A33FhJMAAAAJ&engine=google_scholar_author&hl=en,A33FhJMAAAAJ,arxiv.org,PDF,https://arxiv.org/pdf/1711.05851,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=x2Fw3QHn5kIJ,560.0,"https://scholar.google.com/scholar?cites=4820794446342808007&as_sdt=2005&sciodt=0,5&hl=en&num=20",4820794446342808007,https://serpapi.com/search.json?as_sdt=2005&cites=4820794446342808007&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:x2Fw3QHn5kIJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,5",https://serpapi.com/search.json?as_sdt=0%2C5&engine=google_scholar&hl=en&num=20&q=related%3Ax2Fw3QHn5kIJ%3Ascholar.google.com%2F&start=40,6.0,"https://scholar.google.com/scholar?cluster=4820794446342808007&hl=en&num=20&as_sdt=0,5",4820794446342808007,https://serpapi.com/search.json?as_sdt=0%2C5&cluster=4820794446342808007&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:x2Fw3QHn5kIJ:scholar.google.com/+%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,5",L Vilnis,https://scholar.google.com/citations?user=xWrOthYAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=xWrOthYAAAAJ&engine=google_scholar_author&hl=en,xWrOthYAAAAJ,,,,,,,,,,,,,,,,
14,Deep reinforcement learning with dqn vs. ppo in vizdoom,x9Nr-CKf2usJ,https://ieeexplore.ieee.org/abstract/document/9668479/,… Abstract—VizDoom is a flexible and easy-to-use 3D reinforcement learning research … The paper offers a comparison of different approaches with reinforcement learning: Q-learning and …,"A Zakharenkov, I Makarov - 2021 IEEE 21st International …, 2021 - ieeexplore.ieee.org",I Makarov,https://scholar.google.com/citations?user=cFpDMzIAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=cFpDMzIAAAAJ&engine=google_scholar_author&hl=en,cFpDMzIAAAAJ,,,,,,,,,,,,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=x9Nr-CKf2usJ,11.0,"https://scholar.google.com/scholar?cites=16995071116381508551&as_sdt=2005&sciodt=0,5&hl=en&num=20",16995071116381508551,https://serpapi.com/search.json?as_sdt=2005&cites=16995071116381508551&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:x9Nr-CKf2usJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,5",https://serpapi.com/search.json?as_sdt=0%2C5&engine=google_scholar&hl=en&num=20&q=related%3Ax9Nr-CKf2usJ%3Ascholar.google.com%2F&start=40,2.0,"https://scholar.google.com/scholar?cluster=16995071116381508551&hl=en&num=20&as_sdt=0,5",16995071116381508551,https://serpapi.com/search.json?as_sdt=0%2C5&cluster=16995071116381508551&engine=google_scholar&hl=en&num=20,,,,,,,,,,,,,,,,,,,,,
15,Multi-modal knowledge-aware reinforcement learning network for explainable recommendation,kQ0heecB-PQJ,https://www.sciencedirect.com/science/article/pii/S0950705121004792,"… To demonstrate the efficacy of the multi-modal knowledge graph as well as deep reinforcement learning more intuitively, we then randomly sampled a user based on results generated …","S Tao, R Qiu, Y Ping, H Ma - Knowledge-Based Systems, 2021 - Elsevier",Y Ping,https://scholar.google.com/citations?user=4YOUysMAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=4YOUysMAAAAJ&engine=google_scholar_author&hl=en,4YOUysMAAAAJ,,,,,,,,,,,,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=kQ0heecB-PQJ,44.0,"https://scholar.google.com/scholar?cites=17651860833159941521&as_sdt=2005&sciodt=0,5&hl=en&num=20",17651860833159941521,https://serpapi.com/search.json?as_sdt=2005&cites=17651860833159941521&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:kQ0heecB-PQJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,5",https://serpapi.com/search.json?as_sdt=0%2C5&engine=google_scholar&hl=en&num=20&q=related%3AkQ0heecB-PQJ%3Ascholar.google.com%2F&start=40,3.0,"https://scholar.google.com/scholar?cluster=17651860833159941521&hl=en&num=20&as_sdt=0,5",17651860833159941521,https://serpapi.com/search.json?as_sdt=0%2C5&cluster=17651860833159941521&engine=google_scholar&hl=en&num=20,,,,,,,,,,,,,,,,,,,,,
16,Reinforcement learning via AIXI approximation,E43KFfGjZ64J,https://ojs.aaai.org/index.php/AAAI/article/view/7667,"… general reinforcement learning agent. This approach is based on a direct approximation of AIXI, a … Previously, it has been unclear whether the theory of AIXI could motivate the design of …","J Veness, KS Ng, M Hutter, D Silver - Proceedings of the AAAI …, 2010 - ojs.aaai.org",J Veness,https://scholar.google.com/citations?user=_iYrAxEAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=_iYrAxEAAAAJ&engine=google_scholar_author&hl=en,_iYrAxEAAAAJ,KS Ng,https://scholar.google.com/citations?user=4bL3ThUAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=4bL3ThUAAAAJ&engine=google_scholar_author&hl=en,4bL3ThUAAAAJ,M Hutter,https://scholar.google.com/citations?user=7hmCntEAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=7hmCntEAAAAJ&engine=google_scholar_author&hl=en,7hmCntEAAAAJ,aaai.org,PDF,https://ojs.aaai.org/index.php/AAAI/article/view/7667/7528,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=E43KFfGjZ64J,32.0,"https://scholar.google.com/scholar?cites=12567193541048700179&as_sdt=2005&sciodt=0,5&hl=en&num=20",12567193541048700179,https://serpapi.com/search.json?as_sdt=2005&cites=12567193541048700179&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:E43KFfGjZ64J:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,5",https://serpapi.com/search.json?as_sdt=0%2C5&engine=google_scholar&hl=en&num=20&q=related%3AE43KFfGjZ64J%3Ascholar.google.com%2F&start=40,22.0,"https://scholar.google.com/scholar?cluster=12567193541048700179&hl=en&num=20&as_sdt=0,5",12567193541048700179,https://serpapi.com/search.json?as_sdt=0%2C5&cluster=12567193541048700179&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:E43KFfGjZ64J:scholar.google.com/+%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,5",D Silver,https://scholar.google.com/citations?user=-8DNE4UAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=-8DNE4UAAAAJ&engine=google_scholar_author&hl=en,-8DNE4UAAAAJ,,,,,,,,,,,,,,,,
17,Deep reinforcement learning-based DQN agent algorithm for visual object tracking in a virtual environmental simulation,0vYWKXOuIqsJ,https://www.mdpi.com/2076-3417/12/7/3220,"… Reinforcement Learning (RL) algorithms are mostly based … Basically, the reinforcement learning method is known to be … the deep reinforcement learning-based DQN agent drone …","JH Park, K Farkhodov, SH Lee, KR Kwon - Applied Sciences, 2022 - mdpi.com",K Farkhodov,https://scholar.google.com/citations?user=2Bfdic4AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=2Bfdic4AAAAJ&engine=google_scholar_author&hl=en,2Bfdic4AAAAJ,SH Lee,https://scholar.google.com/citations?user=8fZ6XOoAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=8fZ6XOoAAAAJ&engine=google_scholar_author&hl=en,8fZ6XOoAAAAJ,,,,,mdpi.com,PDF,https://www.mdpi.com/2076-3417/12/7/3220/pdf,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=0vYWKXOuIqsJ,16.0,"https://scholar.google.com/scholar?cites=12331610539327682258&as_sdt=2005&sciodt=0,5&hl=en&num=20",12331610539327682258,https://serpapi.com/search.json?as_sdt=2005&cites=12331610539327682258&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:0vYWKXOuIqsJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,5",https://serpapi.com/search.json?as_sdt=0%2C5&engine=google_scholar&hl=en&num=20&q=related%3A0vYWKXOuIqsJ%3Ascholar.google.com%2F&start=40,6.0,"https://scholar.google.com/scholar?cluster=12331610539327682258&hl=en&num=20&as_sdt=0,5",12331610539327682258,https://serpapi.com/search.json?as_sdt=0%2C5&cluster=12331610539327682258&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:0vYWKXOuIqsJ:scholar.google.com/+%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,5",,,,,,,,,,,,,,,,,,,,
18,Reason more like human: Incorporating meta information into hierarchical reinforcement learning for knowledge graph reasoning,QPQ5qfhW8rQJ,https://link.springer.com/article/10.1007/s10489-022-04147-2,"… In this paper, we proposed a hierarchical reinforcement learning method RMLH for knowledge graph reasoning. When conducting normal chain reasoning, the search space grows …","Y Xia, J Luo, M Lan, G Zhou, Z Li, S Liu - Applied Intelligence, 2023 - Springer",,,,,,,,,,,,,,,,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=QPQ5qfhW8rQJ,6.0,"https://scholar.google.com/scholar?cites=13038579497182032960&as_sdt=2005&sciodt=0,5&hl=en&num=20",13038579497182032960,https://serpapi.com/search.json?as_sdt=2005&cites=13038579497182032960&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:QPQ5qfhW8rQJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,5",https://serpapi.com/search.json?as_sdt=0%2C5&engine=google_scholar&hl=en&num=20&q=related%3AQPQ5qfhW8rQJ%3Ascholar.google.com%2F&start=40,2.0,"https://scholar.google.com/scholar?cluster=13038579497182032960&hl=en&num=20&as_sdt=0,5",13038579497182032960,https://serpapi.com/search.json?as_sdt=0%2C5&cluster=13038579497182032960&engine=google_scholar&hl=en&num=20,,,,,,,,,,,,,,,,,,,,,
19,Recurrent reinforcement learning: a hybrid approach,KslCDW6qVgIJ,https://arxiv.org/abs/1509.03044,"… supervised learning and reinforcement learning. During training, we use the supervised signals to learn the state representation, then jointly train DQN to approximate the Q-function. …","X Li, L Li, J Gao, X He, J Chen, L Deng, J He - arXiv preprint arXiv …, 2015 - arxiv.org",X Li,https://scholar.google.com/citations?user=SW_WaQ0AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=SW_WaQ0AAAAJ&engine=google_scholar_author&hl=en,SW_WaQ0AAAAJ,L Li,https://scholar.google.com/citations?user=Rqy5KDEAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=Rqy5KDEAAAAJ&engine=google_scholar_author&hl=en,Rqy5KDEAAAAJ,J Gao,https://scholar.google.com/citations?user=CQ1cqKkAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=CQ1cqKkAAAAJ&engine=google_scholar_author&hl=en,CQ1cqKkAAAAJ,arxiv.org,PDF,https://arxiv.org/pdf/1509.03044,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=KslCDW6qVgIJ,84.0,"https://scholar.google.com/scholar?cites=168509425718577450&as_sdt=2005&sciodt=0,5&hl=en&num=20",168509425718577450,https://serpapi.com/search.json?as_sdt=2005&cites=168509425718577450&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:KslCDW6qVgIJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,5",https://serpapi.com/search.json?as_sdt=0%2C5&engine=google_scholar&hl=en&num=20&q=related%3AKslCDW6qVgIJ%3Ascholar.google.com%2F&start=40,3.0,"https://scholar.google.com/scholar?cluster=168509425718577450&hl=en&num=20&as_sdt=0,5",168509425718577450,https://serpapi.com/search.json?as_sdt=0%2C5&cluster=168509425718577450&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:KslCDW6qVgIJ:scholar.google.com/+%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,5",X He,https://scholar.google.com/citations?user=W5WbqgoAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=W5WbqgoAAAAJ&engine=google_scholar_author&hl=en,W5WbqgoAAAAJ,,J Chen,https://scholar.google.com/citations?user=jQeFWdoAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=jQeFWdoAAAAJ&engine=google_scholar_author&hl=en,jQeFWdoAAAAJ,,,,L Deng,https://scholar.google.com/citations?user=GQWTo4MAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=GQWTo4MAAAAJ&engine=google_scholar_author&hl=en,GQWTo4MAAAAJ,J He,https://scholar.google.com/citations?user=2gBeukEAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=2gBeukEAAAAJ&engine=google_scholar_author&hl=en,2gBeukEAAAAJ
0,Knowledge-guided deep reinforcement learning for interactive recommendation,n5iH3WQC0UsJ,https://ieeexplore.ieee.org/abstract/document/9207010/,"… have become popular as the knowledge graph can transfer the rela… Specially, we design a knowledge graph to represent … knowledge graph as the guideline to improve the performance. …","X Chen, C Huang, L Yao, X Wang… - … Joint Conference on …, 2020 - ieeexplore.ieee.org",X Chen,https://scholar.google.com/citations?user=GE0iYnYAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=GE0iYnYAAAAJ&engine=google_scholar_author&hl=en,GE0iYnYAAAAJ,C Huang,https://scholar.google.com/citations?user=Wp6viG8AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=Wp6viG8AAAAJ&engine=google_scholar_author&hl=en,Wp6viG8AAAAJ,L Yao,https://scholar.google.com/citations?user=EU3snBgAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=EU3snBgAAAAJ&engine=google_scholar_author&hl=en,EU3snBgAAAAJ,arxiv.org,PDF,https://arxiv.org/pdf/2004.08068,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=n5iH3WQC0UsJ,37.0,"https://scholar.google.com/scholar?cites=5463150455213758623&as_sdt=5,33&sciodt=0,33&hl=en&num=20",5463150455213758623,https://serpapi.com/search.json?as_sdt=5%2C33&cites=5463150455213758623&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:n5iH3WQC0UsJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,33",https://serpapi.com/search.json?as_sdt=0%2C33&engine=google_scholar&hl=en&num=20&q=related%3An5iH3WQC0UsJ%3Ascholar.google.com%2F&start=60,7.0,"https://scholar.google.com/scholar?cluster=5463150455213758623&hl=en&num=20&as_sdt=0,33",5463150455213758623,https://serpapi.com/search.json?as_sdt=0%2C33&cluster=5463150455213758623&engine=google_scholar&hl=en&num=20,,X Wang,https://scholar.google.com/citations?user=Xej6piMAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=Xej6piMAAAAJ&engine=google_scholar_author&hl=en,Xej6piMAAAAJ,,,,,,,,,,,,,,,,
1,Graph convolutional reinforcement learning,NxEFiCP5114J,https://arxiv.org/abs/1810.09202,"… DQN which first get relative high reward, but eventually converge to much lower reward. As observed in the experiment, at the beginning of training, DQN … policy, DQN and CommNet …","J Jiang, C Dun, T Huang, Z Lu - arXiv preprint arXiv:1810.09202, 2018 - arxiv.org",J Jiang,https://scholar.google.com/citations?user=zRgok8IAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=zRgok8IAAAAJ&engine=google_scholar_author&hl=en,zRgok8IAAAAJ,C Dun,https://scholar.google.com/citations?user=QbPWRIoAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=QbPWRIoAAAAJ&engine=google_scholar_author&hl=en,QbPWRIoAAAAJ,T Huang,https://scholar.google.com/citations?user=knvEK4AAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=knvEK4AAAAAJ&engine=google_scholar_author&hl=en,knvEK4AAAAAJ,arxiv.org,PDF,https://arxiv.org/pdf/1810.09202,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=NxEFiCP5114J,408.0,"https://scholar.google.com/scholar?cites=6834204890559222071&as_sdt=5,33&sciodt=0,33&hl=en&num=20",6834204890559222071,https://serpapi.com/search.json?as_sdt=5%2C33&cites=6834204890559222071&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:NxEFiCP5114J:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,33",https://serpapi.com/search.json?as_sdt=0%2C33&engine=google_scholar&hl=en&num=20&q=related%3ANxEFiCP5114J%3Ascholar.google.com%2F&start=60,5.0,"https://scholar.google.com/scholar?cluster=6834204890559222071&hl=en&num=20&as_sdt=0,33",6834204890559222071,https://serpapi.com/search.json?as_sdt=0%2C33&cluster=6834204890559222071&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:NxEFiCP5114J:scholar.google.com/+%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,33",Z Lu,https://scholar.google.com/citations?user=k3IFtTYAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=k3IFtTYAAAAJ&engine=google_scholar_author&hl=en,k3IFtTYAAAAJ,,,,,,,,,,,,,,,,
2,Path Spuriousness-aware Reinforcement Learning for Multi-Hop Knowledge Graph Reasoning,QWt9MjZWH6AJ,https://aclanthology.org/2023.eacl-main.232/,"… Multi-hop reasoning, a prevalent approach for query answering, aims at inferring new facts along reasonable paths over a knowledge graph. Reinforcement learning (RL) methods can …","C Jiang, T Zhu, H Zhou, C Liu, T Deng… - Proceedings of the 17th …, 2023 - aclanthology.org",C Jiang,https://scholar.google.com/citations?user=THm8x5AAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=THm8x5AAAAAJ&engine=google_scholar_author&hl=en,THm8x5AAAAAJ,T Zhu,https://scholar.google.com/citations?user=P60wcZwAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=P60wcZwAAAAJ&engine=google_scholar_author&hl=en,P60wcZwAAAAJ,H Zhou,https://scholar.google.com/citations?user=mbrFlN0AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=mbrFlN0AAAAJ&engine=google_scholar_author&hl=en,mbrFlN0AAAAJ,aclanthology.org,PDF,https://aclanthology.org/2023.eacl-main.232.pdf,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=QWt9MjZWH6AJ,2.0,"https://scholar.google.com/scholar?cites=11538035561121803073&as_sdt=5,33&sciodt=0,33&hl=en&num=20",11538035561121803073,https://serpapi.com/search.json?as_sdt=5%2C33&cites=11538035561121803073&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:QWt9MjZWH6AJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,33",https://serpapi.com/search.json?as_sdt=0%2C33&engine=google_scholar&hl=en&num=20&q=related%3AQWt9MjZWH6AJ%3Ascholar.google.com%2F&start=60,,,,,"https://scholar.googleusercontent.com/scholar?q=cache:QWt9MjZWH6AJ:scholar.google.com/+%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,33",C Liu,https://scholar.google.com/citations?user=Q_24qTQAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=Q_24qTQAAAAJ&engine=google_scholar_author&hl=en,Q_24qTQAAAAJ,,T Deng,https://scholar.google.com/citations?user=nvSID14AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=nvSID14AAAAJ&engine=google_scholar_author&hl=en,nvSID14AAAAJ,,,,,,,,,,,
3,Graph constrained reinforcement learning for natural language action spaces,7Dyob_LsFdEJ,https://arxiv.org/abs/2001.08837,… to extend reinforcement learning … knowledge graph while exploring and generates actions using a template-based action space. We contend that the dual uses of the knowledge graph …,"P Ammanabrolu, M Hausknecht - arXiv preprint arXiv:2001.08837, 2020 - arxiv.org",P Ammanabrolu,https://scholar.google.com/citations?user=2yaiWZ8AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=2yaiWZ8AAAAJ&engine=google_scholar_author&hl=en,2yaiWZ8AAAAJ,M Hausknecht,https://scholar.google.com/citations?user=lutJce0AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=lutJce0AAAAJ&engine=google_scholar_author&hl=en,lutJce0AAAAJ,,,,,arxiv.org,PDF,https://arxiv.org/pdf/2001.08837,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=7Dyob_LsFdEJ,109.0,"https://scholar.google.com/scholar?cites=15066208654437399788&as_sdt=5,33&sciodt=0,33&hl=en&num=20",15066208654437399788,https://serpapi.com/search.json?as_sdt=5%2C33&cites=15066208654437399788&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:7Dyob_LsFdEJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,33",https://serpapi.com/search.json?as_sdt=0%2C33&engine=google_scholar&hl=en&num=20&q=related%3A7Dyob_LsFdEJ%3Ascholar.google.com%2F&start=60,4.0,"https://scholar.google.com/scholar?cluster=15066208654437399788&hl=en&num=20&as_sdt=0,33",15066208654437399788,https://serpapi.com/search.json?as_sdt=0%2C33&cluster=15066208654437399788&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:7Dyob_LsFdEJ:scholar.google.com/+%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,33",,,,,,,,,,,,,,,,,,,,
4,Sigmoid-weighted linear units for neural network function approximation in reinforcement learning,quIqE_P46FgJ,https://www.sciencedirect.com/science/article/pii/S0893608017302976,… as function approximators in reinforcement learning. Two … the deep reinforcement learning algorithm DQN achieved human… function approximation in reinforcement learning: the sigmoid-…,"S Elfwing, E Uchibe, K Doya - Neural networks, 2018 - Elsevier",S Elfwing,https://scholar.google.com/citations?user=LURB9dwAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=LURB9dwAAAAJ&engine=google_scholar_author&hl=en,LURB9dwAAAAJ,E Uchibe,https://scholar.google.com/citations?user=nXqBRo8AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=nXqBRo8AAAAJ&engine=google_scholar_author&hl=en,nXqBRo8AAAAJ,K Doya,https://scholar.google.com/citations?user=SHufeXQAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=SHufeXQAAAAJ&engine=google_scholar_author&hl=en,SHufeXQAAAAJ,sciencedirect.com,HTML,https://www.sciencedirect.com/science/article/pii/S0893608017302976,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=quIqE_P46FgJ,1271.0,"https://scholar.google.com/scholar?cites=6406644192816849578&as_sdt=5,33&sciodt=0,33&hl=en&num=20",6406644192816849578,https://serpapi.com/search.json?as_sdt=5%2C33&cites=6406644192816849578&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:quIqE_P46FgJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,33",https://serpapi.com/search.json?as_sdt=0%2C33&engine=google_scholar&hl=en&num=20&q=related%3AquIqE_P46FgJ%3Ascholar.google.com%2F&start=60,11.0,"https://scholar.google.com/scholar?cluster=6406644192816849578&hl=en&num=20&as_sdt=0,33",6406644192816849578,https://serpapi.com/search.json?as_sdt=0%2C33&cluster=6406644192816849578&engine=google_scholar&hl=en&num=20,,,,,,Html,,,,,https://www.sciencedirect.com/science/article/pii/S0893608017302976,,,,,,,,,,
5,DuAK: Reinforcement Learning-Based Knowledge Graph Reasoning for Steel Surface Defect Detection,vzyzSU-PZ1QJ,https://ieeexplore.ieee.org/abstract/document/10247201/,"… knowledge graph for steel surface defect detection. In the proposed approach, a policy-based reinforcement learning … problem over the industrial knowledge graph. To further improve …","Y Zhang, H Wang, W Shen… - IEEE Transactions on …, 2023 - ieeexplore.ieee.org",Y Zhang,https://scholar.google.com/citations?user=GnPT78wAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=GnPT78wAAAAJ&engine=google_scholar_author&hl=en,GnPT78wAAAAJ,H Wang,https://scholar.google.com/citations?user=lFbTT5AAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=lFbTT5AAAAAJ&engine=google_scholar_author&hl=en,lFbTT5AAAAAJ,W Shen,https://scholar.google.com/citations?user=FuSHsx4AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=FuSHsx4AAAAJ&engine=google_scholar_author&hl=en,FuSHsx4AAAAJ,,,,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=vzyzSU-PZ1QJ,3.0,"https://scholar.google.com/scholar?cites=6081987392488815807&as_sdt=5,33&sciodt=0,33&hl=en&num=20",6081987392488815807,https://serpapi.com/search.json?as_sdt=5%2C33&cites=6081987392488815807&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:vzyzSU-PZ1QJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,33",https://serpapi.com/search.json?as_sdt=0%2C33&engine=google_scholar&hl=en&num=20&q=related%3AvzyzSU-PZ1QJ%3Ascholar.google.com%2F&start=60,,,,,,,,,,,,,,,,,,,,,,,,,
6,Reinforcement learning-based distant supervision relation extraction for fault diagnosis knowledge graph construction under industry 4.0,-BILLMEDCQQJ,https://www.sciencedirect.com/science/article/pii/S1474034623000289,"… In our proposed algorithm, the introduction of reinforcement learning to further process the noisy corpus, which leads to better modelling performance. In the KG graph visualisation, it …","C Chen, T Wang, Y Zheng, Y Liu, H Xie, J Deng… - Advanced Engineering …, 2023 - Elsevier",C Chen,https://scholar.google.com/citations?user=jNbNmU4AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=jNbNmU4AAAAJ&engine=google_scholar_author&hl=en,jNbNmU4AAAAJ,Y Liu,https://scholar.google.com/citations?user=dFgj9cwAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=dFgj9cwAAAAJ&engine=google_scholar_author&hl=en,dFgj9cwAAAAJ,,,,,researchgate.net,PDF,https://www.researchgate.net/profile/Chong-Chen-27/publication/368359486_Reinforcement_Learning-based_Distant_Supervision_Relation_Extraction_for_Fault_Diagnosis_Knowledge_Graph_Construction_Under_Industry_40/links/63e4405d6425237563997f46/Reinforcement-Learning-based-Distant-Supervision-Relation-Extraction-for-Fault-Diagnosis-Knowledge-Graph-Construction-Under-Industry-40.pdf,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=-BILLMEDCQQJ,19.0,"https://scholar.google.com/scholar?cites=290767779144602360&as_sdt=5,33&sciodt=0,33&hl=en&num=20",290767779144602360,https://serpapi.com/search.json?as_sdt=5%2C33&cites=290767779144602360&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:-BILLMEDCQQJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,33",https://serpapi.com/search.json?as_sdt=0%2C33&engine=google_scholar&hl=en&num=20&q=related%3A-BILLMEDCQQJ%3Ascholar.google.com%2F&start=60,4.0,"https://scholar.google.com/scholar?cluster=290767779144602360&hl=en&num=20&as_sdt=0,33",290767779144602360,https://serpapi.com/search.json?as_sdt=0%2C33&cluster=290767779144602360&engine=google_scholar&hl=en&num=20,,,,,,,,,,,,,,,,,,,,,
7,ED-DQN: An event-driven deep reinforcement learning control method for multi-zone residential buildings,wqW3K-aRDokJ,https://www.sciencedirect.com/science/article/pii/S0360132323005735,"… the number of decisions in DQN as D 1 and the number of decisions in ED-DQN as D 2 . … between ED-DQN and DQN. The results indicate that ED-DQN outperforms DQN, with reduction …","Q Fu, Z Li, Z Ding, J Chen, J Luo, Y Wang, Y Lu - Building and Environment, 2023 - Elsevier",,,,,,,,,,,,,,,,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=wqW3K-aRDokJ,37.0,"https://scholar.google.com/scholar?cites=9875991450632037826&as_sdt=5,33&sciodt=0,33&hl=en&num=20",9875991450632037826,https://serpapi.com/search.json?as_sdt=5%2C33&cites=9875991450632037826&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:wqW3K-aRDokJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,33",https://serpapi.com/search.json?as_sdt=0%2C33&engine=google_scholar&hl=en&num=20&q=related%3AwqW3K-aRDokJ%3Ascholar.google.com%2F&start=60,2.0,"https://scholar.google.com/scholar?cluster=9875991450632037826&hl=en&num=20&as_sdt=0,33",9875991450632037826,https://serpapi.com/search.json?as_sdt=0%2C33&cluster=9875991450632037826&engine=google_scholar&hl=en&num=20,,,,,,,,,,,,,,,,,,,,,
8,Internal Logical Induction for Pixel-Symbolic Reinforcement Learning,FvkRRElcUpgJ,https://dl.acm.org/doi/abs/10.1145/3580305.3599393,"… Reinforcement Learning (RL) has experienced rapid … To tackle the above issue, we propose an Internal Logical Induction (ILI) … In this paper, we use the deep RL algorithm DQN and the …","J Xu, C Chen, F Zhang, L Yuan, Z Zhang… - Proceedings of the 29th …, 2023 - dl.acm.org",J Xu,https://scholar.google.com/citations?user=rKEuvd0AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=rKEuvd0AAAAJ&engine=google_scholar_author&hl=en,rKEuvd0AAAAJ,F Zhang,https://scholar.google.com/citations?user=GZRrWXAAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=GZRrWXAAAAAJ&engine=google_scholar_author&hl=en,GZRrWXAAAAAJ,L Yuan,https://scholar.google.com/citations?user=kbDU8bEAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=kbDU8bEAAAAJ&engine=google_scholar_author&hl=en,kbDU8bEAAAAJ,google.com,PDF,https://drive.google.com/file/d/1YOsv_-nu2D3U0Z1yEh0eELakbkwZVX8S/view,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=FvkRRElcUpgJ,,,,,"https://scholar.google.com/scholar?q=related:FvkRRElcUpgJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,33",https://serpapi.com/search.json?as_sdt=0%2C33&engine=google_scholar&hl=en&num=20&q=related%3AFvkRRElcUpgJ%3Ascholar.google.com%2F&start=60,2.0,"https://scholar.google.com/scholar?cluster=10975936711599716630&hl=en&num=20&as_sdt=0,33",10975936711599716630,https://serpapi.com/search.json?as_sdt=0%2C33&cluster=10975936711599716630&engine=google_scholar&hl=en&num=20,,Z Zhang,https://scholar.google.com/citations?user=sG7WEAgAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=sG7WEAgAAAAJ&engine=google_scholar_author&hl=en,sG7WEAgAAAAJ,,,,,,,,,,,,,,,,
9,Opponent portrait for multiagent reinforcement learning in competitive environment,JPSjbFKf_CsJ,https://onlinelibrary.wiley.com/doi/abs/10.1002/int.22594,"… In the context of multiagent reinforcement learning (MARL), inference of opponent's … as knowledge to the knowledge graph (KG), 19 named opponent's behavior knowledge graph (OKG)…","Y Ma, M Shen, Y Zhao, Z Li, X Tong… - … Journal of Intelligent …, 2021 - Wiley Online Library",Y Zhao,https://scholar.google.com/citations?user=mp5Lv-cAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=mp5Lv-cAAAAJ&engine=google_scholar_author&hl=en,mp5Lv-cAAAAJ,,,,,,,,,,,,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=JPSjbFKf_CsJ,19.0,"https://scholar.google.com/scholar?cites=3169583414120805412&as_sdt=5,33&sciodt=0,33&hl=en&num=20",3169583414120805412,https://serpapi.com/search.json?as_sdt=5%2C33&cites=3169583414120805412&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:JPSjbFKf_CsJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,33",https://serpapi.com/search.json?as_sdt=0%2C33&engine=google_scholar&hl=en&num=20&q=related%3AJPSjbFKf_CsJ%3Ascholar.google.com%2F&start=60,3.0,"https://scholar.google.com/scholar?cluster=3169583414120805412&hl=en&num=20&as_sdt=0,33",3169583414120805412,https://serpapi.com/search.json?as_sdt=0%2C33&cluster=3169583414120805412&engine=google_scholar&hl=en&num=20,,,,,,,,,,,,,,,,,,,,,
10,Multi-Hop Temporal Knowledge Graph Reasoning with Multi-Agent Reinforcement Learning,cC7MggFcs7sJ,https://www.sciencedirect.com/science/article/pii/S1568494624005015,… of knowledge graph has gradually become a hot spot. This method finds the next relations through the reinforcement learning … We propose a multi-agent reinforcement learning model to …,"L Bai, M Chen, Q Xiao - Applied Soft Computing, 2024 - Elsevier",,,,,,,,,,,,,,,,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=cC7MggFcs7sJ,,,,,"https://scholar.google.com/scholar?q=related:cC7MggFcs7sJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,33",https://serpapi.com/search.json?as_sdt=0%2C33&engine=google_scholar&hl=en&num=20&q=related%3AcC7MggFcs7sJ%3Ascholar.google.com%2F&start=60,,,,,,,,,,,,,,,,,,,,,,,,,
11,A deep reinforcement learning method for mobile robot collision avoidance based on double dqn,YMGef8KOo3IJ,https://ieeexplore.ieee.org/abstract/document/8781522/,… Abstract—We propose a deep reinforcement learning method based on Double Q-learning … method focuses on using deep reinforcement learning to control the robots reaching the sub…,"X Xue, Z Li, D Zhang, Y Yan - 2019 IEEE 28th International …, 2019 - ieeexplore.ieee.org",Z Li,https://scholar.google.com/citations?user=DhQGAOEAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=DhQGAOEAAAAJ&engine=google_scholar_author&hl=en,DhQGAOEAAAAJ,,,,,,,,,,,,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=YMGef8KOo3IJ,48.0,"https://scholar.google.com/scholar?cites=8260603107543531872&as_sdt=5,33&sciodt=0,33&hl=en&num=20",8260603107543531872,https://serpapi.com/search.json?as_sdt=5%2C33&cites=8260603107543531872&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:YMGef8KOo3IJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,33",https://serpapi.com/search.json?as_sdt=0%2C33&engine=google_scholar&hl=en&num=20&q=related%3AYMGef8KOo3IJ%3Ascholar.google.com%2F&start=60,,,,,,,,,,,,,,,,,,,,,,,,,
12,Deep reinforcement learning: an overview,Lshwcghzf1wJ,https://link.springer.com/chapter/10.1007/978-3-319-56991-8_32,… be combined with reinforcement learning methods to learn … recent advances in deep reinforcement learning with focus on … Like DQN this work also uses ALE framework as testbed for …,"SS Mousavi, M Schukat, E Howley - Proceedings of SAI Intelligent Systems …, 2018 - Springer",SS Mousavi,https://scholar.google.com/citations?user=f1So9sUAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=f1So9sUAAAAJ&engine=google_scholar_author&hl=en,f1So9sUAAAAJ,M Schukat,https://scholar.google.com/citations?user=z_3p87AAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=z_3p87AAAAAJ&engine=google_scholar_author&hl=en,z_3p87AAAAAJ,E Howley,https://scholar.google.com/citations?user=29vbDa0AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=29vbDa0AAAAJ&engine=google_scholar_author&hl=en,29vbDa0AAAAJ,arxiv.org,PDF,https://arxiv.org/pdf/1806.08894,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=Lshwcghzf1wJ,436.0,"https://scholar.google.com/scholar?cites=6665172453648549934&as_sdt=5,33&sciodt=0,33&hl=en&num=20",6665172453648549934,https://serpapi.com/search.json?as_sdt=5%2C33&cites=6665172453648549934&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:Lshwcghzf1wJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,33",https://serpapi.com/search.json?as_sdt=0%2C33&engine=google_scholar&hl=en&num=20&q=related%3ALshwcghzf1wJ%3Ascholar.google.com%2F&start=60,4.0,"https://scholar.google.com/scholar?cluster=6665172453648549934&hl=en&num=20&as_sdt=0,33",6665172453648549934,https://serpapi.com/search.json?as_sdt=0%2C33&cluster=6665172453648549934&engine=google_scholar&hl=en&num=20,,,,,,,,,,,,,,,,,,,,,
13,Deep reinforcement learning for digital materials design,GfY30Qta_A0J,https://pubs.acs.org/doi/abs/10.1021/acsmaterialslett.1c00390,"… The updating process of the DQN algorithm is the core unit of our work and can be treated as a training process for the deep neural networks (DNNs), which can be used to estimate the …","F Sui, R Guo, Z Zhang, GX Gu, L Lin - ACS Materials Letters, 2021 - ACS Publications",F Sui,https://scholar.google.com/citations?user=ELh_nZ4AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=ELh_nZ4AAAAJ&engine=google_scholar_author&hl=en,ELh_nZ4AAAAJ,R Guo,https://scholar.google.com/citations?user=vYbZdzIAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=vYbZdzIAAAAJ&engine=google_scholar_author&hl=en,vYbZdzIAAAAJ,Z Zhang,https://scholar.google.com/citations?user=F0DrYcYAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=F0DrYcYAAAAJ&engine=google_scholar_author&hl=en,F0DrYcYAAAAJ,,,,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=GfY30Qta_A0J,60.0,"https://scholar.google.com/scholar?cites=1007779423425394201&as_sdt=5,33&sciodt=0,33&hl=en&num=20",1007779423425394201,https://serpapi.com/search.json?as_sdt=5%2C33&cites=1007779423425394201&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:GfY30Qta_A0J:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,33",https://serpapi.com/search.json?as_sdt=0%2C33&engine=google_scholar&hl=en&num=20&q=related%3AGfY30Qta_A0J%3Ascholar.google.com%2F&start=60,,,,,,GX Gu,https://scholar.google.com/citations?user=IE4UTWAAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=IE4UTWAAAAAJ&engine=google_scholar_author&hl=en,IE4UTWAAAAAJ,,L Lin,https://scholar.google.com/citations?user=FTe6HDoAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=FTe6HDoAAAAJ&engine=google_scholar_author&hl=en,FTe6HDoAAAAJ,,,,,,,,,,,
14,Deep reinforcement learning for dynamic multichannel access,i11TXniv4OoJ,http://csis.pace.edu/~benjamin/teaching/cs827/webfiles/DQN.pdf,… of DQN on traces obtained from a real indoor WSN deployment. We show that DQN has the … We investigate the use of Deep Reinforcement Learning from the field of machine learning …,"S Wang, H Liu, PH Gomes… - International Conference …, 2017 - csis.pace.edu",S Wang,https://scholar.google.com/citations?user=Bnv_t0sAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=Bnv_t0sAAAAJ&engine=google_scholar_author&hl=en,Bnv_t0sAAAAJ,H Liu,https://scholar.google.com/citations?user=9xkIAQcAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=9xkIAQcAAAAJ&engine=google_scholar_author&hl=en,9xkIAQcAAAAJ,PH Gomes,https://scholar.google.com/citations?user=SqtVOKUAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=SqtVOKUAAAAJ&engine=google_scholar_author&hl=en,SqtVOKUAAAAJ,pace.edu,PDF,http://csis.pace.edu/~benjamin/teaching/cs827/webfiles/DQN.pdf,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=i11TXniv4OoJ,41.0,"https://scholar.google.com/scholar?cites=16924720331171782027&as_sdt=5,33&sciodt=0,33&hl=en&num=20",16924720331171782027,https://serpapi.com/search.json?as_sdt=5%2C33&cites=16924720331171782027&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:i11TXniv4OoJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,33",https://serpapi.com/search.json?as_sdt=0%2C33&engine=google_scholar&hl=en&num=20&q=related%3Ai11TXniv4OoJ%3Ascholar.google.com%2F&start=60,3.0,"https://scholar.google.com/scholar?cluster=16924720331171782027&hl=en&num=20&as_sdt=0,33",16924720331171782027,https://serpapi.com/search.json?as_sdt=0%2C33&cluster=16924720331171782027&engine=google_scholar&hl=en&num=20,"http://scholar.googleusercontent.com/scholar?q=cache:i11TXniv4OoJ:scholar.google.com/+%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,33",,,,,Pdf,,,,,,,,,,,,,,,
15,Dkdr: An approach of knowledge graph and deep reinforcement learning for disease diagnosis,HbJwUFVTo_UJ,https://ieeexplore.ieee.org/abstract/document/9047423/,"… disease obtained from the knowledge graph. At the same time, … dint of Knowledge graph and Deep Reinforcement learning (… We combine the idea of reinforcement learning to find the …","Y Jia, Z Tan, J Zhang - 2019 IEEE Intl Conf on Parallel & …, 2019 - ieeexplore.ieee.org",,,,,,,,,,,,,,,,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=HbJwUFVTo_UJ,8.0,"https://scholar.google.com/scholar?cites=17700082586383069725&as_sdt=5,33&sciodt=0,33&hl=en&num=20",17700082586383069725,https://serpapi.com/search.json?as_sdt=5%2C33&cites=17700082586383069725&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:HbJwUFVTo_UJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,33",https://serpapi.com/search.json?as_sdt=0%2C33&engine=google_scholar&hl=en&num=20&q=related%3AHbJwUFVTo_UJ%3Ascholar.google.com%2F&start=60,2.0,"https://scholar.google.com/scholar?cluster=17700082586383069725&hl=en&num=20&as_sdt=0,33",17700082586383069725,https://serpapi.com/search.json?as_sdt=0%2C33&cluster=17700082586383069725&engine=google_scholar&hl=en&num=20,,,,,,,,,,,,,,,,,,,,,
16,Automated penetration testing using deep reinforcement learning,A_9HCbm2x8cJ,https://ieeexplore.ieee.org/abstract/document/9229752/,"… framework that employs deep reinforcement learning to automate the penetration … reinforcement learning algorithms. As a second stage, we employ the Deep QLearning Network (DQN) …","Z Hu, R Beuran, Y Tan - 2020 IEEE European Symposium on …, 2020 - ieeexplore.ieee.org",R Beuran,https://scholar.google.com/citations?user=ech873oAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=ech873oAAAAJ&engine=google_scholar_author&hl=en,ech873oAAAAJ,,,,,,,,,jaist.ac.jp,PDF,https://www.jaist.ac.jp/~razvan/publications/automated_penetration_testing_reinforcement_learning.pdf,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=A_9HCbm2x8cJ,90.0,"https://scholar.google.com/scholar?cites=14395675639753998083&as_sdt=5,33&sciodt=0,33&hl=en&num=20",14395675639753998083,https://serpapi.com/search.json?as_sdt=5%2C33&cites=14395675639753998083&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:A_9HCbm2x8cJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,33",https://serpapi.com/search.json?as_sdt=0%2C33&engine=google_scholar&hl=en&num=20&q=related%3AA_9HCbm2x8cJ%3Ascholar.google.com%2F&start=60,4.0,"https://scholar.google.com/scholar?cluster=14395675639753998083&hl=en&num=20&as_sdt=0,33",14395675639753998083,https://serpapi.com/search.json?as_sdt=0%2C33&cluster=14395675639753998083&engine=google_scholar&hl=en&num=20,,,,,,,,,,,,,,,,,,,,,
17,Deep reinforcement learning-based music recommendation with knowledge graph using acoustic features,JCB5GuwaCrIJ,https://www.jstage.jst.go.jp/article/mta/10/1/10_8/_article/-char/ja/,"… In this way, we apply a reinforcement learning algorithm to fit the task of music … dense knowledge graph by making recommendations using the optimized path on the knowledge graph. …","K Sakurai, R Togo, T Ogawa… - ITE Transactions on Media …, 2022 - jstage.jst.go.jp",K Sakurai,https://scholar.google.com/citations?user=ge3He7oAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=ge3He7oAAAAJ&engine=google_scholar_author&hl=en,ge3He7oAAAAJ,R Togo,https://scholar.google.com/citations?user=HNaVCtUAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=HNaVCtUAAAAJ&engine=google_scholar_author&hl=en,HNaVCtUAAAAJ,T Ogawa,https://scholar.google.com/citations?user=vPixFIsAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=vPixFIsAAAAJ&engine=google_scholar_author&hl=en,vPixFIsAAAAJ,jst.go.jp,PDF,https://www.jstage.jst.go.jp/article/mta/10/1/10_8/_pdf,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=JCB5GuwaCrIJ,9.0,"https://scholar.google.com/scholar?cites=12829096089877028900&as_sdt=5,33&sciodt=0,33&hl=en&num=20",12829096089877028900,https://serpapi.com/search.json?as_sdt=5%2C33&cites=12829096089877028900&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:JCB5GuwaCrIJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,33",https://serpapi.com/search.json?as_sdt=0%2C33&engine=google_scholar&hl=en&num=20&q=related%3AJCB5GuwaCrIJ%3Ascholar.google.com%2F&start=60,5.0,"https://scholar.google.com/scholar?cluster=12829096089877028900&hl=en&num=20&as_sdt=0,33",12829096089877028900,https://serpapi.com/search.json?as_sdt=0%2C33&cluster=12829096089877028900&engine=google_scholar&hl=en&num=20,,,,,,,,,,,,,,,,,,,,,
18,Deep reinforcement learning for greenhouse climate control,Rk7zS-iuvn4J,https://ieeexplore.ieee.org/abstract/document/9194467/,"… To solve these challenges, we propose a Deep Reinforcement learning based climate control method, which can model future reward explicitly. We further consider the fruit weight and …","L Wang, X He, D Luo - … Conference on Knowledge Graph …, 2020 - ieeexplore.ieee.org",L Wang,https://scholar.google.com/citations?user=hqlU92YAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=hqlU92YAAAAJ&engine=google_scholar_author&hl=en,hqlU92YAAAAJ,,,,,,,,,,,,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=Rk7zS-iuvn4J,23.0,"https://scholar.google.com/scholar?cites=9132929407083826758&as_sdt=5,33&sciodt=0,33&hl=en&num=20",9132929407083826758,https://serpapi.com/search.json?as_sdt=5%2C33&cites=9132929407083826758&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:Rk7zS-iuvn4J:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,33",https://serpapi.com/search.json?as_sdt=0%2C33&engine=google_scholar&hl=en&num=20&q=related%3ARk7zS-iuvn4J%3Ascholar.google.com%2F&start=60,3.0,"https://scholar.google.com/scholar?cluster=9132929407083826758&hl=en&num=20&as_sdt=0,33",9132929407083826758,https://serpapi.com/search.json?as_sdt=0%2C33&cluster=9132929407083826758&engine=google_scholar&hl=en&num=20,,,,,,,,,,,,,,,,,,,,,
19,3DCNN-DQN-RNN: A deep reinforcement learning framework for semantic parsing of large-scale 3D point clouds,x9nKGHj2TOwJ,http://openaccess.thecvf.com/content_iccv_2017/html/Liu_3DCNN-DQN-RNN_A_Deep_ICCV_2017_paper.html,"… (i) We propose a novel deep reinforcement learning model to precisely parse large-scale 3D point clouds. Most of the parameters in the 3DCNN-DQN-RNN are learned, and thus the …","F Liu, S Li, L Zhang, C Zhou, R Ye… - Proceedings of the …, 2017 - openaccess.thecvf.com",F Liu,https://scholar.google.com/citations?user=d19PiS0AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=d19PiS0AAAAJ&engine=google_scholar_author&hl=en,d19PiS0AAAAJ,S Li,https://scholar.google.com/citations?user=omssCtIAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=omssCtIAAAAJ&engine=google_scholar_author&hl=en,omssCtIAAAAJ,L Zhang,https://scholar.google.com/citations?user=UtZDhwgAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=UtZDhwgAAAAJ&engine=google_scholar_author&hl=en,UtZDhwgAAAAJ,thecvf.com,PDF,https://openaccess.thecvf.com/content_ICCV_2017/papers/Liu_3DCNN-DQN-RNN_A_Deep_ICCV_2017_paper.pdf,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=x9nKGHj2TOwJ,143.0,"https://scholar.google.com/scholar?cites=17027255286853458375&as_sdt=5,33&sciodt=0,33&hl=en&num=20",17027255286853458375,https://serpapi.com/search.json?as_sdt=5%2C33&cites=17027255286853458375&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:x9nKGHj2TOwJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,33",https://serpapi.com/search.json?as_sdt=0%2C33&engine=google_scholar&hl=en&num=20&q=related%3Ax9nKGHj2TOwJ%3Ascholar.google.com%2F&start=60,12.0,"https://scholar.google.com/scholar?cluster=17027255286853458375&hl=en&num=20&as_sdt=0,33",17027255286853458375,https://serpapi.com/search.json?as_sdt=0%2C33&cluster=17027255286853458375&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:x9nKGHj2TOwJ:scholar.google.com/+%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,33",R Ye,https://scholar.google.com/citations?user=xeRGQ5AAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=xeRGQ5AAAAAJ&engine=google_scholar_author&hl=en,xeRGQ5AAAAAJ,,,,,,,,,,,,,,,,
0,Asymmetric DQN for partially observable reinforcement learning,wGJViHCPWJ8J,https://proceedings.mlr.press/v180/baisero22a.html,"… environments allows reinforcement learning methods to exploit … in asymmetric reinforcement learning is often heuristic in … in Asymmetric DQN, a model-free deep reinforcement learning …","A Baisero, B Daley, C Amato - Uncertainty in Artificial …, 2022 - proceedings.mlr.press",A Baisero,https://scholar.google.com/citations?user=RHYFcckAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=RHYFcckAAAAJ&engine=google_scholar_author&hl=en,RHYFcckAAAAJ,B Daley,https://scholar.google.com/citations?user=PP2_bZ8AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=PP2_bZ8AAAAJ&engine=google_scholar_author&hl=en,PP2_bZ8AAAAJ,C Amato,https://scholar.google.com/citations?user=-8-sD-sAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=-8-sD-sAAAAJ&engine=google_scholar_author&hl=en,-8-sD-sAAAAJ,mlr.press,PDF,https://proceedings.mlr.press/v180/baisero22a/baisero22a.pdf,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=wGJViHCPWJ8J,8.0,"https://scholar.google.com/scholar?cites=11482084963467485888&as_sdt=80005&sciodt=0,11&hl=en&num=20",11482084963467485888,https://serpapi.com/search.json?as_sdt=80005&cites=11482084963467485888&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:wGJViHCPWJ8J:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,11",https://serpapi.com/search.json?as_sdt=0%2C11&engine=google_scholar&hl=en&num=20&q=related%3AwGJViHCPWJ8J%3Ascholar.google.com%2F&start=80,4.0,"https://scholar.google.com/scholar?cluster=11482084963467485888&hl=en&num=20&as_sdt=0,11",11482084963467485888,https://serpapi.com/search.json?as_sdt=0%2C11&cluster=11482084963467485888&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:wGJViHCPWJ8J:scholar.google.com/+%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,11",,,,,,,,,,,,,,,,,,,,
1,Poisoning attacks against knowledge graph-based recommendation systems using deep reinforcement learning,z4iFrrLAumUJ,https://link.springer.com/article/10.1007/s00521-021-06573-8,… We formulated the process into a deep reinforcement learning method. Conducting experiments on the movie and the fund data sets enabled us to systematically analyze our poisoning …,"ZW Wu, CT Chen, SH Huang - Neural Computing and Applications, 2022 - Springer",CT Chen,https://scholar.google.com/citations?user=7queDSUAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=7queDSUAAAAJ&engine=google_scholar_author&hl=en,7queDSUAAAAJ,SH Huang,https://scholar.google.com/citations?user=myXriUkAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=myXriUkAAAAJ&engine=google_scholar_author&hl=en,myXriUkAAAAJ,,,,,,,,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=z4iFrrLAumUJ,20.0,"https://scholar.google.com/scholar?cites=7330383217163602127&as_sdt=80005&sciodt=0,11&hl=en&num=20",7330383217163602127,https://serpapi.com/search.json?as_sdt=80005&cites=7330383217163602127&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:z4iFrrLAumUJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,11",https://serpapi.com/search.json?as_sdt=0%2C11&engine=google_scholar&hl=en&num=20&q=related%3Az4iFrrLAumUJ%3Ascholar.google.com%2F&start=80,5.0,"https://scholar.google.com/scholar?cluster=7330383217163602127&hl=en&num=20&as_sdt=0,11",7330383217163602127,https://serpapi.com/search.json?as_sdt=0%2C11&cluster=7330383217163602127&engine=google_scholar&hl=en&num=20,,,,,,,,,,,,,,,,,,,,,
2,An edge server placement method based on reinforcement learning,kq7g18NUVFgJ,https://www.mdpi.com/1099-4300/24/3/317,"… Different from the above methods, this paper proposes a novel edge server placement algorithm based on deep reinforcement learning, dubbed DQN-ESPA. First, the ESPP is modeled …","F Luo, S Zheng, W Ding, J Fuentes, Y Li - Entropy, 2022 - mdpi.com",J Fuentes,https://scholar.google.com/citations?user=jb2Ciy4AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=jb2Ciy4AAAAJ&engine=google_scholar_author&hl=en,jb2Ciy4AAAAJ,,,,,,,,,mdpi.com,PDF,https://www.mdpi.com/1099-4300/24/3/317/pdf,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=kq7g18NUVFgJ,15.0,"https://scholar.google.com/scholar?cites=6364805373498535570&as_sdt=80005&sciodt=0,11&hl=en&num=20",6364805373498535570,https://serpapi.com/search.json?as_sdt=80005&cites=6364805373498535570&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:kq7g18NUVFgJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,11",https://serpapi.com/search.json?as_sdt=0%2C11&engine=google_scholar&hl=en&num=20&q=related%3Akq7g18NUVFgJ%3Ascholar.google.com%2F&start=80,8.0,"https://scholar.google.com/scholar?cluster=6364805373498535570&hl=en&num=20&as_sdt=0,11",6364805373498535570,https://serpapi.com/search.json?as_sdt=0%2C11&cluster=6364805373498535570&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:kq7g18NUVFgJ:scholar.google.com/+%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,11",,,,,,,,,,,,,,,,,,,,
3,Deep-reinforcement-learning-based autonomous voltage control for power grid operations,DDqOvUTu6UEJ,https://ieeexplore.ieee.org/abstract/document/8834806/,"… summarizing the applications of reinforcement learning (RL) methods in power … DQN and DDPG methods have their own advantages and drawbacks. In general, the formulation of DQN …","J Duan, D Shi, R Diao, H Li, Z Wang… - … on Power Systems, 2019 - ieeexplore.ieee.org",J Duan,https://scholar.google.com/citations?user=mzb_rjwAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=mzb_rjwAAAAJ&engine=google_scholar_author&hl=en,mzb_rjwAAAAJ,D Shi,https://scholar.google.com/citations?user=3gfrp9EAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=3gfrp9EAAAAJ&engine=google_scholar_author&hl=en,3gfrp9EAAAAJ,R Diao,https://scholar.google.com/citations?user=t1jaia0AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=t1jaia0AAAAJ&engine=google_scholar_author&hl=en,t1jaia0AAAAJ,,,,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=DDqOvUTu6UEJ,332.0,"https://scholar.google.com/scholar?cites=4749589261044300300&as_sdt=80005&sciodt=0,11&hl=en&num=20",4749589261044300300,https://serpapi.com/search.json?as_sdt=80005&cites=4749589261044300300&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:DDqOvUTu6UEJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,11",https://serpapi.com/search.json?as_sdt=0%2C11&engine=google_scholar&hl=en&num=20&q=related%3ADDqOvUTu6UEJ%3Ascholar.google.com%2F&start=80,3.0,"https://scholar.google.com/scholar?cluster=4749589261044300300&hl=en&num=20&as_sdt=0,11",4749589261044300300,https://serpapi.com/search.json?as_sdt=0%2C11&cluster=4749589261044300300&engine=google_scholar&hl=en&num=20,,,,,,,,,,,,,,,,,,,,,
4,Deep reinforcement learning for trading,_JA4tJsNm5QJ,https://arxiv.org/abs/1911.10107,"… We adopt Deep Reinforcement Learning algorithms to design trading strategies for continuous … We compare the above baseline models with our RL algorithms, DQN, PG and A2C. DQN …","Z Zhang, S Zohren, S Roberts - arXiv preprint arXiv:1911.10107, 2019 - arxiv.org",Z Zhang,https://scholar.google.com/citations?user=ros4PE0AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=ros4PE0AAAAJ&engine=google_scholar_author&hl=en,ros4PE0AAAAJ,S Zohren,https://scholar.google.com/citations?user=mtNQD-8AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=mtNQD-8AAAAJ&engine=google_scholar_author&hl=en,mtNQD-8AAAAJ,S Roberts,https://scholar.google.com/citations?user=T1lNNLkAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=T1lNNLkAAAAJ&engine=google_scholar_author&hl=en,T1lNNLkAAAAJ,arxiv.org,PDF,https://arxiv.org/pdf/1911.10107,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=_JA4tJsNm5QJ,216.0,"https://scholar.google.com/scholar?cites=10708167501398184188&as_sdt=80005&sciodt=0,11&hl=en&num=20",10708167501398184188,https://serpapi.com/search.json?as_sdt=80005&cites=10708167501398184188&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:_JA4tJsNm5QJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,11",https://serpapi.com/search.json?as_sdt=0%2C11&engine=google_scholar&hl=en&num=20&q=related%3A_JA4tJsNm5QJ%3Ascholar.google.com%2F&start=80,14.0,"https://scholar.google.com/scholar?cluster=10708167501398184188&hl=en&num=20&as_sdt=0,11",10708167501398184188,https://serpapi.com/search.json?as_sdt=0%2C11&cluster=10708167501398184188&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:_JA4tJsNm5QJ:scholar.google.com/+%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,11",,,,,,,,,,,,,,,,,,,,
5,Reinforcement learning,brb2thL4_G0J,https://link.springer.com/content/pdf/10.1007/978-1-4842-7915-1_14?pdf=chapter%20toc,"… In this chapter, we will introduce the mainstream algorithms in reinforcement learning, including the DQN algorithm for achieving human-like level in games such as Space Invaders, …","D Silver - University Lecture, University College London, 2015 - Springer",D Silver,https://scholar.google.com/citations?user=-8DNE4UAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=-8DNE4UAAAAJ&engine=google_scholar_author&hl=en,-8DNE4UAAAAJ,,,,,,,,,,,,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=brb2thL4_G0J,17.0,"https://scholar.google.com/scholar?cites=7925482203527951982&as_sdt=80005&sciodt=0,11&hl=en&num=20",7925482203527951982,https://serpapi.com/search.json?as_sdt=80005&cites=7925482203527951982&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:brb2thL4_G0J:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,11",https://serpapi.com/search.json?as_sdt=0%2C11&engine=google_scholar&hl=en&num=20&q=related%3Abrb2thL4_G0J%3Ascholar.google.com%2F&start=80,,,,,,,,,,,,,,,,,,,,,,,,,
6,Deep reinforcement learning with pomdps,hLuQbbHAQBQJ,https://cs229.stanford.edu/proj2015/363_report.pdf,… a reinforcement learning approach for POMDPs that maps an action-observation history to an optimal action using a DQN. … against the DQN approach to reinforcement learning with …,"M Egorov - Tech. Rep.(Technical Report, Stanford University …, 2015 - cs229.stanford.edu",M Egorov,https://scholar.google.com/citations?user=fJn4gFIAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=fJn4gFIAAAAJ&engine=google_scholar_author&hl=en,fJn4gFIAAAAJ,,,,,,,,,stanford.edu,PDF,https://cs229.stanford.edu/proj2015/363_report.pdf,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=hLuQbbHAQBQJ,32.0,"https://scholar.google.com/scholar?cites=1459378147547986820&as_sdt=80005&sciodt=0,11&hl=en&num=20",1459378147547986820,https://serpapi.com/search.json?as_sdt=80005&cites=1459378147547986820&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:hLuQbbHAQBQJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,11",https://serpapi.com/search.json?as_sdt=0%2C11&engine=google_scholar&hl=en&num=20&q=related%3AhLuQbbHAQBQJ%3Ascholar.google.com%2F&start=80,,,,,"https://scholar.googleusercontent.com/scholar?q=cache:hLuQbbHAQBQJ:scholar.google.com/+%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,11",,,,,Pdf,,,,,,,,,,,,,,,
7,Accelerated methods for deep reinforcement learning,ardMq5_EkYwJ,https://arxiv.org/abs/1803.02811,"… DQN: We experimented with batch … DQN to learn well using up to 4 GPU learners, each using batch size 512. Categorical DQN: We found Categorical DQN to scale further than DQN. …","A Stooke, P Abbeel - arXiv preprint arXiv:1803.02811, 2018 - arxiv.org",A Stooke,https://scholar.google.com/citations?user=whdanWAAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=whdanWAAAAAJ&engine=google_scholar_author&hl=en,whdanWAAAAAJ,P Abbeel,https://scholar.google.com/citations?user=vtwH6GkAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=vtwH6GkAAAAJ&engine=google_scholar_author&hl=en,vtwH6GkAAAAJ,,,,,arxiv.org,PDF,https://arxiv.org/pdf/1803.02811,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=ardMq5_EkYwJ,138.0,"https://scholar.google.com/scholar?cites=10129093226985731946&as_sdt=80005&sciodt=0,11&hl=en&num=20",10129093226985731946,https://serpapi.com/search.json?as_sdt=80005&cites=10129093226985731946&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:ardMq5_EkYwJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,11",https://serpapi.com/search.json?as_sdt=0%2C11&engine=google_scholar&hl=en&num=20&q=related%3AardMq5_EkYwJ%3Ascholar.google.com%2F&start=80,2.0,"https://scholar.google.com/scholar?cluster=10129093226985731946&hl=en&num=20&as_sdt=0,11",10129093226985731946,https://serpapi.com/search.json?as_sdt=0%2C11&cluster=10129093226985731946&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:ardMq5_EkYwJ:scholar.google.com/+%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,11",,,,,,,,,,,,,,,,,,,,
8,Towards robust knowledge graph embedding via multi-task reinforcement learning,3xJDkD4TJ3kJ,https://ieeexplore.ieee.org/abstract/document/9615000/,"… However, most existing knowledge graph … task reinforcement learning framework, which can greatly alleviate the noisy data problem. In our framework, we exploit reinforcement learning …","Z Zhang, F Zhuang, H Zhu, C Li… - … on Knowledge and …, 2021 - ieeexplore.ieee.org",Z Zhang,https://scholar.google.com/citations?user=i8a07CgAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=i8a07CgAAAAJ&engine=google_scholar_author&hl=en,i8a07CgAAAAJ,F Zhuang,https://scholar.google.com/citations?user=klJBYrAAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=klJBYrAAAAAJ&engine=google_scholar_author&hl=en,klJBYrAAAAAJ,H Zhu,https://scholar.google.com/citations?user=55MQBzYAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=55MQBzYAAAAJ&engine=google_scholar_author&hl=en,55MQBzYAAAAJ,arxiv.org,PDF,https://arxiv.org/pdf/2111.06103,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=3xJDkD4TJ3kJ,6.0,"https://scholar.google.com/scholar?cites=8729967562110210783&as_sdt=80005&sciodt=0,11&hl=en&num=20",8729967562110210783,https://serpapi.com/search.json?as_sdt=80005&cites=8729967562110210783&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:3xJDkD4TJ3kJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,11",https://serpapi.com/search.json?as_sdt=0%2C11&engine=google_scholar&hl=en&num=20&q=related%3A3xJDkD4TJ3kJ%3Ascholar.google.com%2F&start=80,7.0,"https://scholar.google.com/scholar?cluster=8729967562110210783&hl=en&num=20&as_sdt=0,11",8729967562110210783,https://serpapi.com/search.json?as_sdt=0%2C11&cluster=8729967562110210783&engine=google_scholar&hl=en&num=20,,C Li,https://scholar.google.com/citations?user=gF8h0HMAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=gF8h0HMAAAAJ&engine=google_scholar_author&hl=en,gF8h0HMAAAAJ,,,,,,,,,,,,,,,,
9,Deep reinforcement learning for semiconductor production scheduling,IS58yj4ncvwJ,https://ieeexplore.ieee.org/abstract/document/8373191/,… (DQN) agent algorithm for Reinforcement Learning (RL) to semiconductor production scheduling. In an RL environment several cooperative DQN … heuristics with the DQN agents in an …,"B Waschneck, A Reichstaller, L Belzner… - 2018 29th annual …, 2018 - ieeexplore.ieee.org",B Waschneck,https://scholar.google.com/citations?user=G4oK_VQAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=G4oK_VQAAAAJ&engine=google_scholar_author&hl=en,G4oK_VQAAAAJ,A Reichstaller,https://scholar.google.com/citations?user=m5Gy9jAAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=m5Gy9jAAAAAJ&engine=google_scholar_author&hl=en,m5Gy9jAAAAAJ,L Belzner,https://scholar.google.com/citations?user=mtPandAAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=mtPandAAAAAJ&engine=google_scholar_author&hl=en,mtPandAAAAAJ,researchgate.net,PDF,https://www.researchgate.net/profile/Lenz-Belzner/publication/325713164_Deep_reinforcement_learning_for_semiconductor_production_scheduling/links/5be537caa6fdcc3a8dc89fb3/Deep-reinforcement-learning-for-semiconductor-production-scheduling.pdf,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=IS58yj4ncvwJ,139.0,"https://scholar.google.com/scholar?cites=18190644995541446177&as_sdt=80005&sciodt=0,11&hl=en&num=20",18190644995541446177,https://serpapi.com/search.json?as_sdt=80005&cites=18190644995541446177&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:IS58yj4ncvwJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,11",https://serpapi.com/search.json?as_sdt=0%2C11&engine=google_scholar&hl=en&num=20&q=related%3AIS58yj4ncvwJ%3Ascholar.google.com%2F&start=80,3.0,"https://scholar.google.com/scholar?cluster=18190644995541446177&hl=en&num=20&as_sdt=0,11",18190644995541446177,https://serpapi.com/search.json?as_sdt=0%2C11&cluster=18190644995541446177&engine=google_scholar&hl=en&num=20,,,,,,,,,,,,,,,,,,,,,
10,A reinforcement learning approach to irrigation decision-making for rice using weather forecasts,zhkccMZFVK8J,https://www.sciencedirect.com/science/article/pii/S0378377421001037,"… The rainfall forecast is the main variable of the DQN irrigation … with the DQN algorithm for irrigation decision-making. … , (2) to propose a reinforcement learning strategy based on DQN for …","M Chen, Y Cui, X Wang, H Xie, F Liu, T Luo… - Agricultural Water …, 2021 - Elsevier",,,,,,,,,,,,,sciencedirect.com,HTML,https://www.sciencedirect.com/science/article/pii/S0378377421001037,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=zhkccMZFVK8J,61.0,"https://scholar.google.com/scholar?cites=12633799573267814862&as_sdt=80005&sciodt=0,11&hl=en&num=20",12633799573267814862,https://serpapi.com/search.json?as_sdt=80005&cites=12633799573267814862&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:zhkccMZFVK8J:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,11",https://serpapi.com/search.json?as_sdt=0%2C11&engine=google_scholar&hl=en&num=20&q=related%3AzhkccMZFVK8J%3Ascholar.google.com%2F&start=80,6.0,"https://scholar.google.com/scholar?cluster=12633799573267814862&hl=en&num=20&as_sdt=0,11",12633799573267814862,https://serpapi.com/search.json?as_sdt=0%2C11&cluster=12633799573267814862&engine=google_scholar&hl=en&num=20,,,,,,Html,,,,,https://www.sciencedirect.com/science/article/pii/S0378377421001037,,,,,,,,,,
11,Deep reinforcement learning for resource protection and real-time detection in IoT environment,GxKE5dv61MAJ,https://ieeexplore.ieee.org/abstract/document/9000524/,"… In this article, a fast deep-reinforcement-learning (DRL)-based … Additionally, DQN can establish two neural networks with the … So thus, this article utilized the DQN algorithm for the …","W Liang, W Huang, J Long, K Zhang… - IEEE Internet of …, 2020 - ieeexplore.ieee.org",W Liang,https://scholar.google.com/citations?user=lgK7k8QAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=lgK7k8QAAAAJ&engine=google_scholar_author&hl=en,lgK7k8QAAAAJ,K Zhang,https://scholar.google.com/citations?user=P6OgLjoAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=P6OgLjoAAAAJ&engine=google_scholar_author&hl=en,P6OgLjoAAAAJ,,,,,,,,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=GxKE5dv61MAJ,175.0,"https://scholar.google.com/scholar?cites=13895006572700242459&as_sdt=80005&sciodt=0,11&hl=en&num=20",13895006572700242459,https://serpapi.com/search.json?as_sdt=80005&cites=13895006572700242459&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:GxKE5dv61MAJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,11",https://serpapi.com/search.json?as_sdt=0%2C11&engine=google_scholar&hl=en&num=20&q=related%3AGxKE5dv61MAJ%3Ascholar.google.com%2F&start=80,2.0,"https://scholar.google.com/scholar?cluster=13895006572700242459&hl=en&num=20&as_sdt=0,11",13895006572700242459,https://serpapi.com/search.json?as_sdt=0%2C11&cluster=13895006572700242459&engine=google_scholar&hl=en&num=20,,,,,,,,,,,,,,,,,,,,,
12,Deep multi-agent reinforcement learning with relevance graphs,Y8AWY6_R2vkJ,https://arxiv.org/abs/1811.12557,… ) reinforcement learning techniques that were applied to multi-agent domains. The algorithms introduced below (DQN… The majority of work in the area of reinforcement learning applies a …,"A Malysheva, TT Sung, CB Sohn, D Kudenko… - arXiv preprint arXiv …, 2018 - arxiv.org",A Malysheva,https://scholar.google.com/citations?user=_VCRZzkAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=_VCRZzkAAAAJ&engine=google_scholar_author&hl=en,_VCRZzkAAAAJ,TT Sung,https://scholar.google.com/citations?user=Hy8aDpkAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=Hy8aDpkAAAAJ&engine=google_scholar_author&hl=en,Hy8aDpkAAAAJ,CB Sohn,https://scholar.google.com/citations?user=F6qqDGQAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=F6qqDGQAAAAJ&engine=google_scholar_author&hl=en,F6qqDGQAAAAJ,arxiv.org,PDF,https://arxiv.org/pdf/1811.12557,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=Y8AWY6_R2vkJ,52.0,"https://scholar.google.com/scholar?cites=18003933011578896483&as_sdt=80005&sciodt=0,11&hl=en&num=20",18003933011578896483,https://serpapi.com/search.json?as_sdt=80005&cites=18003933011578896483&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:Y8AWY6_R2vkJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,11",https://serpapi.com/search.json?as_sdt=0%2C11&engine=google_scholar&hl=en&num=20&q=related%3AY8AWY6_R2vkJ%3Ascholar.google.com%2F&start=80,3.0,"https://scholar.google.com/scholar?cluster=18003933011578896483&hl=en&num=20&as_sdt=0,11",18003933011578896483,https://serpapi.com/search.json?as_sdt=0%2C11&cluster=18003933011578896483&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:Y8AWY6_R2vkJ:scholar.google.com/+%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,11",D Kudenko,https://scholar.google.com/citations?user=uUXUMukAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=uUXUMukAAAAJ&engine=google_scholar_author&hl=en,uUXUMukAAAAJ,,,,,,,,,,,,,,,,
13,Opponent modeling in deep reinforcement learning,-veKtEyjwhgJ,https://proceedings.mlr.press/v48/he16.html,"… Inspired by the recent success of deep reinforcement learning, we present neural-… DQN-world, we also compare with DQN-self, a baseline without interaction with opponents at all. DQN-…","H He, J Boyd-Graber, K Kwok… - … conference on machine …, 2016 - proceedings.mlr.press",H He,https://scholar.google.com/citations?user=K-isjagAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=K-isjagAAAAJ&engine=google_scholar_author&hl=en,K-isjagAAAAJ,J Boyd-Graber,https://scholar.google.com/citations?user=BT4XTP4AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=BT4XTP4AAAAJ&engine=google_scholar_author&hl=en,BT4XTP4AAAAJ,K Kwok,https://scholar.google.com/citations?user=t_iLVOoAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=t_iLVOoAAAAJ&engine=google_scholar_author&hl=en,t_iLVOoAAAAJ,mlr.press,PDF,http://proceedings.mlr.press/v48/he16.pdf,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=-veKtEyjwhgJ,353.0,"https://scholar.google.com/scholar?cites=1784167952233986042&as_sdt=80005&sciodt=0,11&hl=en&num=20",1784167952233986042,https://serpapi.com/search.json?as_sdt=80005&cites=1784167952233986042&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:-veKtEyjwhgJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,11",https://serpapi.com/search.json?as_sdt=0%2C11&engine=google_scholar&hl=en&num=20&q=related%3A-veKtEyjwhgJ%3Ascholar.google.com%2F&start=80,18.0,"https://scholar.google.com/scholar?cluster=1784167952233986042&hl=en&num=20&as_sdt=0,11",1784167952233986042,https://serpapi.com/search.json?as_sdt=0%2C11&cluster=1784167952233986042&engine=google_scholar&hl=en&num=20,"http://scholar.googleusercontent.com/scholar?q=cache:-veKtEyjwhgJ:scholar.google.com/+%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,11",,,,,,,,,,,,,,,,,,,,
14,Deep reinforcement learning with modulated hebbian plus Q-network architecture,CSD-wY-8wv8J,https://ieeexplore.ieee.org/abstract/document/9547670/,… by two aspects which are problematic for reinforcement learning (RL) algorithms: 1) … DQN body are summarized in supplementary Material 1. Both the DQN head and the DQN …,"P Ladosz, E Ben-Iwhiwhu, J Dick, N Ketz… - … on Neural Networks …, 2021 - ieeexplore.ieee.org",P Ladosz,https://scholar.google.com/citations?user=fSEWVN8AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=fSEWVN8AAAAJ&engine=google_scholar_author&hl=en,fSEWVN8AAAAJ,J Dick,https://scholar.google.com/citations?user=u7bPwBMAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=u7bPwBMAAAAJ&engine=google_scholar_author&hl=en,u7bPwBMAAAAJ,N Ketz,https://scholar.google.com/citations?user=VOvR0i8AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=VOvR0i8AAAAJ&engine=google_scholar_author&hl=en,VOvR0i8AAAAJ,arxiv.org,PDF,https://arxiv.org/pdf/1909.09902,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=CSD-wY-8wv8J,16.0,"https://scholar.google.com/scholar?cites=18429499950774493193&as_sdt=80005&sciodt=0,11&hl=en&num=20",18429499950774493193,https://serpapi.com/search.json?as_sdt=80005&cites=18429499950774493193&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:CSD-wY-8wv8J:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,11",https://serpapi.com/search.json?as_sdt=0%2C11&engine=google_scholar&hl=en&num=20&q=related%3ACSD-wY-8wv8J%3Ascholar.google.com%2F&start=80,9.0,"https://scholar.google.com/scholar?cluster=18429499950774493193&hl=en&num=20&as_sdt=0,11",18429499950774493193,https://serpapi.com/search.json?as_sdt=0%2C11&cluster=18429499950774493193&engine=google_scholar&hl=en&num=20,,,,,,,,,,,,,,,,,,,,,
15,Controllable music playlist generation based on knowledge graph and reinforcement learning,Lx343KOKTPgJ,https://www.mdpi.com/1424-8220/22/10/3722,"… based on a knowledge graph and reinforcement learning. The … To overcome the difficulty, we use a reinforcement learning … : using the informative knowledge graph data to promote …","K Sakurai, R Togo, T Ogawa, M Haseyama - Sensors, 2022 - mdpi.com",K Sakurai,https://scholar.google.com/citations?user=ge3He7oAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=ge3He7oAAAAJ&engine=google_scholar_author&hl=en,ge3He7oAAAAJ,R Togo,https://scholar.google.com/citations?user=HNaVCtUAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=HNaVCtUAAAAJ&engine=google_scholar_author&hl=en,HNaVCtUAAAAJ,T Ogawa,https://scholar.google.com/citations?user=vPixFIsAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=vPixFIsAAAAJ&engine=google_scholar_author&hl=en,vPixFIsAAAAJ,mdpi.com,PDF,https://www.mdpi.com/1424-8220/22/10/3722/pdf,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=Lx343KOKTPgJ,5.0,"https://scholar.google.com/scholar?cites=17891827856027688239&as_sdt=80005&sciodt=0,11&hl=en&num=20",17891827856027688239,https://serpapi.com/search.json?as_sdt=80005&cites=17891827856027688239&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:Lx343KOKTPgJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,11",https://serpapi.com/search.json?as_sdt=0%2C11&engine=google_scholar&hl=en&num=20&q=related%3ALx343KOKTPgJ%3Ascholar.google.com%2F&start=80,11.0,"https://scholar.google.com/scholar?cluster=17891827856027688239&hl=en&num=20&as_sdt=0,11",17891827856027688239,https://serpapi.com/search.json?as_sdt=0%2C11&cluster=17891827856027688239&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:Lx343KOKTPgJ:scholar.google.com/+%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,11",M Haseyama,https://scholar.google.com/citations?user=ubMXV98AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=ubMXV98AAAAJ&engine=google_scholar_author&hl=en,ubMXV98AAAAJ,,,,,,,,,,,,,,,,
16,Parametrized deep q-networks learning: Reinforcement learning with discrete-continuous hybrid action space,ddZc758RuQcJ,https://arxiv.org/abs/1810.06394,"… DQN with discrete action approximation is also compared in the simulation example. In DQN and P-DQN, we … We compare the proposed P-DQN with DDPG architecture using the same …","J Xiong, Q Wang, Z Yang, P Sun, L Han… - arXiv preprint arXiv …, 2018 - arxiv.org",J Xiong,https://scholar.google.com/citations?user=X8YIcKEAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=X8YIcKEAAAAJ&engine=google_scholar_author&hl=en,X8YIcKEAAAAJ,Q Wang,https://scholar.google.com/citations?user=fivHT0MAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=fivHT0MAAAAJ&engine=google_scholar_author&hl=en,fivHT0MAAAAJ,L Han,https://scholar.google.com/citations?user=Tz4_zi8AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=Tz4_zi8AAAAJ&engine=google_scholar_author&hl=en,Tz4_zi8AAAAJ,arxiv.org,PDF,https://arxiv.org/pdf/1810.06394,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=ddZc758RuQcJ,190.0,"https://scholar.google.com/scholar?cites=556495407570278005&as_sdt=80005&sciodt=0,11&hl=en&num=20",556495407570278005,https://serpapi.com/search.json?as_sdt=80005&cites=556495407570278005&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:ddZc758RuQcJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,11",https://serpapi.com/search.json?as_sdt=0%2C11&engine=google_scholar&hl=en&num=20&q=related%3AddZc758RuQcJ%3Ascholar.google.com%2F&start=80,2.0,"https://scholar.google.com/scholar?cluster=556495407570278005&hl=en&num=20&as_sdt=0,11",556495407570278005,https://serpapi.com/search.json?as_sdt=0%2C11&cluster=556495407570278005&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:ddZc758RuQcJ:scholar.google.com/+%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,11",,,,,,,,,,,,,,,,,,,,
17,Action branching architectures for deep reinforcement learning,Psmqvpn4L_4J,https://ojs.aaai.org/index.php/AAAI/article/view/11798,"… Here we introduce various methods for adapting the DQN algorithm, as well as its notable … For brevity, we mainly focus on the methods that result in our best performing DQN-based …","A Tavakoli, F Pardo, P Kormushev - … of the aaai conference on artificial …, 2018 - ojs.aaai.org",A Tavakoli,https://scholar.google.com/citations?user=Jwq-Qx0AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=Jwq-Qx0AAAAJ&engine=google_scholar_author&hl=en,Jwq-Qx0AAAAJ,F Pardo,https://scholar.google.com/citations?user=LDpuKxkAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=LDpuKxkAAAAJ&engine=google_scholar_author&hl=en,LDpuKxkAAAAJ,P Kormushev,https://scholar.google.com/citations?user=z6CxsHsAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=z6CxsHsAAAAJ&engine=google_scholar_author&hl=en,z6CxsHsAAAAJ,aaai.org,PDF,https://ojs.aaai.org/index.php/AAAI/article/view/11798/11657,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=Psmqvpn4L_4J,278.0,"https://scholar.google.com/scholar?cites=18316131548751644990&as_sdt=80005&sciodt=0,11&hl=en&num=20",18316131548751644990,https://serpapi.com/search.json?as_sdt=80005&cites=18316131548751644990&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:Psmqvpn4L_4J:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,11",https://serpapi.com/search.json?as_sdt=0%2C11&engine=google_scholar&hl=en&num=20&q=related%3APsmqvpn4L_4J%3Ascholar.google.com%2F&start=80,13.0,"https://scholar.google.com/scholar?cluster=18316131548751644990&hl=en&num=20&as_sdt=0,11",18316131548751644990,https://serpapi.com/search.json?as_sdt=0%2C11&cluster=18316131548751644990&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:Psmqvpn4L_4J:scholar.google.com/+%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,11",,,,,,,,,,,,,,,,,,,,
18,Massively parallel methods for deep reinforcement learning,q35wP0HmVrAJ,https://arxiv.org/abs/1507.04296,"… In this work, our goal is to build a distributed architecture that enables us to scale up deep reinforcement learning algorithms such as DQN by exploiting massive computational …","A Nair, P Srinivasan, S Blackwell, C Alcicek… - arXiv preprint arXiv …, 2015 - arxiv.org",S Blackwell,https://scholar.google.com/citations?user=ilWwid4AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=ilWwid4AAAAJ&engine=google_scholar_author&hl=en,ilWwid4AAAAJ,,,,,,,,,arxiv.org,PDF,"https://arxiv.org/pdf/1507.04296.pdf),",https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=q35wP0HmVrAJ,618.0,"https://scholar.google.com/scholar?cites=12706596566584032939&as_sdt=80005&sciodt=0,11&hl=en&num=20",12706596566584032939,https://serpapi.com/search.json?as_sdt=80005&cites=12706596566584032939&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:q35wP0HmVrAJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,11",https://serpapi.com/search.json?as_sdt=0%2C11&engine=google_scholar&hl=en&num=20&q=related%3Aq35wP0HmVrAJ%3Ascholar.google.com%2F&start=80,5.0,"https://scholar.google.com/scholar?cluster=12706596566584032939&hl=en&num=20&as_sdt=0,11",12706596566584032939,https://serpapi.com/search.json?as_sdt=0%2C11&cluster=12706596566584032939&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:q35wP0HmVrAJ:scholar.google.com/+%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,11",,,,,,,,,,,,,,,,,,,,
19,Towards knowledge transfer in deep reinforcement learning,cWKf8exU6NsJ,https://ieeexplore.ieee.org/abstract/document/7839568/,… for DQN and what consequences arise for the learning agent when TL is blindly applied. Our proposal in this article is to train a DQN in a source task and reuse the trained DQN for the …,"R Glatt, FL Da Silva, AHR Costa - 2016 5th Brazilian …, 2016 - ieeexplore.ieee.org",R Glatt,https://scholar.google.com/citations?user=XVfDYnAAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=XVfDYnAAAAAJ&engine=google_scholar_author&hl=en,XVfDYnAAAAAJ,FL Da Silva,https://scholar.google.com/citations?user=XbyIZQ4AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=XbyIZQ4AAAAJ&engine=google_scholar_author&hl=en,XbyIZQ4AAAAJ,AHR Costa,https://scholar.google.com/citations?user=MGAVI6EAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=MGAVI6EAAAAJ&engine=google_scholar_author&hl=en,MGAVI6EAAAAJ,143.54.25.88,PDF,http://143.54.25.88/index.php/bracis/article/download/95/82,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=cWKf8exU6NsJ,53.0,"https://scholar.google.com/scholar?cites=15846008665545859697&as_sdt=80005&sciodt=0,11&hl=en&num=20",15846008665545859697,https://serpapi.com/search.json?as_sdt=80005&cites=15846008665545859697&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:cWKf8exU6NsJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+(%22aixi%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22)&hl=en&num=20&as_sdt=0,11",https://serpapi.com/search.json?as_sdt=0%2C11&engine=google_scholar&hl=en&num=20&q=related%3AcWKf8exU6NsJ%3Ascholar.google.com%2F&start=80,6.0,"https://scholar.google.com/scholar?cluster=15846008665545859697&hl=en&num=20&as_sdt=0,11",15846008665545859697,https://serpapi.com/search.json?as_sdt=0%2C11&cluster=15846008665545859697&engine=google_scholar&hl=en&num=20,,,,,,,,,,,,,,,,,,,,,
