position,title,result_id,link,snippet,publication_info_summary,publication_info_authors_0_name,publication_info_authors_0_link,publication_info_authors_0_serpapi_scholar_link,publication_info_authors_0_author_id,publication_info_authors_1_name,publication_info_authors_1_link,publication_info_authors_1_serpapi_scholar_link,publication_info_authors_1_author_id,publication_info_authors_2_name,publication_info_authors_2_link,publication_info_authors_2_serpapi_scholar_link,publication_info_authors_2_author_id,resources_0_title,resources_0_file_format,resources_0_link,inline_links_serpapi_cite_link,inline_links_cited_by_total,inline_links_cited_by_link,inline_links_cited_by_cites_id,inline_links_cited_by_serpapi_scholar_link,inline_links_related_pages_link,inline_links_serpapi_related_pages_link,inline_links_versions_total,inline_links_versions_link,inline_links_versions_cluster_id,inline_links_versions_serpapi_scholar_link,inline_links_cached_page_link,type,inline_links_html_version,publication_info_authors_3_name,publication_info_authors_3_link,publication_info_authors_3_serpapi_scholar_link,publication_info_authors_3_author_id
0,Bayesian reinforcement learning: A survey,3zVnN4hjXvsJ,https://www.nowpublishers.com/article/Details/MAL-049,… of Bayesian methods for the reinforcement learning (RL) paradigm. The major incentives for incorporating Bayesian … We first discuss models and methods for Bayesian inference in the …,"M Ghavamzadeh, S Mannor, J Pineau… - … and Trends® in …, 2015 - nowpublishers.com",M Ghavamzadeh,https://scholar.google.com/citations?user=Bo-wyrkAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=Bo-wyrkAAAAJ&engine=google_scholar_author&hl=en,Bo-wyrkAAAAJ,S Mannor,https://scholar.google.com/citations?user=q1HlbIUAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=q1HlbIUAAAAJ&engine=google_scholar_author&hl=en,q1HlbIUAAAAJ,J Pineau,https://scholar.google.com/citations?user=CEt6_mMAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=CEt6_mMAAAAJ&engine=google_scholar_author&hl=en,CEt6_mMAAAAJ,nowpublishers.com,PDF,https://www.nowpublishers.com/article/DownloadSummary/MAL-049,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=3zVnN4hjXvsJ,531,"https://scholar.google.com/scholar?cites=18113024188026926559&as_sdt=80005&sciodt=0,11&hl=en&num=20",18113024188026926559,https://serpapi.com/search.json?as_sdt=80005&cites=18113024188026926559&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:3zVnN4hjXvsJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+%22aixi%22+OR+%22bayes%22+OR+%22bayesian%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22+OR+%22knowledge+base%22)&hl=en&num=20&as_sdt=0,11",https://serpapi.com/search.json?as_sdt=0%2C11&engine=google_scholar&hl=en&num=20&q=related%3A3zVnN4hjXvsJ%3Ascholar.google.com%2F&start=0,13,"https://scholar.google.com/scholar?cluster=18113024188026926559&hl=en&num=20&as_sdt=0,11",18113024188026926559,https://serpapi.com/search.json?as_sdt=0%2C11&cluster=18113024188026926559&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:3zVnN4hjXvsJ:scholar.google.com/+%22reinforcement+learning%22+AND+%22aixi%22+OR+%22bayes%22+OR+%22bayesian%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22+OR+%22knowledge+base%22)&hl=en&num=20&as_sdt=0,11",,,,,,
1,Bayesian reinforcement learning,18PTp0x1v2cJ,https://link.springer.com/chapter/10.1007/978-3-642-27645-3_11,"… This chapter surveys recent lines of work that use Bayesian techniques for reinforcement learning. In Bayesian learning, uncertainty is expressed by a prior distribution over unknown …","N Vlassis, M Ghavamzadeh, S Mannor… - Reinforcement Learning …, 2012 - Springer",N Vlassis,https://scholar.google.com/citations?user=JJWWPjsAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=JJWWPjsAAAAJ&engine=google_scholar_author&hl=en,JJWWPjsAAAAJ,M Ghavamzadeh,https://scholar.google.com/citations?user=Bo-wyrkAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=Bo-wyrkAAAAJ&engine=google_scholar_author&hl=en,Bo-wyrkAAAAJ,S Mannor,https://scholar.google.com/citations?user=q1HlbIUAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=q1HlbIUAAAAJ&engine=google_scholar_author&hl=en,q1HlbIUAAAAJ,uni.lu,PDF,https://orbilu.uni.lu/bitstream/10993/3390/1/BRLchapter.pdf,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=18PTp0x1v2cJ,101,"https://scholar.google.com/scholar?cites=7475822878551950295&as_sdt=80005&sciodt=0,11&hl=en&num=20",7475822878551950295,https://serpapi.com/search.json?as_sdt=80005&cites=7475822878551950295&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:18PTp0x1v2cJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+%22aixi%22+OR+%22bayes%22+OR+%22bayesian%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22+OR+%22knowledge+base%22)&hl=en&num=20&as_sdt=0,11",https://serpapi.com/search.json?as_sdt=0%2C11&engine=google_scholar&hl=en&num=20&q=related%3A18PTp0x1v2cJ%3Ascholar.google.com%2F&start=0,14,"https://scholar.google.com/scholar?cluster=7475822878551950295&hl=en&num=20&as_sdt=0,11",7475822878551950295,https://serpapi.com/search.json?as_sdt=0%2C11&cluster=7475822878551950295&engine=google_scholar&hl=en&num=20,,,,,,,
2,A Bayesian framework for reinforcement learning,8qUHOBQ3vGQJ,http://www.ece.uvic.ca/~bctill/papers/learning/Strens_2000.pdf,… The reinforcement learning problem can be decomposed into two parallel types of inference: (i… This Bayesian method always converges to the optimal policy for a stationary process with …,"M Strens - ICML, 2000 - ece.uvic.ca",M Strens,https://scholar.google.com/citations?user=O4ZsVzYAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=O4ZsVzYAAAAJ&engine=google_scholar_author&hl=en,O4ZsVzYAAAAJ,,,,,,,,,uvic.ca,PDF,http://www.ece.uvic.ca/~bctill/papers/learning/Strens_2000.pdf,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=8qUHOBQ3vGQJ,582,"https://scholar.google.com/scholar?cites=7258737259393295858&as_sdt=80005&sciodt=0,11&hl=en&num=20",7258737259393295858,https://serpapi.com/search.json?as_sdt=80005&cites=7258737259393295858&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:8qUHOBQ3vGQJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+%22aixi%22+OR+%22bayes%22+OR+%22bayesian%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22+OR+%22knowledge+base%22)&hl=en&num=20&as_sdt=0,11",https://serpapi.com/search.json?as_sdt=0%2C11&engine=google_scholar&hl=en&num=20&q=related%3A8qUHOBQ3vGQJ%3Ascholar.google.com%2F&start=0,7,"https://scholar.google.com/scholar?cluster=7258737259393295858&hl=en&num=20&as_sdt=0,11",7258737259393295858,https://serpapi.com/search.json?as_sdt=0%2C11&cluster=7258737259393295858&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:8qUHOBQ3vGQJ:scholar.google.com/+%22reinforcement+learning%22+AND+%22aixi%22+OR+%22bayes%22+OR+%22bayesian%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22+OR+%22knowledge+base%22)&hl=en&num=20&as_sdt=0,11",Pdf,,,,,
3,Efficient reinforcement learning from demonstration via bayesian network-based knowledge extraction,Li_6GMjfbGIJ,https://www.hindawi.com/journals/cin/2021/7588221/,"… Reinforcement Learning from demonstration via Bayesian … from expert demonstrations via Bayesian networks and combines … , we use Bayesian networks to represent discrete Bayesian …","Y Zhang, Y Lan, Q Fang, X Xu, J Li… - Computational …, 2021 - hindawi.com",Y Lan,https://scholar.google.com/citations?user=NTCmJmEAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=NTCmJmEAAAAJ&engine=google_scholar_author&hl=en,NTCmJmEAAAAJ,Q Fang,https://scholar.google.com/citations?user=uJWsyxAAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=uJWsyxAAAAAJ&engine=google_scholar_author&hl=en,uJWsyxAAAAAJ,,,,,hindawi.com,HTML,https://www.hindawi.com/journals/cin/2021/7588221/,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=Li_6GMjfbGIJ,14,"https://scholar.google.com/scholar?cites=7092289563707191086&as_sdt=80005&sciodt=0,11&hl=en&num=20",7092289563707191086,https://serpapi.com/search.json?as_sdt=80005&cites=7092289563707191086&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:Li_6GMjfbGIJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+%22aixi%22+OR+%22bayes%22+OR+%22bayesian%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22+OR+%22knowledge+base%22)&hl=en&num=20&as_sdt=0,11",https://serpapi.com/search.json?as_sdt=0%2C11&engine=google_scholar&hl=en&num=20&q=related%3ALi_6GMjfbGIJ%3Ascholar.google.com%2F&start=0,9,"https://scholar.google.com/scholar?cluster=7092289563707191086&hl=en&num=20&as_sdt=0,11",7092289563707191086,https://serpapi.com/search.json?as_sdt=0%2C11&cluster=7092289563707191086&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:Li_6GMjfbGIJ:scholar.google.com/+%22reinforcement+learning%22+AND+%22aixi%22+OR+%22bayes%22+OR+%22bayesian%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22+OR+%22knowledge+base%22)&hl=en&num=20&as_sdt=0,11",Html,https://www.hindawi.com/journals/cin/2021/7588221/,,,,
4,Bayesian Inverse Reinforcement Learning.,BRK6gYeLqDkJ,https://www.academia.edu/download/7555717/10.1.1.79.2974.pdf,"… 3.1 Evidence from the Expert Now we present the details of our Bayesian IRL model (Fig. 2). … a policy for (M, R) using a reinforcement learning algorithm. Because the expert’s policy is …","D Ramachandran, E Amir - IJCAI, 2007 - academia.edu",D Ramachandran,https://scholar.google.com/citations?user=TJnfAvYAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=TJnfAvYAAAAJ&engine=google_scholar_author&hl=en,TJnfAvYAAAAJ,E Amir,https://scholar.google.com/citations?user=fK04qe4AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=fK04qe4AAAAJ&engine=google_scholar_author&hl=en,fK04qe4AAAAJ,,,,,academia.edu,PDF,https://www.academia.edu/download/7555717/10.1.1.79.2974.pdf,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=BRK6gYeLqDkJ,954,"https://scholar.google.com/scholar?cites=4154724070362583557&as_sdt=80005&sciodt=0,11&hl=en&num=20",4154724070362583557,https://serpapi.com/search.json?as_sdt=80005&cites=4154724070362583557&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:BRK6gYeLqDkJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+%22aixi%22+OR+%22bayes%22+OR+%22bayesian%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22+OR+%22knowledge+base%22)&hl=en&num=20&as_sdt=0,11",https://serpapi.com/search.json?as_sdt=0%2C11&engine=google_scholar&hl=en&num=20&q=related%3ABRK6gYeLqDkJ%3Ascholar.google.com%2F&start=0,15,"https://scholar.google.com/scholar?cluster=4154724070362583557&hl=en&num=20&as_sdt=0,11",4154724070362583557,https://serpapi.com/search.json?as_sdt=0%2C11&cluster=4154724070362583557&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:BRK6gYeLqDkJ:scholar.google.com/+%22reinforcement+learning%22+AND+%22aixi%22+OR+%22bayes%22+OR+%22bayesian%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22+OR+%22knowledge+base%22)&hl=en&num=20&as_sdt=0,11",Pdf,,,,,
5,KERL: A knowledge-guided reinforcement learning model for sequential recommendation,oF5KuB-PnlYJ,https://dl.acm.org/doi/abs/10.1145/3397271.3401134,"… To improve the predictive capacity, we adopt reinforcement learning (RL) for developing … of knowledge graph (KG), we propose a novel Knowledge-guidEd Reinforcement Learning …","P Wang, Y Fan, L Xia, WX Zhao, SZ Niu… - Proceedings of the 43rd …, 2020 - dl.acm.org",P Wang,https://scholar.google.com/citations?user=BEDKYxUAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=BEDKYxUAAAAJ&engine=google_scholar_author&hl=en,BEDKYxUAAAAJ,Y Fan,https://scholar.google.com/citations?user=IZ2kY8gAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=IZ2kY8gAAAAJ&engine=google_scholar_author&hl=en,IZ2kY8gAAAAJ,L Xia,https://scholar.google.com/citations?user=NRwerBAAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=NRwerBAAAAAJ&engine=google_scholar_author&hl=en,NRwerBAAAAAJ,google.com,PDF,https://drive.google.com/file/d/1An5YXDvQ1K0A1AwpJG-I4gTbIQ26gUDS/view,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=oF5KuB-PnlYJ,121,"https://scholar.google.com/scholar?cites=6241583499980725920&as_sdt=80005&sciodt=0,11&hl=en&num=20",6241583499980725920,https://serpapi.com/search.json?as_sdt=80005&cites=6241583499980725920&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:oF5KuB-PnlYJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+%22aixi%22+OR+%22bayes%22+OR+%22bayesian%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22+OR+%22knowledge+base%22)&hl=en&num=20&as_sdt=0,11",https://serpapi.com/search.json?as_sdt=0%2C11&engine=google_scholar&hl=en&num=20&q=related%3AoF5KuB-PnlYJ%3Ascholar.google.com%2F&start=0,3,"https://scholar.google.com/scholar?cluster=6241583499980725920&hl=en&num=20&as_sdt=0,11",6241583499980725920,https://serpapi.com/search.json?as_sdt=0%2C11&cluster=6241583499980725920&engine=google_scholar&hl=en&num=20,,,,WX Zhao,https://scholar.google.com/citations?user=JNhNacoAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=JNhNacoAAAAJ&engine=google_scholar_author&hl=en,JNhNacoAAAAJ
6,Deeppath: A reinforcement learning method for knowledge graph reasoning,ljqVj9Pm070J,https://arxiv.org/abs/1707.06690,"… 2016) is a more recent work on KG reasoning, which also applies reinforcement learning … our RL model tries to add new facts to knowledge graph (KG) by reasoning on existing KG …","W Xiong, T Hoang, WY Wang - arXiv preprint arXiv:1707.06690, 2017 - arxiv.org",W Xiong,https://scholar.google.com/citations?user=J9_LwQUAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=J9_LwQUAAAAJ&engine=google_scholar_author&hl=en,J9_LwQUAAAAJ,WY Wang,https://scholar.google.com/citations?user=gf8Ms_8AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=gf8Ms_8AAAAJ&engine=google_scholar_author&hl=en,gf8Ms_8AAAAJ,,,,,arxiv.org,PDF,https://arxiv.org/pdf/1707.06690,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=ljqVj9Pm070J,783,"https://scholar.google.com/scholar?cites=13678530289575738006&as_sdt=80005&sciodt=0,11&hl=en&num=20",13678530289575738006,https://serpapi.com/search.json?as_sdt=80005&cites=13678530289575738006&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:ljqVj9Pm070J:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+%22aixi%22+OR+%22bayes%22+OR+%22bayesian%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22+OR+%22knowledge+base%22)&hl=en&num=20&as_sdt=0,11",https://serpapi.com/search.json?as_sdt=0%2C11&engine=google_scholar&hl=en&num=20&q=related%3AljqVj9Pm070J%3Ascholar.google.com%2F&start=0,8,"https://scholar.google.com/scholar?cluster=13678530289575738006&hl=en&num=20&as_sdt=0,11",13678530289575738006,https://serpapi.com/search.json?as_sdt=0%2C11&cluster=13678530289575738006&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:ljqVj9Pm070J:scholar.google.com/+%22reinforcement+learning%22+AND+%22aixi%22+OR+%22bayes%22+OR+%22bayesian%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22+OR+%22knowledge+base%22)&hl=en&num=20&as_sdt=0,11",,,,,,
7,Timetraveler: Reinforcement learning for temporal knowledge graph forecasting,lK34YvgFpH0J,https://arxiv.org/abs/2109.04101,"… Temporal knowledge graph (TKG) reasoning is a crucial task that has gained … reinforcement learning method for forecasting. Specifically, the agent travels on historical knowledge graph …","H Sun, J Zhong, Y Ma, Z Han, K He - arXiv preprint arXiv:2109.04101, 2021 - arxiv.org",Y Ma,https://scholar.google.com/citations?user=fj5DzgcAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=fj5DzgcAAAAJ&engine=google_scholar_author&hl=en,fj5DzgcAAAAJ,Z Han,https://scholar.google.com/citations?user=HMdgrwoAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=HMdgrwoAAAAJ&engine=google_scholar_author&hl=en,HMdgrwoAAAAJ,K He,https://scholar.google.com/citations?user=YTQnGJsAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=YTQnGJsAAAAJ&engine=google_scholar_author&hl=en,YTQnGJsAAAAJ,arxiv.org,PDF,https://arxiv.org/pdf/2109.04101,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=lK34YvgFpH0J,103,"https://scholar.google.com/scholar?cites=9053367715292032404&as_sdt=80005&sciodt=0,11&hl=en&num=20",9053367715292032404,https://serpapi.com/search.json?as_sdt=80005&cites=9053367715292032404&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:lK34YvgFpH0J:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+%22aixi%22+OR+%22bayes%22+OR+%22bayesian%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22+OR+%22knowledge+base%22)&hl=en&num=20&as_sdt=0,11",https://serpapi.com/search.json?as_sdt=0%2C11&engine=google_scholar&hl=en&num=20&q=related%3AlK34YvgFpH0J%3Ascholar.google.com%2F&start=0,5,"https://scholar.google.com/scholar?cluster=9053367715292032404&hl=en&num=20&as_sdt=0,11",9053367715292032404,https://serpapi.com/search.json?as_sdt=0%2C11&cluster=9053367715292032404&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:lK34YvgFpH0J:scholar.google.com/+%22reinforcement+learning%22+AND+%22aixi%22+OR+%22bayes%22+OR+%22bayesian%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22+OR+%22knowledge+base%22)&hl=en&num=20&as_sdt=0,11",,,,,,
8,Causal Reinforcement Learning for Knowledge Graph Reasoning,fiZbLaFiAusJ,https://www.mdpi.com/2076-3417/14/6/2498,"… We introduce a new method combining causal inference and reinforcement learning that applies to knowledge graph reasoning. Specifically, the prior knowledge is integrated into the …","D Li, Y Lu, J Wu, W Zhou, G Zeng - Applied Sciences, 2024 - mdpi.com",,,,,,,,,,,,,mdpi.com,PDF,https://www.mdpi.com/2076-3417/14/6/2498/pdf,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=fiZbLaFiAusJ,1,"https://scholar.google.com/scholar?cites=16934205993256691326&as_sdt=80005&sciodt=0,11&hl=en&num=20",16934205993256691326,https://serpapi.com/search.json?as_sdt=80005&cites=16934205993256691326&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:fiZbLaFiAusJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+%22aixi%22+OR+%22bayes%22+OR+%22bayesian%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22+OR+%22knowledge+base%22)&hl=en&num=20&as_sdt=0,11",https://serpapi.com/search.json?as_sdt=0%2C11&engine=google_scholar&hl=en&num=20&q=related%3AfiZbLaFiAusJ%3Ascholar.google.com%2F&start=0,2,"https://scholar.google.com/scholar?cluster=16934205993256691326&hl=en&num=20&as_sdt=0,11",16934205993256691326,https://serpapi.com/search.json?as_sdt=0%2C11&cluster=16934205993256691326&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:fiZbLaFiAusJ:scholar.google.com/+%22reinforcement+learning%22+AND+%22aixi%22+OR+%22bayes%22+OR+%22bayesian%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22+OR+%22knowledge+base%22)&hl=en&num=20&as_sdt=0,11",,,,,,
9,A Bayesian sampling approach to exploration in reinforcement learning,nduvUnIJzZwJ,https://arxiv.org/abs/1205.2664,… We present a modular approach to reinforcement learning that uses a Bayesian repre… to state-of-the-art reinforcement-learning approaches and illustrate its flexibility by pairing it …,"J Asmuth, L Li, ML Littman, A Nouri… - arXiv preprint arXiv …, 2012 - arxiv.org",J Asmuth,https://scholar.google.com/citations?user=-d3QRgUAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=-d3QRgUAAAAJ&engine=google_scholar_author&hl=en,-d3QRgUAAAAJ,L Li,https://scholar.google.com/citations?user=Rqy5KDEAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=Rqy5KDEAAAAJ&engine=google_scholar_author&hl=en,Rqy5KDEAAAAJ,ML Littman,https://scholar.google.com/citations?user=iRMZ2hoAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=iRMZ2hoAAAAJ&engine=google_scholar_author&hl=en,iRMZ2hoAAAAJ,arxiv.org,PDF,https://arxiv.org/pdf/1205.2664,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=nduvUnIJzZwJ,201,"https://scholar.google.com/scholar?cites=11298697426760620957&as_sdt=80005&sciodt=0,11&hl=en&num=20",11298697426760620957,https://serpapi.com/search.json?as_sdt=80005&cites=11298697426760620957&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:nduvUnIJzZwJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+%22aixi%22+OR+%22bayes%22+OR+%22bayesian%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22+OR+%22knowledge+base%22)&hl=en&num=20&as_sdt=0,11",https://serpapi.com/search.json?as_sdt=0%2C11&engine=google_scholar&hl=en&num=20&q=related%3AnduvUnIJzZwJ%3Ascholar.google.com%2F&start=0,19,"https://scholar.google.com/scholar?cluster=11298697426760620957&hl=en&num=20&as_sdt=0,11",11298697426760620957,https://serpapi.com/search.json?as_sdt=0%2C11&cluster=11298697426760620957&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:nduvUnIJzZwJ:scholar.google.com/+%22reinforcement+learning%22+AND+%22aixi%22+OR+%22bayes%22+OR+%22bayesian%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22+OR+%22knowledge+base%22)&hl=en&num=20&as_sdt=0,11",,,,,,
10,An analytic solution to discrete Bayesian reinforcement learning,Oq7JpAaFlHYJ,https://dl.acm.org/doi/abs/10.1145/1143844.1143932,"… value function is one of the causes of the poor scalability of Bayesian RL algorithms. We show that for discrete Bayesian RL, the optimal value function is parameterized by a set of …","P Poupart, N Vlassis, J Hoey, K Regan - Proceedings of the 23rd …, 2006 - dl.acm.org",P Poupart,https://scholar.google.com/citations?user=KhAJWroAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=KhAJWroAAAAJ&engine=google_scholar_author&hl=en,KhAJWroAAAAJ,N Vlassis,https://scholar.google.com/citations?user=JJWWPjsAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=JJWWPjsAAAAJ&engine=google_scholar_author&hl=en,JJWWPjsAAAAJ,J Hoey,https://scholar.google.com/citations?user=YcBGOtQAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=YcBGOtQAAAAJ&engine=google_scholar_author&hl=en,YcBGOtQAAAAJ,uni.lu,PDF,https://orbilu.uni.lu/bitstream/10993/11055/1/download.pdf,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=Oq7JpAaFlHYJ,389,"https://scholar.google.com/scholar?cites=8544600656609652282&as_sdt=80005&sciodt=0,11&hl=en&num=20",8544600656609652282,https://serpapi.com/search.json?as_sdt=80005&cites=8544600656609652282&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:Oq7JpAaFlHYJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+%22aixi%22+OR+%22bayes%22+OR+%22bayesian%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22+OR+%22knowledge+base%22)&hl=en&num=20&as_sdt=0,11",https://serpapi.com/search.json?as_sdt=0%2C11&engine=google_scholar&hl=en&num=20&q=related%3AOq7JpAaFlHYJ%3Ascholar.google.com%2F&start=0,32,"https://scholar.google.com/scholar?cluster=8544600656609652282&hl=en&num=20&as_sdt=0,11",8544600656609652282,https://serpapi.com/search.json?as_sdt=0%2C11&cluster=8544600656609652282&engine=google_scholar&hl=en&num=20,,,,K Regan,https://scholar.google.com/citations?user=VvRfXYwAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=VvRfXYwAAAAJ&engine=google_scholar_author&hl=en,VvRfXYwAAAAJ
11,Reasoning like human: Hierarchical reinforcement learning for knowledge graph reasoning,-1CnwyW_JpQJ,https://opus.lib.uts.edu.au/handle/10453/157768,… Reinforcement Learning framework to learn chains of reasoning from a Knowledge Graph … a hierarchy of two-level Reinforcement Learning policies for encoding historical information …,"G Wan, S Pan, C Gong, C Zhou… - … Joint Conference on …, 2021 - opus.lib.uts.edu.au",G Wan,https://scholar.google.com/citations?user=R-Wy9ksAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=R-Wy9ksAAAAJ&engine=google_scholar_author&hl=en,R-Wy9ksAAAAJ,S Pan,https://scholar.google.com/citations?user=frWRJN4AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=frWRJN4AAAAJ&engine=google_scholar_author&hl=en,frWRJN4AAAAJ,C Gong,https://scholar.google.com/citations?user=guttoBwAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=guttoBwAAAAJ&engine=google_scholar_author&hl=en,guttoBwAAAAJ,uts.edu.au,PDF,https://opus.lib.uts.edu.au/bitstream/10453/157768/2/0267.pdf,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=-1CnwyW_JpQJ,87,"https://scholar.google.com/scholar?cites=10675430135645556987&as_sdt=80005&sciodt=0,11&hl=en&num=20",10675430135645556987,https://serpapi.com/search.json?as_sdt=80005&cites=10675430135645556987&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:-1CnwyW_JpQJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+%22aixi%22+OR+%22bayes%22+OR+%22bayesian%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22+OR+%22knowledge+base%22)&hl=en&num=20&as_sdt=0,11",https://serpapi.com/search.json?as_sdt=0%2C11&engine=google_scholar&hl=en&num=20&q=related%3A-1CnwyW_JpQJ%3Ascholar.google.com%2F&start=0,8,"https://scholar.google.com/scholar?cluster=10675430135645556987&hl=en&num=20&as_sdt=0,11",10675430135645556987,https://serpapi.com/search.json?as_sdt=0%2C11&cluster=10675430135645556987&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:-1CnwyW_JpQJ:scholar.google.com/+%22reinforcement+learning%22+AND+%22aixi%22+OR+%22bayes%22+OR+%22bayesian%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22+OR+%22knowledge+base%22)&hl=en&num=20&as_sdt=0,11",,,C Zhou,https://scholar.google.com/citations?user=4oBUWVEAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=4oBUWVEAAAAJ&engine=google_scholar_author&hl=en,4oBUWVEAAAAJ
12,Rule-aware reinforcement learning for knowledge graph reasoning,sdAnSBNZPUQJ,https://aclanthology.org/2021.findings-acl.412.pdf,Multi-hop reasoning is an effective and explainable approach to predicting missing facts in Knowledge Graphs (KGs). It usually adopts the Reinforcement Learning (RL) framework and …,"Z Hou, X Jin, Z Li, L Bai - Findings of the Association for …, 2021 - aclanthology.org",X Jin,https://scholar.google.com/citations?user=5TRLpyIAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=5TRLpyIAAAAJ&engine=google_scholar_author&hl=en,5TRLpyIAAAAJ,Z Li,https://scholar.google.com/citations?user=fibOdOkAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=fibOdOkAAAAJ&engine=google_scholar_author&hl=en,fibOdOkAAAAJ,L Bai,https://scholar.google.com/citations?user=Zrd9pCMAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=Zrd9pCMAAAAJ&engine=google_scholar_author&hl=en,Zrd9pCMAAAAJ,aclanthology.org,PDF,https://aclanthology.org/2021.findings-acl.412.pdf,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=sdAnSBNZPUQJ,21,"https://scholar.google.com/scholar?cites=4917184307508269233&as_sdt=80005&sciodt=0,11&hl=en&num=20",4917184307508269233,https://serpapi.com/search.json?as_sdt=80005&cites=4917184307508269233&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:sdAnSBNZPUQJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+%22aixi%22+OR+%22bayes%22+OR+%22bayesian%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22+OR+%22knowledge+base%22)&hl=en&num=20&as_sdt=0,11",https://serpapi.com/search.json?as_sdt=0%2C11&engine=google_scholar&hl=en&num=20&q=related%3AsdAnSBNZPUQJ%3Ascholar.google.com%2F&start=0,2,"https://scholar.google.com/scholar?cluster=4917184307508269233&hl=en&num=20&as_sdt=0,11",4917184307508269233,https://serpapi.com/search.json?as_sdt=0%2C11&cluster=4917184307508269233&engine=google_scholar&hl=en&num=20,"https://scholar.googleusercontent.com/scholar?q=cache:sdAnSBNZPUQJ:scholar.google.com/+%22reinforcement+learning%22+AND+%22aixi%22+OR+%22bayes%22+OR+%22bayesian%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22+OR+%22knowledge+base%22)&hl=en&num=20&as_sdt=0,11",Pdf,,,,,
13,GRL: Knowledge graph completion with GAN-based reinforcement learning,4mJwBc2tywMJ,https://www.sciencedirect.com/science/article/pii/S0950705120305505,"… knowledge graph are important factors for knowledge graph … based on GAN and reinforcement learning. We use WGAN to … NAS) to knowledge graph reasoning, and combine GAN and …","Q Wang, Y Ji, Y Hao, J Cao - Knowledge-Based Systems, 2020 - Elsevier",Y Ji,https://scholar.google.com/citations?user=1-GjVYgAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=1-GjVYgAAAAJ&engine=google_scholar_author&hl=en,1-GjVYgAAAAJ,Y Hao,https://scholar.google.com/citations?user=26lghIsAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=26lghIsAAAAJ&engine=google_scholar_author&hl=en,26lghIsAAAAJ,,,,,,,,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=4mJwBc2tywMJ,47,"https://scholar.google.com/scholar?cites=273503298457199330&as_sdt=80005&sciodt=0,11&hl=en&num=20",273503298457199330,https://serpapi.com/search.json?as_sdt=80005&cites=273503298457199330&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:4mJwBc2tywMJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+%22aixi%22+OR+%22bayes%22+OR+%22bayesian%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22+OR+%22knowledge+base%22)&hl=en&num=20&as_sdt=0,11",https://serpapi.com/search.json?as_sdt=0%2C11&engine=google_scholar&hl=en&num=20&q=related%3A4mJwBc2tywMJ%3Ascholar.google.com%2F&start=0,2,"https://scholar.google.com/scholar?cluster=273503298457199330&hl=en&num=20&as_sdt=0,11",273503298457199330,https://serpapi.com/search.json?as_sdt=0%2C11&cluster=273503298457199330&engine=google_scholar&hl=en&num=20,,,,,,,
14,Model-based Bayesian reinforcement learning in large structured domains,Xz2kHoipackJ,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4629999/,"… Model-based Bayesian reinforcement learning has … tradeoff in classical reinforcement learning. Unfortunately, the … The main contribution of this paper is a Bayesian framework for …","S Ross, J Pineau - … in artificial intelligence: proceedings of the …, 2008 - ncbi.nlm.nih.gov",J Pineau,https://scholar.google.com/citations?user=CEt6_mMAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=CEt6_mMAAAAJ&engine=google_scholar_author&hl=en,CEt6_mMAAAAJ,,,,,,,,,nih.gov,HTML,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4629999/,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=Xz2kHoipackJ,75,"https://scholar.google.com/scholar?cites=14513317676272860511&as_sdt=80005&sciodt=0,11&hl=en&num=20",14513317676272860511,https://serpapi.com/search.json?as_sdt=80005&cites=14513317676272860511&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:Xz2kHoipackJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+%22aixi%22+OR+%22bayes%22+OR+%22bayesian%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22+OR+%22knowledge+base%22)&hl=en&num=20&as_sdt=0,11",https://serpapi.com/search.json?as_sdt=0%2C11&engine=google_scholar&hl=en&num=20&q=related%3AXz2kHoipackJ%3Ascholar.google.com%2F&start=0,17,"https://scholar.google.com/scholar?cluster=14513317676272860511&hl=en&num=20&as_sdt=0,11",14513317676272860511,https://serpapi.com/search.json?as_sdt=0%2C11&cluster=14513317676272860511&engine=google_scholar&hl=en&num=20,,Html,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4629999/,,,,
15,Dynamic knowledge graph reasoning based on deep reinforcement learning,8uknR9-IccAJ,https://www.sciencedirect.com/science/article/pii/S0950705122000697,"… has become a new technical tool for knowledge graph reasoning. However, most previous … knowledge graph reasoning framework is proposed based on deep reinforcement learning, …","H Liu, S Zhou, C Chen, T Gao, J Xu, M Shu - Knowledge-Based Systems, 2022 - Elsevier",H Liu,https://scholar.google.com/citations?user=Kv0kuVYAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=Kv0kuVYAAAAJ&engine=google_scholar_author&hl=en,Kv0kuVYAAAAJ,,,,,,,,,,,,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=8uknR9-IccAJ,38,"https://scholar.google.com/scholar?cites=13867015220203350514&as_sdt=80005&sciodt=0,11&hl=en&num=20",13867015220203350514,https://serpapi.com/search.json?as_sdt=80005&cites=13867015220203350514&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:8uknR9-IccAJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+%22aixi%22+OR+%22bayes%22+OR+%22bayesian%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22+OR+%22knowledge+base%22)&hl=en&num=20&as_sdt=0,11",https://serpapi.com/search.json?as_sdt=0%2C11&engine=google_scholar&hl=en&num=20&q=related%3A8uknR9-IccAJ%3Ascholar.google.com%2F&start=0,2,"https://scholar.google.com/scholar?cluster=13867015220203350514&hl=en&num=20&as_sdt=0,11",13867015220203350514,https://serpapi.com/search.json?as_sdt=0%2C11&cluster=13867015220203350514&engine=google_scholar&hl=en&num=20,,,,,,,
16,Interactive recommender system via knowledge graph-enhanced reinforcement learning,aVQ7jm2mwjgJ,https://dl.acm.org/doi/abs/10.1145/3397271.3401174,"… Knowledge Graph enhanced Q-learning framework for interactive Recommendation), a novel architecture that extends DQN… to-end deep reinforcement learning based framework KGQR …","S Zhou, X Dai, H Chen, W Zhang, K Ren… - Proceedings of the 43rd …, 2020 - dl.acm.org",X Dai,https://scholar.google.com/citations?user=X20p7l4AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=X20p7l4AAAAJ&engine=google_scholar_author&hl=en,X20p7l4AAAAJ,H Chen,https://scholar.google.com/citations?user=J_GWOJAAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=J_GWOJAAAAAJ&engine=google_scholar_author&hl=en,J_GWOJAAAAAJ,W Zhang,https://scholar.google.com/citations?user=Qzss0GEAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=Qzss0GEAAAAJ&engine=google_scholar_author&hl=en,Qzss0GEAAAAJ,arxiv.org,PDF,https://arxiv.org/pdf/2006.10389,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=aVQ7jm2mwjgJ,156,"https://scholar.google.com/scholar?cites=4090014401073730665&as_sdt=80005&sciodt=0,11&hl=en&num=20",4090014401073730665,https://serpapi.com/search.json?as_sdt=80005&cites=4090014401073730665&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:aVQ7jm2mwjgJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+%22aixi%22+OR+%22bayes%22+OR+%22bayesian%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22+OR+%22knowledge+base%22)&hl=en&num=20&as_sdt=0,11",https://serpapi.com/search.json?as_sdt=0%2C11&engine=google_scholar&hl=en&num=20&q=related%3AaVQ7jm2mwjgJ%3Ascholar.google.com%2F&start=0,4,"https://scholar.google.com/scholar?cluster=4090014401073730665&hl=en&num=20&as_sdt=0,11",4090014401073730665,https://serpapi.com/search.json?as_sdt=0%2C11&cluster=4090014401073730665&engine=google_scholar&hl=en&num=20,,,,K Ren,https://scholar.google.com/citations?user=USnQVWgAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=USnQVWgAAAAJ&engine=google_scholar_author&hl=en,USnQVWgAAAAJ
17,A bayesian approach to robust reinforcement learning,lT7PFx5MMkMJ,http://proceedings.mlr.press/v115/derman20a.html,"… In this work, we introduce a Bayesian framework for robust RL and address the first Bayesian … and less conservative, improved performance for the resulting DQN-URBE policy. …","E Derman, D Mankowitz, T Mann… - Uncertainty in Artificial …, 2020 - proceedings.mlr.press",E Derman,https://scholar.google.com/citations?user=IBIXZCAAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=IBIXZCAAAAAJ&engine=google_scholar_author&hl=en,IBIXZCAAAAAJ,D Mankowitz,https://scholar.google.com/citations?user=v84tWxsAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=v84tWxsAAAAJ&engine=google_scholar_author&hl=en,v84tWxsAAAAJ,T Mann,https://scholar.google.com/citations?user=iIKGkhYAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=iIKGkhYAAAAJ&engine=google_scholar_author&hl=en,iIKGkhYAAAAJ,mlr.press,PDF,http://proceedings.mlr.press/v115/derman20a/derman20a.pdf,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=lT7PFx5MMkMJ,48,"https://scholar.google.com/scholar?cites=4842016241508892309&as_sdt=80005&sciodt=0,11&hl=en&num=20",4842016241508892309,https://serpapi.com/search.json?as_sdt=80005&cites=4842016241508892309&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:lT7PFx5MMkMJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+%22aixi%22+OR+%22bayes%22+OR+%22bayesian%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22+OR+%22knowledge+base%22)&hl=en&num=20&as_sdt=0,11",https://serpapi.com/search.json?as_sdt=0%2C11&engine=google_scholar&hl=en&num=20&q=related%3AlT7PFx5MMkMJ%3Ascholar.google.com%2F&start=0,6,"https://scholar.google.com/scholar?cluster=4842016241508892309&hl=en&num=20&as_sdt=0,11",4842016241508892309,https://serpapi.com/search.json?as_sdt=0%2C11&cluster=4842016241508892309&engine=google_scholar&hl=en&num=20,"http://scholar.googleusercontent.com/scholar?q=cache:lT7PFx5MMkMJ:scholar.google.com/+%22reinforcement+learning%22+AND+%22aixi%22+OR+%22bayes%22+OR+%22bayesian%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22+OR+%22knowledge+base%22)&hl=en&num=20&as_sdt=0,11",,,,,,
18,Multi-task reinforcement learning: a hierarchical bayesian approach,onHFHqVDlqgJ,https://dl.acm.org/doi/abs/10.1145/1273496.1273624,… We model the distribution over MDPs using a hierarchical Bayesian infinite mixture model. … modelbased Bayesian reinforcement learning. The hierarchical Bayesian framework provides …,"A Wilson, A Fern, S Ray, P Tadepalli - Proceedings of the 24th …, 2007 - dl.acm.org",A Wilson,https://scholar.google.com/citations?user=tyT75gsAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=tyT75gsAAAAJ&engine=google_scholar_author&hl=en,tyT75gsAAAAJ,A Fern,https://scholar.google.com/citations?user=Xt_Qd94AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=Xt_Qd94AAAAJ&engine=google_scholar_author&hl=en,Xt_Qd94AAAAJ,S Ray,https://scholar.google.com/citations?user=T3Wxu_AAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=T3Wxu_AAAAAJ&engine=google_scholar_author&hl=en,T3Wxu_AAAAAJ,academia.edu,PDF,https://www.academia.edu/download/42337001/463.pdf,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=onHFHqVDlqgJ,395,"https://scholar.google.com/scholar?cites=12147971421343412642&as_sdt=80005&sciodt=0,11&hl=en&num=20",12147971421343412642,https://serpapi.com/search.json?as_sdt=80005&cites=12147971421343412642&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:onHFHqVDlqgJ:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+%22aixi%22+OR+%22bayes%22+OR+%22bayesian%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22+OR+%22knowledge+base%22)&hl=en&num=20&as_sdt=0,11",https://serpapi.com/search.json?as_sdt=0%2C11&engine=google_scholar&hl=en&num=20&q=related%3AonHFHqVDlqgJ%3Ascholar.google.com%2F&start=0,17,"https://scholar.google.com/scholar?cluster=12147971421343412642&hl=en&num=20&as_sdt=0,11",12147971421343412642,https://serpapi.com/search.json?as_sdt=0%2C11&cluster=12147971421343412642&engine=google_scholar&hl=en&num=20,,,,P Tadepalli,https://scholar.google.com/citations?user=CXAN0i0AAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=CXAN0i0AAAAJ&engine=google_scholar_author&hl=en,CXAN0i0AAAAJ
19,Coordination in multiagent reinforcement learning: A Bayesian approach,uMcS9cxKv18J,https://dl.acm.org/doi/abs/10.1145/860575.860689,… Much emphasis in multiagent reinforcement learning (MARL) re… We propose a Bayesian model for optimal exploration in … We develop tractable approximations to optimal Bayesian …,"G Chalkiadakis, C Boutilier - … of the second international joint conference …, 2003 - dl.acm.org",G Chalkiadakis,https://scholar.google.com/citations?user=KdYD5-cAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=KdYD5-cAAAAJ&engine=google_scholar_author&hl=en,KdYD5-cAAAAJ,C Boutilier,https://scholar.google.com/citations?user=cXkm3rsAAAAJ&hl=en&num=20&oi=sra,https://serpapi.com/search.json?author_id=cXkm3rsAAAAJ&engine=google_scholar_author&hl=en,cXkm3rsAAAAJ,,,,,huji.ac.il,PDF,http://www.cs.huji.ac.il/course/2003/aisemin/articles/chalkiadakis.pdf,https://serpapi.com/search.json?engine=google_scholar_cite&hl=en&q=uMcS9cxKv18J,232,"https://scholar.google.com/scholar?cites=6899315398300321720&as_sdt=80005&sciodt=0,11&hl=en&num=20",6899315398300321720,https://serpapi.com/search.json?as_sdt=80005&cites=6899315398300321720&engine=google_scholar&hl=en&num=20,"https://scholar.google.com/scholar?q=related:uMcS9cxKv18J:scholar.google.com/&scioq=%22reinforcement+learning%22+AND+%22aixi%22+OR+%22bayes%22+OR+%22bayesian%22+OR+%22dqn%22+OR+%22induction%22+OR+%22solomonoff%22+OR+%22kolmogorov%22+OR+%22knowledge+graph%22+OR+%22knowledge+base%22)&hl=en&num=20&as_sdt=0,11",https://serpapi.com/search.json?as_sdt=0%2C11&engine=google_scholar&hl=en&num=20&q=related%3AuMcS9cxKv18J%3Ascholar.google.com%2F&start=0,20,"https://scholar.google.com/scholar?cluster=6899315398300321720&hl=en&num=20&as_sdt=0,11",6899315398300321720,https://serpapi.com/search.json?as_sdt=0%2C11&cluster=6899315398300321720&engine=google_scholar&hl=en&num=20,,,,,,,
